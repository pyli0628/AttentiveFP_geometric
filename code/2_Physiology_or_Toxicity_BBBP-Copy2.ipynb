{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  2050\n",
      "failed to process smiles:  O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n",
      "failed to process smiles:  c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
      "failed to process smiles:  Cc1nc(sc1)\\[NH]=C(\\N)N\n",
      "failed to process smiles:  s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n",
      "failed to process smiles:  c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n",
      "failed to process smiles:  s1cc(nc1\\[NH]=C(\\N)N)C\n",
      "failed to process smiles:  c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n",
      "number of successfully processed smiles:  2039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'BBBP'\n",
    "tasks = ['BBBP']\n",
    "raw_filename = \"../data/BBBP.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"failed to process smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBBP</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)C1OC(=O)C2=CCCN2C(=O)c3coc(CC(=O)CC(O)\\C=...</td>\n",
       "      <td>C/C1=C/C(O)CC(=O)Cc2nc(co2)C(=O)N2CCC=C2C(=O)O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BBBP                                             smiles  \\\n",
       "944     0  CC(C)C1OC(=O)C2=CCCN2C(=O)c3coc(CC(=O)CC(O)\\C=...   \n",
       "\n",
       "                                           cano_smiles  \n",
       "944  C/C1=C/C(O)CC(=O)Cc2nc(co2)C(=O)N2CCC=C2C(=O)O...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "remained_df = remained_df.reset_index(drop=True)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "class ScaffoldGenerator(object):\n",
    "    \"\"\"\n",
    "    Generate molecular scaffolds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    include_chirality : : bool, optional (default False)\n",
    "      Include chirality in scaffolds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, include_chirality=False):\n",
    "        self.include_chirality = include_chirality\n",
    "\n",
    "    def get_scaffold(self, mol):\n",
    "        \"\"\"\n",
    "        Get Murcko scaffolds for molecules.\n",
    "\n",
    "        Murcko scaffolds are described in DOI: 10.1021/jm9602928. They are\n",
    "        essentially that part of the molecule consisting of rings and the\n",
    "        linker atoms between them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mols : array_like\n",
    "            Molecules.\n",
    "        \"\"\"\n",
    "        return MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=self.include_chirality)\n",
    "\n",
    "\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    engine = ScaffoldGenerator(include_chirality=include_chirality)\n",
    "    scaffold = engine.get_scaffold(mol)\n",
    "    return scaffold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "scaffold_list = []\n",
    "all_scaffolds_dict = {}\n",
    "\n",
    "for index, smiles in enumerate(remained_df['cano_smiles']):\n",
    "    scaffold = generate_scaffold(smiles)\n",
    "    scaffold_list.append(scaffold)\n",
    "    if scaffold not in all_scaffolds_dict:\n",
    "        all_scaffolds_dict[scaffold] = [index]\n",
    "    else:\n",
    "        all_scaffolds_dict[scaffold].append(index)\n",
    "remained_df['scaffold'] = scaffold_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaffold</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>c1ccccc1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>O=C1C=CC2C(=C1)CCC1C3CCCC3CCC21</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>c1ccc2c(c1)Nc1ccccc1S2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>O=C1CN=C(c2ccccc2)c2ccccc2N1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>O=C1C=C2CCC3C4CCCC4CCC3C2CC1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>c1ccc(Cc2ccccc2)cc1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>O=C1CC(=O)NC(=O)N1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>O=C(Cc1ccccc1)N1CCNCC1CN1CCCC1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>c1ccncc1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            scaffold  count\n",
       "991                         c1ccccc1    137\n",
       "0                                        99\n",
       "379  O=C1C=CC2C(=C1)CCC1C3CCCC3CCC21     76\n",
       "945           c1ccc2c(c1)Nc1ccccc1S2     26\n",
       "496     O=C1CN=C(c2ccccc2)c2ccccc2N1     26\n",
       "357     O=C1C=C2CCC3C4CCCC4CCC3C2CC1     24\n",
       "833              c1ccc(Cc2ccccc2)cc1     21\n",
       "400               O=C1CC(=O)NC(=O)N1     18\n",
       "201   O=C(Cc1ccccc1)N1CCNCC1CN1CCCC1     17\n",
       "994                         c1ccncc1     16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_df.groupby(['scaffold'])['scaffold'].count() \\\n",
    "                     .reset_index(name='count') \\\n",
    "                     .sort_values(['count'], ascending=False) \\\n",
    "                     .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "160 201 49 [176, 836, 1000, 663, 807, 872, 926, 254, 995, 1843, 1158, 689, 1393, 1761, 1025, 977, 1120, 1425, 1712, 1060, 1803, 1588, 331, 1440, 863, 938, 14, 470, 578, 708, 851, 946, 967, 1049, 1155, 1274, 1370, 1606, 1693, 1697, 1703, 1708, 1725, 1741, 1857, 1887, 1917, 476, 1116, 1590, 1998, 169, 633, 1673, 62, 359, 63, 871, 841, 860, 1867, 1004, 734, 909, 492, 1609, 1879, 477, 1565, 1935, 553, 1031, 1264, 1902, 1454, 1327, 304, 23, 1316, 1456, 1208, 1392, 1968, 481, 270, 911, 1436, 1428, 1318, 1801, 106, 283, 284, 216, 222, 822, 916, 572, 1389, 1357, 3, 89, 654, 656, 793, 794, 846, 862, 1154, 1485, 488, 490, 507, 508, 510, 511, 512, 513, 514, 515, 516, 537, 538, 539, 540, 594, 599, 738, 25, 48, 58, 114, 275, 325, 357, 559, 560, 610, 611, 641, 1397, 1398, 1564, 1856, 1384, 1065, 1390, 1500, 27, 1551, 1460, 1157, 1368, 330, 1439, 64, 1690, 1864, 1566, 1209, 1483, 900, 1080, 776, 279, 328, 1032, 1047, 498, 1172, 1657, 1760, 178, 1493, 1236, 1401, 1980, 2003, 1192, 1977, 768, 30, 193, 445, 448, 479, 496, 989, 1007, 1050, 1347, 1492, 1577, 1699, 1710, 1909, 1990, 2021, 2022, 1451, 1054]\n",
      "164 207 49 [151, 1602, 636, 473, 1610, 1013, 1072, 1252, 1311, 857, 191, 133, 1044, 1194, 1343, 1576, 1767, 920, 934, 1045, 885, 5, 1853, 1956, 1284, 319, 244, 428, 547, 574, 651, 1292, 1727, 1883, 1952, 1906, 644, 674, 1403, 174, 1855, 990, 1308, 115, 1544, 1905, 1205, 180, 1543, 137, 1519, 813, 1658, 1678, 96, 267, 358, 579, 1256, 1452, 1530, 45, 55, 166, 185, 186, 240, 442, 482, 483, 522, 628, 685, 686, 697, 1125, 1221, 1659, 1665, 1674, 1754, 1784, 1859, 1863, 1889, 1960, 2011, 1945, 747, 192, 573, 1723, 1808, 1193, 1422, 1463, 1470, 1160, 1645, 342, 919, 1869, 975, 2004, 1925, 47, 765, 766, 341, 551, 125, 150, 205, 348, 399, 695, 722, 796, 800, 849, 870, 346, 1423, 61, 586, 618, 619, 620, 621, 1467, 1476, 1829, 985, 408, 879, 84, 1764, 227, 386, 2031, 1419, 1448, 1941, 2014, 671, 1813, 1881, 2015, 85, 657, 998, 217, 1306, 1514, 1802, 1559, 1738, 1873, 755, 742, 743, 744, 745, 756, 772, 775, 788, 1780, 272, 925, 965, 996, 1323, 1792, 1799, 1324, 1653, 159, 867, 873, 688, 1939, 145, 893, 1600, 968, 978, 1183, 1550, 1552, 1640, 1962, 1970, 1987, 1213, 642, 748, 759, 762, 763, 1561, 2028, 842, 715, 352, 729, 865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/erikxiong/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def scaffold_randomized_spliting(scaffolds_dict, sample_size, random_seed = 0): \n",
    "    count = 0\n",
    "    minor_count = 0\n",
    "    minor_class = np.argmax(weights[0]) # weights are inverse of the ratio\n",
    "    minor_ratio= 1/weights[0][minor_class]\n",
    "    optimal_count = 0.1*len(remained_df)\n",
    "    while (count < optimal_count*0.95 or  count > optimal_count*1.05) \\\n",
    "        or (minor_count < minor_ratio*optimal_count*0.95 \\\n",
    "            or  minor_count > minor_ratio*optimal_count*1.05):\n",
    "        random_seed +=1\n",
    "        random.seed(random_seed)\n",
    "        scaffold = random.sample(list(scaffolds_dict.keys()), sample_size)\n",
    "        count = sum([len(scaffolds_dict[scaffold]) for scaffold in scaffold])\n",
    "        index = [index for scaffold in scaffold for index in scaffolds_dict[scaffold]]\n",
    "        minor_count = len(remained_df.iloc[index, :][remained_df[tasks[0]] == minor_class])\n",
    "#     print(random)\n",
    "    print(random_seed, count, minor_count, index)\n",
    "    return scaffold, index\n",
    "\n",
    "samples_size = int(len(all_scaffolds_dict.keys())*0.1)\n",
    "print(samples_size)\n",
    "test_scaffold, test_index = scaffold_randomized_spliting(all_scaffolds_dict, samples_size, random_seed=100)\n",
    "training_scaffolds_dict = {x: all_scaffolds_dict[x] for x in all_scaffolds_dict.keys() if x not in test_scaffold}\n",
    "valid_scaffold, valid_index = scaffold_randomized_spliting(training_scaffolds_dict, samples_size, random_seed=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = remained_df.iloc[test_index,:] # test set\n",
    "valid_df = remained_df.iloc[valid_index,:] # valid set\n",
    "train_df = remained_df.drop(test_df.index).drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "#     test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "# #     test_prc = auc(recall, precision)\n",
    "#     test_precision = [precision_score(y_val_list[i],\n",
    "#                                      (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "#     test_recall = [recall_score(y_val_list[i],\n",
    "#                                (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_loss #test_prc, test_precision, test_recall, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc:[0.6801856763925729]\n",
      "valid_roc:[0.8266597778351847]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.758597347480106]\n",
      "valid_roc:[0.9026091449237923]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.7745994694960213]\n",
      "valid_roc:[0.9192715060707827]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.7814005305039787]\n",
      "valid_roc:[0.9267631103074141]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7906015915119364]\n",
      "valid_roc:[0.931929733918884]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.7989262599469497]\n",
      "valid_roc:[0.9323172306897443]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.8087045092838197]\n",
      "valid_roc:[0.933996383363472]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.8162567639257294]\n",
      "valid_roc:[0.9368380263497803]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.8238790450928383]\n",
      "valid_roc:[0.9355463704469129]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.8327787798408488]\n",
      "valid_roc:[0.9387755102040817]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.8394228116710876]\n",
      "valid_roc:[0.9387755102040818]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.8425061007957559]\n",
      "valid_roc:[0.9394213381555153]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.8420137931034483]\n",
      "valid_roc:[0.9373546887109273]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.8446641909814324]\n",
      "valid_roc:[0.9392921725652287]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.8470705570291778]\n",
      "valid_roc:[0.9409713252389563]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.8518875331564986]\n",
      "valid_roc:[0.9392921725652286]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.8582175066312998]\n",
      "valid_roc:[0.9369671919400673]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.8609273209549071]\n",
      "valid_roc:[0.9374838543012141]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.8622811671087535]\n",
      "valid_roc:[0.9369671919400671]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.8676498673740052]\n",
      "valid_roc:[0.93606303280806]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.8699968169761273]\n",
      "valid_roc:[0.9364505295789202]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.8709347480106101]\n",
      "valid_roc:[0.9363213639886334]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.8746079575596818]\n",
      "valid_roc:[0.9356755360371997]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.8737230769230768]\n",
      "valid_roc:[0.9376130198915009]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.8740901856763925]\n",
      "valid_roc:[0.9383880134332213]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.8779734748010611]\n",
      "valid_roc:[0.9385171790235082]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.880231299734748]\n",
      "valid_roc:[0.9373546887109275]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.8801549071618038]\n",
      "valid_roc:[0.9352880392663395]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.8789474801061007]\n",
      "valid_roc:[0.9370963575303539]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.8796541114058356]\n",
      "valid_roc:[0.9373546887109273]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.8820625994694958]\n",
      "valid_roc:[0.9378713510720744]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.8820986737400531]\n",
      "valid_roc:[0.9385171790235082]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.8859522546419099]\n",
      "valid_roc:[0.9376130198915009]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.8837453580901857]\n",
      "valid_roc:[0.9399380005166624]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.8859946949602122]\n",
      "valid_roc:[0.9405838284680961]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.8874567639257294]\n",
      "valid_roc:[0.9412296564195299]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.8893538461538463]\n",
      "valid_roc:[0.9390338413846552]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.889975596816976]\n",
      "valid_roc:[0.9399380005166624]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.8905506631299734]\n",
      "valid_roc:[0.9394213381555154]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.8914949602122016]\n",
      "valid_roc:[0.9400671661069493]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8888785145888595]\n",
      "valid_roc:[0.9405838284680962]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.888176127320955]\n",
      "valid_roc:[0.9391630069749419]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.891978779840849]\n",
      "valid_roc:[0.9394213381555154]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.8940286472148542]\n",
      "valid_roc:[0.9395505037458022]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.8944360742705568]\n",
      "valid_roc:[0.9400671661069491]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.8961909814323609]\n",
      "valid_roc:[0.9409713252389563]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.8966408488063661]\n",
      "valid_roc:[0.9409713252389563]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.8989771883289125]\n",
      "valid_roc:[0.9420046499612504]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.8973283819628648]\n",
      "valid_roc:[0.9430379746835443]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.8970355437665783]\n",
      "valid_roc:[0.9416171531903902]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.8992424403183024]\n",
      "valid_roc:[0.9394213381555153]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.8983936339522547]\n",
      "valid_roc:[0.9418754843709637]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.9011458885941646]\n",
      "valid_roc:[0.9447171273572721]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.9035480106100795]\n",
      "valid_roc:[0.9448462929475587]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.9041379310344828]\n",
      "valid_roc:[0.9430379746835443]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.9040933687002652]\n",
      "valid_roc:[0.9439421338155516]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.9033824933687002]\n",
      "valid_roc:[0.9434254714544046]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.9061623342175066]\n",
      "valid_roc:[0.9432963058641177]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.9057973474801062]\n",
      "valid_roc:[0.943167140273831]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.9106037135278515]\n",
      "valid_roc:[0.9454921208989926]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.9073167108753316]\n",
      "valid_roc:[0.9407129940583827]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.9125241379310345]\n",
      "valid_roc:[0.9466546112115733]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.9156053050397879]\n",
      "valid_roc:[0.9471712735727202]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.9117962864721485]\n",
      "valid_roc:[0.946267114440713]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.9131586206896551]\n",
      "valid_roc:[0.9416171531903901]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.9108350132625993]\n",
      "valid_roc:[0.943683802634978]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.9155543766578249]\n",
      "valid_roc:[0.9452337897184191]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.9137612732095489]\n",
      "valid_roc:[0.9461379488504262]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.9162822281167108]\n",
      "valid_roc:[0.9466546112115732]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.9195607427055703]\n",
      "valid_roc:[0.9454921208989926]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.9162652519893898]\n",
      "valid_roc:[0.9445879617669852]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.9224]\n",
      "valid_roc:[0.94678377680186]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.9210864721485411]\n",
      "valid_roc:[0.9509170756910359]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.9217740053050398]\n",
      "valid_roc:[0.9458796176698526]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.9250440318302389]\n",
      "valid_roc:[0.9470421079824334]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.9178737400530506]\n",
      "valid_roc:[0.9489795918367346]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.9216424403183024]\n",
      "valid_roc:[0.9502712477396021]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.9274885941644562]\n",
      "valid_roc:[0.9474296047532937]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.9180689655172413]\n",
      "valid_roc:[0.9400671661069491]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.9294026525198937]\n",
      "valid_roc:[0.948333763885301]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.9281145888594164]\n",
      "valid_roc:[0.9452337897184189]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.9227437665782494]\n",
      "valid_roc:[0.9418754843709636]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.9307649867374006]\n",
      "valid_roc:[0.9473004391630069]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.9186185676392573]\n",
      "valid_roc:[0.9505295789201756]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.9264328912466844]\n",
      "valid_roc:[0.9435546370446913]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.9317602122015914]\n",
      "valid_roc:[0.95233789718419]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.930576127320955]\n",
      "valid_roc:[0.9489795918367347]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.9329336870026524]\n",
      "valid_roc:[0.9516920692327564]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.9338610079575597]\n",
      "valid_roc:[0.947817101524154]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.9300923076923078]\n",
      "valid_roc:[0.9435546370446913]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.9353421750663129]\n",
      "valid_roc:[0.9504004133298889]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.936014854111406]\n",
      "valid_roc:[0.949883750968742]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.9377994694960213]\n",
      "valid_roc:[0.9524670627744769]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.9372498673740054]\n",
      "valid_roc:[0.9520795660036167]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.935518302387268]\n",
      "valid_roc:[0.9426504779126841]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.927787798408488]\n",
      "valid_roc:[0.9383880134332214]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.937332625994695]\n",
      "valid_roc:[0.947817101524154]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.9401931034482758]\n",
      "valid_roc:[0.9524670627744768]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.9377506631299735]\n",
      "valid_roc:[0.9492379230173081]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.937101326259947]\n",
      "valid_roc:[0.9524670627744768]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.937831299734748]\n",
      "valid_roc:[0.9476879359338674]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.9418610079575598]\n",
      "valid_roc:[0.9528545595453372]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.9412477453580902]\n",
      "valid_roc:[0.9532420563161975]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.9419458885941645]\n",
      "valid_roc:[0.9500129165590285]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.943766578249337]\n",
      "valid_roc:[0.9516920692327564]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.9420286472148542]\n",
      "valid_roc:[0.9541462154482047]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.9384233421750663]\n",
      "valid_roc:[0.9553087057607852]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.9375490716180371]\n",
      "valid_roc:[0.9385171790235082]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.9434928381962865]\n",
      "valid_roc:[0.9501420821493154]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.9440190981432361]\n",
      "valid_roc:[0.9562128648927926]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.9441230769230768]\n",
      "valid_roc:[0.9474296047532936]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.9447787798408488]\n",
      "valid_roc:[0.9546628778093516]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.9459310344827587]\n",
      "valid_roc:[0.9537587186773444]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t113\n",
      "train_roc:[0.9467777188328914]\n",
      "valid_roc:[0.9492379230173082]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.9454302387267904]\n",
      "valid_roc:[0.9466546112115732]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.944180371352785]\n",
      "valid_roc:[0.9572461896150866]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.9464127320954907]\n",
      "valid_roc:[0.9456212864892792]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.9466801061007957]\n",
      "valid_roc:[0.9542753810384914]\n",
      "\n",
      "EPOCH:\t118\n",
      "train_roc:[0.9469135278514588]\n",
      "valid_roc:[0.948850426246448]\n",
      "\n",
      "EPOCH:\t119\n",
      "train_roc:[0.9480551724137931]\n",
      "valid_roc:[0.9489795918367347]\n",
      "\n",
      "EPOCH:\t120\n",
      "train_roc:[0.9487618037135278]\n",
      "valid_roc:[0.9545337122190648]\n",
      "\n",
      "EPOCH:\t121\n",
      "train_roc:[0.9487448275862069]\n",
      "valid_roc:[0.9555670369413588]\n",
      "\n",
      "EPOCH:\t122\n",
      "train_roc:[0.9408509283819629]\n",
      "valid_roc:[0.953887884267631]\n",
      "\n",
      "EPOCH:\t123\n",
      "train_roc:[0.9485453580901857]\n",
      "valid_roc:[0.953371221906484]\n",
      "\n",
      "EPOCH:\t124\n",
      "train_roc:[0.9463427055702919]\n",
      "valid_roc:[0.9476879359338671]\n",
      "\n",
      "EPOCH:\t125\n",
      "train_roc:[0.9483628647214855]\n",
      "valid_roc:[0.9480754327047275]\n",
      "\n",
      "EPOCH:\t126\n",
      "train_roc:[0.949795225464191]\n",
      "valid_roc:[0.9549212089899253]\n",
      "\n",
      "EPOCH:\t127\n",
      "train_roc:[0.9512572944297083]\n",
      "valid_roc:[0.9525962283647637]\n",
      "\n",
      "EPOCH:\t128\n",
      "train_roc:[0.9489676392572945]\n",
      "valid_roc:[0.9474296047532937]\n",
      "\n",
      "EPOCH:\t129\n",
      "train_roc:[0.9462514588859416]\n",
      "valid_roc:[0.9479462671144407]\n",
      "\n",
      "EPOCH:\t130\n",
      "train_roc:[0.9450758620689655]\n",
      "valid_roc:[0.9482045982950142]\n",
      "\n",
      "EPOCH:\t131\n",
      "train_roc:[0.9495108753315651]\n",
      "valid_roc:[0.9502712477396021]\n",
      "\n",
      "EPOCH:\t132\n",
      "train_roc:[0.9511405835543767]\n",
      "valid_roc:[0.9513045724618961]\n",
      "\n",
      "EPOCH:\t133\n",
      "train_roc:[0.9495427055702917]\n",
      "valid_roc:[0.9458796176698528]\n",
      "\n",
      "EPOCH:\t134\n",
      "train_roc:[0.9515840848806365]\n",
      "valid_roc:[0.9540170498579178]\n",
      "\n",
      "EPOCH:\t135\n",
      "train_roc:[0.952337400530504]\n",
      "valid_roc:[0.9545337122190649]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.87:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch:115\n",
      "test_roc:[0.6868958109559614]\n",
      "test_roc_mean: 0.6868958109559614\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "# best_model = torch.load('saved_models/model_BBBP_Fri_Jul_26_21-17-57_2019_90.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_losses = eval(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
