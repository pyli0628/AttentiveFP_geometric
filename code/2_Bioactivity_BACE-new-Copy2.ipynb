{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP.featurizing import graph_dict\n",
    "from AttentiveFP.AttentiveLayers_new3 import Fingerprint, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1513\n",
      "number of successfully processed smiles:  1513\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'BACE'\n",
    "tasks = ['Class']\n",
    "raw_filename = \"../data/bace.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.mol.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"mol\"].isin(remained_smiles)]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 32\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "K = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 2 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/bace.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['mol'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "class ScaffoldGenerator(object):\n",
    "    \"\"\"\n",
    "    Generate molecular scaffolds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    include_chirality : : bool, optional (default False)\n",
    "      Include chirality in scaffolds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, include_chirality=False):\n",
    "        self.include_chirality = include_chirality\n",
    "\n",
    "    def get_scaffold(self, mol):\n",
    "        \"\"\"\n",
    "        Get Murcko scaffolds for molecules.\n",
    "\n",
    "        Murcko scaffolds are described in DOI: 10.1021/jm9602928. They are\n",
    "        essentially that part of the molecule consisting of rings and the\n",
    "        linker atoms between them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mols : array_like\n",
    "            Molecules.\n",
    "        \"\"\"\n",
    "        return MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=self.include_chirality)\n",
    "\n",
    "\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    engine = ScaffoldGenerator(include_chirality=include_chirality)\n",
    "    scaffold = engine.get_scaffold(mol)\n",
    "    return scaffold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = smiles_tasks_df[smiles_tasks_df[task] == 0][[\"mol\",task]]\n",
    "    positive_df = smiles_tasks_df[smiles_tasks_df[task] == 1][[\"mol\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "scaffold_list = []\n",
    "all_scaffolds_dict = {}\n",
    "\n",
    "for index, smiles in enumerate(smiles_tasks_df['mol']):\n",
    "    scaffold = generate_scaffold(smiles)\n",
    "    scaffold_list.append(scaffold)\n",
    "    if scaffold not in all_scaffolds_dict:\n",
    "        all_scaffolds_dict[scaffold] = [index]\n",
    "    else:\n",
    "        all_scaffolds_dict[scaffold].append(index)\n",
    "smiles_tasks_df['scaffold'] = scaffold_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaffold</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>O=C1NC=NC1(c1ccccc1)c1ccccc1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>O=S1(=O)CC(Cc2ccccc2)CC([NH2+]Cc2ccccc2)C1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>c1ccc(CCCC[NH2+]C2(c3ccccc3)CCCCC2)cc1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>c1ccc(CCCC[NH2+]C2CC3(CCC3)Oc3ncccc32)cc1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>O=C(NC(CC[NH2+]Cc1ccccc1)Cc1ccccc1)c1ccccc1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>O=C(Nc1cccc(C2CCOC=N2)c1)c1ccccn1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>O=C1NC=NC1(c1ccccc1)c1cccc(-c2cccnc2)c1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>O=C1NC=NC12CCOc1ccc(-c3ccccc3)cc12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>O=c1cc(C2CC2c2ccc(-c3ccccc3)cc2)nc[nH]1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>O=C(NC(CC[NH2+]Cc1ccccc1)Cc1ccccc1)c1c[nH]c2cc...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              scaffold  count\n",
       "440                       O=C1NC=NC1(c1ccccc1)c1ccccc1     55\n",
       "495         O=S1(=O)CC(Cc2ccccc2)CC([NH2+]Cc2ccccc2)C1     53\n",
       "613             c1ccc(CCCC[NH2+]C2(c3ccccc3)CCCCC2)cc1     41\n",
       "634          c1ccc(CCCC[NH2+]C2CC3(CCC3)Oc3ncccc32)cc1     31\n",
       "246        O=C(NC(CC[NH2+]Cc1ccccc1)Cc1ccccc1)c1ccccc1     26\n",
       "345                  O=C(Nc1cccc(C2CCOC=N2)c1)c1ccccn1     26\n",
       "434            O=C1NC=NC1(c1ccccc1)c1cccc(-c2cccnc2)c1     22\n",
       "456                 O=C1NC=NC12CCOc1ccc(-c3ccccc3)cc12     19\n",
       "522            O=c1cc(C2CC2c2ccc(-c3ccccc3)cc2)nc[nH]1     17\n",
       "212  O=C(NC(CC[NH2+]Cc1ccccc1)Cc1ccccc1)c1c[nH]c2cc...     16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_tasks_df.groupby(['scaffold'])['scaffold'].count() \\\n",
    "                     .reset_index(name='count') \\\n",
    "                     .sort_values(['count'], ascending=False) \\\n",
    "                     .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/erikxiong/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 146 65 [63, 468, 770, 1005, 107, 927, 463, 684, 711, 742, 959, 132, 46, 854, 1224, 1279, 692, 708, 763, 864, 993, 713, 198, 167, 1440, 706, 1278, 695, 404, 202, 1, 249, 273, 300, 310, 433, 454, 491, 506, 518, 592, 997, 1363, 1365, 1408, 1419, 850, 1014, 1252, 86, 7, 611, 1029, 124, 286, 1264, 52, 113, 175, 157, 24, 40, 525, 561, 983, 1304, 1082, 461, 462, 1063, 44, 309, 344, 543, 845, 573, 727, 1194, 1093, 1110, 281, 305, 316, 353, 365, 390, 418, 438, 504, 524, 530, 908, 1077, 1234, 1396, 1397, 1400, 1406, 1415, 1476, 1494, 1202, 1240, 1255, 1290, 1361, 1284, 1336, 599, 13, 43, 342, 372, 393, 394, 445, 467, 821, 878, 937, 1117, 1283, 904, 1491, 1174, 994, 1227, 1402, 1485, 1473, 1355, 1444, 1479, 1100, 1193, 955, 839, 903, 1324, 1325, 1169, 36, 1490, 1509, 228, 102]\n",
      "90 152 69 [339, 129, 1149, 1219, 1469, 1504, 735, 890, 1166, 1142, 1481, 1498, 709, 1256, 523, 1237, 542, 764, 928, 105, 723, 1391, 1405, 1417, 1420, 201, 59, 961, 942, 1165, 151, 1109, 1296, 1307, 184, 1386, 1395, 1337, 1478, 272, 348, 406, 78, 130, 810, 960, 1243, 108, 146, 712, 920, 925, 945, 989, 1067, 1436, 33, 270, 431, 533, 591, 171, 1274, 626, 932, 1412, 1413, 360, 173, 147, 1061, 11, 5, 14, 335, 347, 387, 388, 405, 413, 448, 587, 752, 892, 1004, 118, 1383, 1463, 473, 478, 479, 495, 225, 37, 39, 48, 53, 60, 68, 76, 77, 79, 90, 111, 126, 140, 441, 527, 528, 582, 608, 630, 668, 678, 704, 760, 798, 836, 931, 1398, 1421, 1428, 1091, 92, 1213, 767, 822, 1465, 546, 255, 740, 1101, 761, 1348, 1464, 1060, 1260, 1351, 81, 815, 884, 1206, 1250, 852, 1433, 1259, 1075, 516, 322, 412, 520, 534]\n"
     ]
    }
   ],
   "source": [
    "def scaffold_randomized_spliting(scaffolds_dict, sample_size, random_seed = 0): \n",
    "    count = 0\n",
    "    minor_count = 0\n",
    "    minor_class = np.argmax(weights[0]) # weights are inverse of the ratio\n",
    "    minor_ratio= 1/weights[0][minor_class]\n",
    "    optimal_count = 0.1*len(smiles_tasks_df)\n",
    "    while (count < optimal_count*0.9 or  count > optimal_count*1.1) \\\n",
    "        or (minor_count < minor_ratio*optimal_count*0.9 \\\n",
    "            or  minor_count > minor_ratio*optimal_count*1.1):\n",
    "        random_seed +=1\n",
    "        random.seed(random_seed)\n",
    "        scaffold = random.sample(list(scaffolds_dict.keys()), sample_size)\n",
    "        count = sum([len(scaffolds_dict[scaffold]) for scaffold in scaffold])\n",
    "        index = [index for scaffold in scaffold for index in scaffolds_dict[scaffold]]\n",
    "        minor_count = len(smiles_tasks_df.iloc[index, :][smiles_tasks_df[tasks[0]] == minor_class])\n",
    "#     print(random)\n",
    "    print(random_seed, count, minor_count, index)\n",
    "    return scaffold, index\n",
    "\n",
    "samples_size = int(len(all_scaffolds_dict.keys())*0.1)\n",
    "print(samples_size)\n",
    "test_scaffold, test_index = scaffold_randomized_spliting(all_scaffolds_dict, samples_size, random_seed=88)\n",
    "training_scaffolds_dict = {x: all_scaffolds_dict[x] for x in all_scaffolds_dict.keys() if x not in test_scaffold}\n",
    "valid_scaffold, valid_index = scaffold_randomized_spliting(training_scaffolds_dict, samples_size, random_seed=88)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = smiles_tasks_df.iloc[test_index,:] # test set\n",
    "valid_df = smiles_tasks_df.iloc[valid_index,:] # valid set\n",
    "train_df = smiles_tasks_df.drop(test_df.index).drop(valid_df.index) # train set\n",
    "test_smiles = test_df.mol.values\n",
    "valid_smiles = valid_df.mol.values\n",
    "train_smiles = train_df.mol.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76998\n",
      "preprocess.0.linear.weight torch.Size([32, 39])\n",
      "preprocess.0.linear.bias torch.Size([32])\n",
      "preprocess.0.bn.weight torch.Size([32])\n",
      "preprocess.0.bn.bias torch.Size([32])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.0.align.weight torch.Size([1, 64])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.0.attend.linear.bias torch.Size([32])\n",
      "propagate.0.attend.bn.weight torch.Size([32])\n",
      "propagate.0.attend.bn.bias torch.Size([32])\n",
      "propagate.0.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.0.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.0.gru.bias_ih torch.Size([96])\n",
      "propagate.0.gru.bias_hh torch.Size([96])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.1.align.weight torch.Size([1, 64])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.1.attend.linear.bias torch.Size([32])\n",
      "propagate.1.attend.bn.weight torch.Size([32])\n",
      "propagate.1.attend.bn.bias torch.Size([32])\n",
      "propagate.1.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.1.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.1.gru.bias_ih torch.Size([96])\n",
      "propagate.1.gru.bias_hh torch.Size([96])\n",
      "superGather.0.align.weight torch.Size([1, 64])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.0.attend.linear.bias torch.Size([32])\n",
      "superGather.0.attend.bn.weight torch.Size([32])\n",
      "superGather.0.attend.bn.bias torch.Size([32])\n",
      "superGather.0.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.0.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.0.gru.bias_ih torch.Size([96])\n",
      "superGather.0.gru.bias_hh torch.Size([96])\n",
      "superGather.1.align.weight torch.Size([1, 64])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.1.attend.linear.bias torch.Size([32])\n",
      "superGather.1.attend.bn.weight torch.Size([32])\n",
      "superGather.1.attend.bn.bias torch.Size([32])\n",
      "superGather.1.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.1.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.1.gru.bias_ih torch.Size([96])\n",
      "superGather.1.gru.bias_hh torch.Size([96])\n",
      "predict.0.linear.weight torch.Size([512, 32])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([2, 512])\n",
      "predict.3.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED),drop_last=True)\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            \n",
    "            validInds = np.where((label==0) | (label==1))[0]\n",
    "#             validInds = np.where(label != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            label_adjust = np.array([label[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(label_adjust))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(model, smiles_list):\n",
    "    model.eval()\n",
    "    label_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "\n",
    "            validInds = np.where((label==0) | (label==1))[0]\n",
    "#             validInds = np.where((label=='0') | (label=='1'))[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            label_adjust = np.array([label[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(label_adjust))\n",
    "            \n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                label_list[i].extend(label_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                label_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                label_list[i].extend(label_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                \n",
    "    eval_roc = [roc_auc_score(label_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "#     eval_prc = [auc(precision_recall_curve(label_list[i], y_pred_list[i])[1],precision_recall_curve(label_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     eval_precision = [precision_score(label_list[i],\n",
    "#                                      (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "#     eval_recall = [recall_score(label_list[i],\n",
    "#                                (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    eval_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return eval_roc, eval_loss #eval_prc, eval_precision, eval_recall, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | losses | train loss | valid loss | train roc |  valid roc |   time  |\n",
      "  0   | 0.6361 |   0.6125   |   0.7338   |  0.7263   |  0.6756   |  0 hr 00 min |\n",
      "  1   | 0.5483 |   0.5424   |   0.5870   |  0.8001   |  0.7831   |  0 hr 00 min |\n",
      "  2   | 0.5111 |   0.4826   |   0.6585   |  0.8580   |  0.7725   |  0 hr 00 min |\n",
      "  3   | 0.5266 |   0.4394   |   0.4863   |  0.8748   |  0.8545   |  0 hr 00 min |\n",
      "  4   | 0.4881 |   0.7525   |   0.6254   |  0.8502   |  0.7938   |  0 hr 00 min |\n",
      "  5   | 0.4916 |   0.4723   |   0.6997   |  0.8537   |  0.8130   |  0 hr 00 min |\n",
      "  6   | 0.4556 |   0.3884   |   0.5988   |  0.9052   |  0.8633   |  0 hr 00 min |\n",
      "  7   | 0.4623 |   0.3792   |   0.7067   |  0.9109   |  0.8388   |  0 hr 00 min |\n",
      "  8   | 0.4313 |   0.3994   |   0.5146   |  0.9087   |  0.8703   |  0 hr 00 min |\n",
      "  9   | 0.4211 |   0.4238   |   0.6082   |  0.9018   |  0.8933   |  0 hr 00 min |\n",
      " 10   | 0.4191 |   0.3520   |   0.7417   |  0.9167   |  0.8425   |  0 hr 00 min |\n",
      " 11   | 0.4009 |   0.4024   |   0.7473   |  0.9252   |  0.8112   |  0 hr 01 min |\n",
      " 12   | 0.3702 |   0.3190   |   0.6485   |  0.9380   |  0.8497   |  0 hr 01 min |\n",
      " 13   | 0.3563 |   0.3846   |   0.4995   |  0.9270   |  0.8942   |  0 hr 01 min |\n",
      " 14   | 0.3601 |   0.3306   |   0.7077   |  0.9303   |  0.8020   |  0 hr 01 min |\n",
      " 15   | 0.3617 |   0.3530   |   0.6306   |  0.9414   |  0.8023   |  0 hr 01 min |\n",
      " 16   | 0.3574 |   0.2739   |   0.7014   |  0.9554   |  0.8601   |  0 hr 01 min |\n",
      " 17   | 0.3354 |   0.3861   |   1.0260   |  0.9248   |  0.7603   |  0 hr 01 min |\n",
      " 18   | 0.3657 |   0.2846   |   0.7056   |  0.9549   |  0.8869   |  0 hr 01 min |\n",
      " 19   | 0.3288 |   0.3093   |   0.7470   |  0.9488   |  0.8486   |  0 hr 01 min |\n",
      " 20   | 0.3107 |   0.2363   |   0.7852   |  0.9653   |  0.8636   |  0 hr 01 min |\n",
      " 21   | 0.3154 |   0.2889   |   0.8619   |  0.9541   |  0.8226   |  0 hr 01 min |\n",
      " 22   | 0.3162 |   0.2495   |   0.6789   |  0.9650   |  0.9174   |  0 hr 01 min |\n",
      " 23   | 0.3057 |   0.3432   |   1.1873   |  0.9435   |  0.8144   |  0 hr 01 min |\n",
      " 24   | 0.3143 |   0.2662   |   0.7274   |  0.9581   |  0.8795   |  0 hr 02 min |\n",
      " 25   | 0.3080 |   0.2618   |   1.4935   |  0.9627   |  0.8212   |  0 hr 02 min |\n",
      " 26   | 0.3123 |   0.2297   |   0.6972   |  0.9670   |  0.8619   |  0 hr 02 min |\n",
      " 27   | 0.2728 |   0.2506   |   0.8821   |  0.9612   |  0.8865   |  0 hr 02 min |\n",
      " 28   | 0.3052 |   0.2518   |   0.4453   |  0.9590   |  0.8736   |  0 hr 02 min |\n",
      " 29   | 0.2672 |   0.2026   |   0.9221   |  0.9749   |  0.8692   |  0 hr 02 min |\n",
      " 30   | 0.2857 |   0.2380   |   0.7097   |  0.9711   |  0.9029   |  0 hr 02 min |\n",
      " 31   | 0.2806 |   0.3171   |   0.8362   |  0.9502   |  0.8268   |  0 hr 02 min |\n",
      " 32   | 0.2812 |   0.2722   |   0.5547   |  0.9704   |  0.8692   |  0 hr 02 min |\n",
      " 33   | 0.2624 |   0.2069   |   0.6104   |  0.9738   |  0.8668   |  0 hr 02 min |\n",
      " 34   | 0.2527 |   0.1871   |   0.5948   |  0.9799   |  0.8902   |  0 hr 02 min |\n",
      " 35   | 0.2580 |   0.1969   |   0.8438   |  0.9748   |  0.8725   |  0 hr 02 min |\n",
      " 36   | 0.2660 |   0.1926   |   0.6874   |  0.9811   |  0.8804   |  0 hr 03 min |\n",
      " 37   | 0.2563 |   0.1902   |   0.8429   |  0.9776   |  0.9099   |  0 hr 03 min |\n",
      " 38   | 0.2557 |   0.1952   |   0.4089   |  0.9785   |  0.8828   |  0 hr 03 min |\n",
      " 39   | 0.2586 |   0.2078   |   0.7392   |  0.9754   |  0.8989   |  0 hr 03 min |\n",
      " 40   | 0.2479 |   0.2393   |   0.5445   |  0.9767   |  0.8638   |  0 hr 03 min |\n",
      " 41   | 0.2670 |   0.1954   |   0.4242   |  0.9783   |  0.9153   |  0 hr 03 min |\n",
      " 42   | 0.2382 |   0.1652   |   1.0524   |  0.9852   |  0.8729   |  0 hr 03 min |\n",
      " 43   | 0.2250 |   0.1984   |   1.1607   |  0.9754   |  0.8919   |  0 hr 03 min |\n",
      " 44   | 0.2334 |   0.2122   |   0.7569   |  0.9805   |  0.8495   |  0 hr 03 min |\n",
      " 45   | 0.2307 |   0.2187   |   0.9641   |  0.9710   |  0.8545   |  0 hr 03 min |\n",
      " 46   | 0.2304 |   0.1675   |   1.1801   |  0.9836   |  0.8544   |  0 hr 03 min |\n",
      " 47   | 0.2084 |   0.1403   |   0.8312   |  0.9891   |  0.8837   |  0 hr 03 min |\n",
      " 48   | 0.2272 |   0.1512   |   1.5132   |  0.9860   |  0.8757   |  0 hr 03 min |\n",
      " 49   | 0.2092 |   0.1629   |   1.6166   |  0.9860   |  0.8023   |  0 hr 04 min |\n",
      " 50   | 0.2005 |   0.1821   |   1.9185   |  0.9863   |  0.8594   |  0 hr 04 min |\n",
      " 51   | 0.2449 |   0.1595   |   1.0106   |  0.9852   |  0.8554   |  0 hr 04 min |\n",
      " 52   | 0.2129 |   0.1867   |   1.6074   |  0.9822   |  0.8497   |  0 hr 04 min |\n",
      " 53   | 0.1858 |   0.1861   |   0.8910   |  0.9814   |  0.8552   |  0 hr 04 min |\n",
      " 54   | 0.1893 |   0.1335   |   2.6246   |  0.9896   |  0.8359   |  0 hr 04 min |\n",
      " 55   | 0.2015 |   0.1559   |   1.1398   |  0.9917   |  0.8673   |  0 hr 04 min |\n",
      " 56   | 0.2021 |   0.1352   |   0.9879   |  0.9908   |  0.8650   |  0 hr 04 min |\n",
      " 57   | 0.1812 |   0.1329   |   1.3614   |  0.9891   |  0.8535   |  0 hr 04 min |\n",
      "22 38 0.9174087654967698\n"
     ]
    }
   ],
   "source": [
    "log = Logger()\n",
    "log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^6.4f} | {:^10.4f} | {:^10.4f} | {:^9.4f} | {:^9.4f} | {:^10} |\\n'\n",
    "log.write('epoch | losses | train loss | valid loss | train roc |  valid roc |   time  |\\n')\n",
    "start = timer()\n",
    "\n",
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    losses = train(model, train_smiles)\n",
    "    train_roc, train_loss = eval(model, train_smiles)\n",
    "    valid_roc, valid_loss = eval(model, valid_smiles)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "    timing = time_to_str((timer() - start), 'min')  \n",
    "    log.write(f.format(epoch, losses, train_loss, valid_loss, train_roc_mean, valid_roc_mean, timing))\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.87:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    if (epoch - best_param[\"roc_epoch\"] >8) and (epoch - best_param[\"loss_epoch\"] >18):        \n",
    "        break\n",
    "        \n",
    "print(best_param[\"roc_epoch\"],best_param[\"loss_epoch\"],best_param[\"valid_roc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch:22\n",
      "test_roc:[0.8339981006647673]\n",
      "test_roc_mean: 0.8339981006647673\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_losses = eval(best_model, test_smiles)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
