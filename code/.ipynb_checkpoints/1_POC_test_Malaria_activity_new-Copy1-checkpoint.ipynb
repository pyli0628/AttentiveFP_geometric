{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP.featurizing import graph_dict\n",
    "from AttentiveFP.AttentiveLayers_new3 import Fingerprint, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  9999\n",
      "number of successfully processed smiles:  9999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'Malaria Bioactivity'\n",
    "tasks = ['Loge EC50']\n",
    "\n",
    "raw_filename = \"../data/malaria-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename, names = [\"Loge EC50\", \"smiles\"])\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 32\n",
    "\n",
    "weight_decay = 6 # also known as l2_regularization_lambda\n",
    "learning_rate = 3\n",
    "K = 3\n",
    "T = 3\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/malaria-processed.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  50\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "    \n",
    "while (len(train_fold[0]) % batch_size) / batch_size <0.8:\n",
    "    batch_size +=1\n",
    "print(\"batch size: \", batch_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104839\n",
      "preprocess.0.linear.weight torch.Size([32, 39])\n",
      "preprocess.0.linear.bias torch.Size([32])\n",
      "preprocess.0.bn.weight torch.Size([32])\n",
      "preprocess.0.bn.bias torch.Size([32])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.0.align.weight torch.Size([1, 64])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.0.attend.linear.bias torch.Size([32])\n",
      "propagate.0.attend.bn.weight torch.Size([32])\n",
      "propagate.0.attend.bn.bias torch.Size([32])\n",
      "propagate.0.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.0.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.0.gru.bias_ih torch.Size([96])\n",
      "propagate.0.gru.bias_hh torch.Size([96])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.1.align.weight torch.Size([1, 64])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.1.attend.linear.bias torch.Size([32])\n",
      "propagate.1.attend.bn.weight torch.Size([32])\n",
      "propagate.1.attend.bn.bias torch.Size([32])\n",
      "propagate.1.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.1.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.1.gru.bias_ih torch.Size([96])\n",
      "propagate.1.gru.bias_hh torch.Size([96])\n",
      "propagate.2.encoder.0.linear.weight torch.Size([1024, 10])\n",
      "propagate.2.encoder.0.linear.bias torch.Size([1024])\n",
      "propagate.2.encoder.0.bn.weight torch.Size([1024])\n",
      "propagate.2.encoder.0.bn.bias torch.Size([1024])\n",
      "propagate.2.align.weight torch.Size([1, 64])\n",
      "propagate.2.align.bias torch.Size([1])\n",
      "propagate.2.attend.linear.weight torch.Size([32, 32])\n",
      "propagate.2.attend.linear.bias torch.Size([32])\n",
      "propagate.2.attend.bn.weight torch.Size([32])\n",
      "propagate.2.attend.bn.bias torch.Size([32])\n",
      "propagate.2.gru.weight_ih torch.Size([96, 32])\n",
      "propagate.2.gru.weight_hh torch.Size([96, 32])\n",
      "propagate.2.gru.bias_ih torch.Size([96])\n",
      "propagate.2.gru.bias_hh torch.Size([96])\n",
      "superGather.0.align.weight torch.Size([1, 64])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.0.attend.linear.bias torch.Size([32])\n",
      "superGather.0.attend.bn.weight torch.Size([32])\n",
      "superGather.0.attend.bn.bias torch.Size([32])\n",
      "superGather.0.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.0.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.0.gru.bias_ih torch.Size([96])\n",
      "superGather.0.gru.bias_hh torch.Size([96])\n",
      "superGather.1.align.weight torch.Size([1, 64])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.1.attend.linear.bias torch.Size([32])\n",
      "superGather.1.attend.bn.weight torch.Size([32])\n",
      "superGather.1.attend.bn.bias torch.Size([32])\n",
      "superGather.1.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.1.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.1.gru.bias_ih torch.Size([96])\n",
      "superGather.1.gru.bias_hh torch.Size([96])\n",
      "superGather.2.align.weight torch.Size([1, 64])\n",
      "superGather.2.align.bias torch.Size([1])\n",
      "superGather.2.attend.linear.weight torch.Size([32, 32])\n",
      "superGather.2.attend.linear.bias torch.Size([32])\n",
      "superGather.2.attend.bn.weight torch.Size([32])\n",
      "superGather.2.attend.bn.bias torch.Size([32])\n",
      "superGather.2.gru.weight_ih torch.Size([96, 32])\n",
      "superGather.2.gru.weight_hh torch.Size([96, 32])\n",
      "superGather.2.gru.bias_ih torch.Size([96])\n",
      "superGather.2.gru.bias_hh torch.Size([96])\n",
      "predict.0.linear.weight torch.Size([512, 32])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([1, 512])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = Logger()\n",
    "# log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "# f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "# log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "# start = timer()\n",
    "\n",
    "# best_param ={}\n",
    "# best_param[\"train_epoch\"] = 0\n",
    "# best_param[\"valid_epoch\"] = 0\n",
    "# best_param[\"train_MSE\"] = 9e8\n",
    "# best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "# fold_index = 0\n",
    "# for epoch in range(800):\n",
    "#     losses = train(smiles_list[train_fold[fold_index]])\n",
    "#     traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "#     valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "\n",
    "#     timing = time_to_str((timer() - start), 'min')  \n",
    "#     log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "\n",
    "#     if train_MSE < best_param[\"train_MSE\"]:\n",
    "#         best_param[\"train_epoch\"] = epoch\n",
    "#         best_param[\"train_MSE\"] = train_MSE\n",
    "#     if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "#         best_param[\"valid_epoch\"] = epoch\n",
    "#         best_param[\"valid_MSE\"] = valid_MSE\n",
    "# #         if valid_MSE < 0.35:\n",
    "# #              torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "#     if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "#         break\n",
    "# print(best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train MSE |  valid MSE |  time \n",
      "  0   | 1.3391  | 1.2643  | 1.3725  |  0 hr 00 min \n",
      "  1   | 1.2640  | 1.1976  | 1.3040  |  0 hr 00 min \n",
      "  2   | 1.2234  | 1.1331  | 1.2852  |  0 hr 00 min \n",
      "  3   | 1.1886  | 1.1840  | 1.3374  |  0 hr 00 min \n",
      "  4   | 1.1638  | 1.1089  | 1.2777  |  0 hr 01 min \n",
      "  5   | 1.1543  | 1.1391  | 1.2718  |  0 hr 01 min \n",
      "  6   | 1.1404  | 1.0929  | 1.2566  |  0 hr 01 min \n",
      "  7   | 1.1113  | 1.1050  | 1.2745  |  0 hr 01 min \n",
      "  8   | 1.0904  | 1.0892  | 1.2602  |  0 hr 01 min \n",
      "  9   | 1.0791  | 0.9996  | 1.2332  |  0 hr 02 min \n",
      " 10   | 1.0695  | 0.9806  | 1.2325  |  0 hr 02 min \n",
      " 11   | 1.0581  | 0.9827  | 1.1775  |  0 hr 02 min \n",
      " 12   | 1.0309  | 0.9449  | 1.1601  |  0 hr 02 min \n",
      " 13   | 1.0214  | 0.9380  | 1.1789  |  0 hr 03 min \n",
      " 14   | 0.9978  | 0.9170  | 1.2180  |  0 hr 03 min \n",
      " 15   | 0.9906  | 0.8943  | 1.1588  |  0 hr 03 min \n",
      " 16   | 0.9829  | 0.8706  | 1.1448  |  0 hr 03 min \n",
      " 17   | 0.9719  | 0.8840  | 1.1654  |  0 hr 03 min \n",
      " 18   | 0.9365  | 0.8791  | 1.1804  |  0 hr 04 min \n",
      " 19   | 0.9458  | 0.8333  | 1.1315  |  0 hr 04 min \n",
      " 20   | 0.9238  | 0.8211  | 1.1788  |  0 hr 04 min \n",
      " 21   | 0.8970  | 0.7909  | 1.1488  |  0 hr 04 min \n",
      " 22   | 0.8883  | 0.8125  | 1.1847  |  0 hr 04 min \n",
      " 23   | 0.8943  | 0.7695  | 1.1867  |  0 hr 05 min \n",
      " 24   | 0.8692  | 0.8259  | 1.2094  |  0 hr 05 min \n",
      " 25   | 0.8729  | 0.7478  | 1.1833  |  0 hr 05 min \n",
      " 26   | 0.8439  | 0.7303  | 1.1732  |  0 hr 05 min \n",
      " 27   | 0.8246  | 0.7008  | 1.1601  |  0 hr 05 min \n",
      " 28   | 0.8138  | 0.6786  | 1.1507  |  0 hr 06 min \n",
      " 29   | 0.7921  | 0.6934  | 1.1993  |  0 hr 06 min \n",
      " 30   | 0.7858  | 0.6401  | 1.2212  |  0 hr 06 min \n",
      " 31   | 0.7632  | 0.6468  | 1.1987  |  0 hr 06 min \n",
      " 32   | 0.7666  | 0.6353  | 1.2159  |  0 hr 06 min \n",
      " 33   | 0.7491  | 0.6283  | 1.2423  |  0 hr 07 min \n",
      " 34   | 0.7479  | 0.6181  | 1.2183  |  0 hr 07 min \n",
      " 35   | 0.7317  | 0.6040  | 1.1810  |  0 hr 07 min \n",
      " 36   | 0.6978  | 0.5673  | 1.2093  |  0 hr 07 min \n",
      " 37   | 0.6993  | 0.5705  | 1.1959  |  0 hr 08 min \n",
      " 38   | 0.7007  | 0.5763  | 1.2181  |  0 hr 08 min \n",
      " 39   | 0.6833  | 0.5598  | 1.2126  |  0 hr 08 min \n",
      " 40   | 0.6578  | 0.5553  | 1.1788  |  0 hr 08 min \n",
      " 41   | 0.6603  | 0.5083  | 1.2128  |  0 hr 08 min \n",
      " 42   | 0.6472  | 0.5008  | 1.1994  |  0 hr 09 min \n",
      " 43   | 0.6464  | 0.5195  | 1.2150  |  0 hr 09 min \n",
      " 44   | 0.6354  | 0.5070  | 1.2348  |  0 hr 09 min \n",
      " 45   | 0.6128  | 0.4887  | 1.2860  |  0 hr 09 min \n",
      " 46   | 0.6137  | 0.4915  | 1.2933  |  0 hr 09 min \n",
      " 47   | 0.5942  | 0.4553  | 1.2381  |  0 hr 10 min \n",
      " 48   | 0.6014  | 0.4647  | 1.2098  |  0 hr 10 min \n",
      " 49   | 0.5916  | 0.4364  | 1.2402  |  0 hr 10 min \n",
      " 50   | 0.5688  | 0.4326  | 1.2302  |  0 hr 10 min \n",
      " 51   | 0.5650  | 0.4249  | 1.2086  |  0 hr 10 min \n",
      " 52   | 0.5705  | 0.4648  | 1.1913  |  0 hr 11 min \n",
      " 53   | 0.5712  | 0.4367  | 1.2780  |  0 hr 11 min \n",
      " 54   | 0.5395  | 0.4066  | 1.2539  |  0 hr 11 min \n",
      " 55   | 0.5470  | 0.3985  | 1.2505  |  0 hr 11 min \n",
      " 56   | 0.5146  | 0.4027  | 1.2091  |  0 hr 11 min \n",
      " 57   | 0.5282  | 0.3694  | 1.2650  |  0 hr 12 min \n",
      " 58   | 0.5085  | 0.3795  | 1.3067  |  0 hr 12 min \n",
      " 59   | 0.5101  | 0.3812  | 1.2987  |  0 hr 12 min \n",
      " 60   | 0.4906  | 0.3918  | 1.2519  |  0 hr 12 min \n",
      " 61   | 0.5007  | 0.3678  | 1.3310  |  0 hr 12 min \n",
      " 62   | 0.5053  | 0.3557  | 1.2119  |  0 hr 13 min \n",
      " 63   | 0.4835  | 0.3668  | 1.2834  |  0 hr 13 min \n",
      " 64   | 0.4767  | 0.3382  | 1.2263  |  0 hr 13 min \n",
      " 65   | 0.4838  | 0.3544  | 1.1844  |  0 hr 13 min \n",
      " 66   | 0.4739  | 0.3207  | 1.2399  |  0 hr 13 min \n",
      " 67   | 0.4701  | 0.3411  | 1.2883  |  0 hr 14 min \n",
      " 68   | 0.4655  | 0.3283  | 1.2583  |  0 hr 14 min \n",
      " 69   | 0.4622  | 0.3182  | 1.2307  |  0 hr 14 min \n",
      " 70   | 0.4627  | 0.3127  | 1.2273  |  0 hr 14 min \n",
      " 71   | 0.4567  | 0.3086  | 1.2867  |  0 hr 14 min \n",
      " 72   | 0.4285  | 0.3008  | 1.2726  |  0 hr 15 min \n",
      " 73   | 0.4418  | 0.3002  | 1.2499  |  0 hr 15 min \n",
      " 74   | 0.4319  | 0.3142  | 1.2719  |  0 hr 15 min \n",
      " 75   | 0.4222  | 0.3030  | 1.2492  |  0 hr 15 min \n",
      " 76   | 0.4240  | 0.2898  | 1.2456  |  0 hr 15 min \n",
      " 77   | 0.4162  | 0.2849  | 1.2337  |  0 hr 16 min \n",
      " 78   | 0.4149  | 0.2778  | 1.2757  |  0 hr 16 min \n",
      " 79   | 0.4186  | 0.2737  | 1.2740  |  0 hr 16 min \n",
      " 80   | 0.4146  | 0.2644  | 1.2801  |  0 hr 16 min \n",
      " 81   | 0.4050  | 0.2679  | 1.2312  |  0 hr 16 min \n",
      " 82   | 0.4028  | 0.2865  | 1.2765  |  0 hr 17 min \n",
      " 83   | 0.3997  | 0.2719  | 1.3315  |  0 hr 17 min \n",
      " 84   | 0.3987  | 0.2799  | 1.2397  |  0 hr 17 min \n",
      " 85   | 0.3928  | 0.2658  | 1.2506  |  0 hr 17 min \n",
      " 86   | 0.3916  | 0.2620  | 1.2871  |  0 hr 17 min \n",
      " 87   | 0.4085  | 0.2637  | 1.2638  |  0 hr 18 min \n",
      " 88   | 0.3916  | 0.2545  | 1.3019  |  0 hr 18 min \n",
      " 89   | 0.3771  | 0.2517  | 1.2376  |  0 hr 18 min \n",
      " 90   | 0.3705  | 0.2381  | 1.2924  |  0 hr 18 min \n",
      " 91   | 0.3692  | 0.2465  | 1.2746  |  0 hr 18 min \n",
      " 92   | 0.3597  | 0.2514  | 1.2719  |  0 hr 19 min \n",
      " 93   | 0.3697  | 0.2368  | 1.2792  |  0 hr 19 min \n",
      " 94   | 0.3759  | 0.2399  | 1.3123  |  0 hr 19 min \n",
      " 95   | 0.3536  | 0.2359  | 1.2484  |  0 hr 19 min \n",
      " 96   | 0.3591  | 0.2407  | 1.2802  |  0 hr 20 min \n",
      " 97   | 0.3567  | 0.2300  | 1.2508  |  0 hr 20 min \n",
      " 98   | 0.3648  | 0.2252  | 1.2631  |  0 hr 20 min \n",
      " 99   | 0.3609  | 0.2166  | 1.2838  |  0 hr 20 min \n",
      " 100  | 0.3436  | 0.2460  | 1.2832  |  0 hr 20 min \n",
      " 101  | 0.3430  | 0.2186  | 1.2662  |  0 hr 21 min \n",
      " 102  | 0.3339  | 0.2100  | 1.2334  |  0 hr 21 min \n",
      " 103  | 0.3434  | 0.2200  | 1.3226  |  0 hr 21 min \n",
      " 104  | 0.3389  | 0.2056  | 1.2824  |  0 hr 21 min \n",
      " 105  | 0.3261  | 0.2205  | 1.2941  |  0 hr 21 min \n",
      " 106  | 0.3376  | 0.2235  | 1.3444  |  0 hr 22 min \n",
      " 107  | 0.3158  | 0.1973  | 1.2724  |  0 hr 22 min \n",
      " 108  | 0.3164  | 0.2069  | 1.2876  |  0 hr 22 min \n",
      " 109  | 0.3234  | 0.1992  | 1.2653  |  0 hr 22 min \n",
      " 110  | 0.3253  | 0.1978  | 1.2797  |  0 hr 23 min \n",
      " 111  | 0.3247  | 0.1889  | 1.2460  |  0 hr 23 min \n",
      " 112  | 0.3142  | 0.2068  | 1.2935  |  0 hr 23 min \n",
      " 113  | 0.3159  | 0.2011  | 1.2523  |  0 hr 23 min \n",
      " 114  | 0.3148  | 0.1956  | 1.2713  |  0 hr 23 min \n",
      " 115  | 0.3162  | 0.1965  | 1.2706  |  0 hr 24 min \n",
      " 116  | 0.3090  | 0.1954  | 1.2757  |  0 hr 24 min \n",
      " 117  | 0.3071  | 0.1768  | 1.2574  |  0 hr 24 min \n",
      " 118  | 0.2992  | 0.1738  | 1.2845  |  0 hr 24 min \n",
      " 119  | 0.3017  | 0.1911  | 1.3023  |  0 hr 25 min \n",
      " 120  | 0.2999  | 0.1839  | 1.3076  |  0 hr 25 min \n",
      " 121  | 0.3123  | 0.1712  | 1.2524  |  0 hr 25 min \n",
      " 122  | 0.2948  | 0.1897  | 1.3149  |  0 hr 25 min \n",
      " 123  | 0.3036  | 0.1796  | 1.3110  |  0 hr 25 min \n",
      " 124  | 0.2868  | 0.1933  | 1.3220  |  0 hr 26 min \n",
      " 125  | 0.2974  | 0.1718  | 1.2768  |  0 hr 26 min \n",
      " 126  | 0.2999  | 0.1706  | 1.2961  |  0 hr 26 min \n",
      " 127  | 0.2792  | 0.1624  | 1.2691  |  0 hr 26 min \n",
      " 128  | 0.2940  | 0.1984  | 1.2662  |  0 hr 27 min \n",
      " 129  | 0.3035  | 0.1867  | 1.3128  |  0 hr 27 min \n",
      " 130  | 0.2866  | 0.1814  | 1.2750  |  0 hr 27 min \n",
      " 131  | 0.2786  | 0.1627  | 1.2854  |  0 hr 27 min \n",
      " 132  | 0.2800  | 0.1666  | 1.2668  |  0 hr 27 min \n",
      " 133  | 0.2698  | 0.1740  | 1.3059  |  0 hr 28 min \n",
      " 134  | 0.2815  | 0.1708  | 1.2989  |  0 hr 28 min \n",
      " 135  | 0.2777  | 0.1655  | 1.2768  |  0 hr 28 min \n",
      " 136  | 0.2772  | 0.1696  | 1.2687  |  0 hr 28 min \n",
      " 137  | 0.2721  | 0.1564  | 1.2854  |  0 hr 29 min \n",
      " 138  | 0.2823  | 0.1633  | 1.2696  |  0 hr 29 min \n",
      " 139  | 0.2599  | 0.1538  | 1.2825  |  0 hr 29 min \n",
      " 140  | 0.2735  | 0.1576  | 1.2863  |  0 hr 29 min \n",
      " 141  | 0.2809  | 0.1611  | 1.2655  |  0 hr 29 min \n",
      " 142  | 0.2736  | 0.1499  | 1.2719  |  0 hr 30 min \n",
      " 143  | 0.2625  | 0.1475  | 1.3151  |  0 hr 30 min \n",
      " 144  | 0.2663  | 0.1489  | 1.2593  |  0 hr 30 min \n",
      " 145  | 0.2578  | 0.1670  | 1.3063  |  0 hr 30 min \n",
      " 146  | 0.2714  | 0.1507  | 1.2833  |  0 hr 30 min \n",
      " 147  | 0.2633  | 0.1487  | 1.2435  |  0 hr 31 min \n",
      " 148  | 0.2624  | 0.1483  | 1.2742  |  0 hr 31 min \n",
      " 149  | 0.2583  | 0.1435  | 1.3090  |  0 hr 31 min \n",
      " 150  | 0.2623  | 0.1401  | 1.3006  |  0 hr 31 min \n",
      " 151  | 0.2529  | 0.1413  | 1.2683  |  0 hr 32 min \n",
      " 152  | 0.2544  | 0.1440  | 1.2478  |  0 hr 32 min \n",
      " 153  | 0.2509  | 0.1604  | 1.3253  |  0 hr 32 min \n",
      " 154  | 0.2472  | 0.1442  | 1.3265  |  0 hr 32 min \n",
      " 155  | 0.2511  | 0.1459  | 1.3231  |  0 hr 32 min \n",
      " 156  | 0.2531  | 0.1440  | 1.2620  |  0 hr 33 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 157  | 0.2545  | 0.1348  | 1.2651  |  0 hr 33 min \n",
      " 158  | 0.2584  | 0.1364  | 1.2607  |  0 hr 33 min \n",
      " 159  | 0.2420  | 0.1415  | 1.3047  |  0 hr 33 min \n",
      " 160  | 0.2303  | 0.1325  | 1.2865  |  0 hr 34 min \n",
      " 161  | 0.2535  | 0.1443  | 1.3061  |  0 hr 34 min \n",
      " 162  | 0.2435  | 0.1376  | 1.3143  |  0 hr 34 min \n",
      " 163  | 0.2411  | 0.1404  | 1.2700  |  0 hr 34 min \n",
      " 164  | 0.2350  | 0.1346  | 1.2965  |  0 hr 35 min \n",
      " 165  | 0.2430  | 0.1412  | 1.2621  |  0 hr 35 min \n",
      " 166  | 0.2385  | 0.1379  | 1.3384  |  0 hr 35 min \n",
      " 167  | 0.2414  | 0.1374  | 1.3065  |  0 hr 35 min \n",
      " 168  | 0.2445  | 0.1444  | 1.2922  |  0 hr 35 min \n",
      " 169  | 0.2381  | 0.1461  | 1.3494  |  0 hr 36 min \n",
      " 170  | 0.2362  | 0.1282  | 1.3296  |  0 hr 36 min \n",
      " 171  | 0.2340  | 0.1291  | 1.3377  |  0 hr 36 min \n",
      " 172  | 0.2245  | 0.1284  | 1.3159  |  0 hr 36 min \n",
      " 173  | 0.2341  | 0.1276  | 1.3086  |  0 hr 37 min \n",
      " 174  | 0.2321  | 0.1226  | 1.2960  |  0 hr 37 min \n",
      " 175  | 0.2308  | 0.1254  | 1.2950  |  0 hr 37 min \n",
      " 176  | 0.2306  | 0.1414  | 1.2891  |  0 hr 37 min \n",
      " 177  | 0.2346  | 0.1303  | 1.2948  |  0 hr 38 min \n",
      " 178  | 0.2293  | 0.1136  | 1.2657  |  0 hr 38 min \n",
      " 179  | 0.2265  | 0.1436  | 1.3903  |  0 hr 38 min \n",
      " 180  | 0.2195  | 0.1231  | 1.2610  |  0 hr 38 min \n",
      " 181  | 0.2205  | 0.1172  | 1.3200  |  0 hr 38 min \n",
      " 182  | 0.2176  | 0.1174  | 1.2648  |  0 hr 39 min \n",
      " 183  | 0.2196  | 0.1225  | 1.3014  |  0 hr 39 min \n",
      " 184  | 0.2374  | 0.1408  | 1.3114  |  0 hr 39 min \n",
      " 185  | 0.2224  | 0.1139  | 1.2660  |  0 hr 39 min \n",
      " 186  | 0.2145  | 0.1141  | 1.3092  |  0 hr 40 min \n",
      " 187  | 0.2171  | 0.1097  | 1.3120  |  0 hr 40 min \n",
      " 188  | 0.2221  | 0.1259  | 1.3112  |  0 hr 40 min \n",
      " 189  | 0.2133  | 0.1244  | 1.3175  |  0 hr 40 min \n",
      " 190  | 0.2258  | 0.1278  | 1.2652  |  0 hr 41 min \n",
      " 191  | 0.2102  | 0.1228  | 1.3064  |  0 hr 41 min \n",
      " 192  | 0.2173  | 0.1073  | 1.3081  |  0 hr 41 min \n",
      " 193  | 0.2326  | 0.1425  | 1.3060  |  0 hr 41 min \n",
      " 194  | 0.2337  | 0.1288  | 1.3230  |  0 hr 41 min \n",
      " 195  | 0.2237  | 0.1217  | 1.3160  |  0 hr 42 min \n",
      " 196  | 0.2109  | 0.1072  | 1.2469  |  0 hr 42 min \n",
      " 197  | 0.2178  | 0.1134  | 1.2774  |  0 hr 42 min \n",
      " 198  | 0.2159  | 0.1068  | 1.2613  |  0 hr 42 min \n",
      " 199  | 0.2182  | 0.1201  | 1.2783  |  0 hr 43 min \n",
      " 200  | 0.2091  | 0.1210  | 1.2740  |  0 hr 43 min \n",
      " 201  | 0.2077  | 0.1279  | 1.3088  |  0 hr 43 min \n",
      " 202  | 0.2097  | 0.1300  | 1.3079  |  0 hr 43 min \n",
      " 203  | 0.2166  | 0.1179  | 1.3137  |  0 hr 43 min \n",
      " 204  | 0.2162  | 0.1154  | 1.2707  |  0 hr 44 min \n",
      " 205  | 0.2157  | 0.1117  | 1.2982  |  0 hr 44 min \n",
      " 206  | 0.2007  | 0.1014  | 1.3053  |  0 hr 44 min \n",
      " 207  | 0.2022  | 0.1227  | 1.3081  |  0 hr 44 min \n",
      " 208  | 0.2207  | 0.1038  | 1.2886  |  0 hr 45 min \n",
      " 209  | 0.2091  | 0.1085  | 1.3281  |  0 hr 45 min \n",
      " 210  | 0.2036  | 0.1063  | 1.2767  |  0 hr 45 min \n",
      " 211  | 0.1975  | 0.1005  | 1.3061  |  0 hr 45 min \n",
      " 212  | 0.2009  | 0.1135  | 1.2860  |  0 hr 45 min \n",
      " 213  | 0.2056  | 0.1184  | 1.3310  |  0 hr 46 min \n",
      " 214  | 0.2096  | 0.1100  | 1.3182  |  0 hr 46 min \n",
      " 215  | 0.2042  | 0.1188  | 1.3073  |  0 hr 46 min \n",
      " 216  | 0.2037  | 0.0993  | 1.2687  |  0 hr 46 min \n",
      " 217  | 0.2016  | 0.0972  | 1.2670  |  0 hr 46 min \n",
      " 218  | 0.1964  | 0.0977  | 1.3052  |  0 hr 47 min \n",
      " 219  | 0.1990  | 0.1004  | 1.2422  |  0 hr 47 min \n",
      " 220  | 0.1960  | 0.0926  | 1.2814  |  0 hr 47 min \n",
      " 221  | 0.2064  | 0.1048  | 1.2814  |  0 hr 47 min \n",
      " 222  | 0.2046  | 0.1106  | 1.2620  |  0 hr 48 min \n",
      " 223  | 0.1897  | 0.1027  | 1.3142  |  0 hr 48 min \n",
      " 224  | 0.1951  | 0.1189  | 1.3403  |  0 hr 48 min \n",
      " 225  | 0.2048  | 0.1032  | 1.3266  |  0 hr 48 min \n",
      " 226  | 0.2025  | 0.1119  | 1.3262  |  0 hr 48 min \n",
      " 227  | 0.1997  | 0.0968  | 1.2498  |  0 hr 49 min \n",
      " 228  | 0.1923  | 0.1100  | 1.2826  |  0 hr 49 min \n",
      " 229  | 0.1925  | 0.1031  | 1.2998  |  0 hr 49 min \n",
      " 230  | 0.1947  | 0.0988  | 1.3247  |  0 hr 49 min \n",
      " 231  | 0.1928  | 0.1036  | 1.2843  |  0 hr 49 min \n",
      " 232  | 0.1954  | 0.0924  | 1.2881  |  0 hr 50 min \n",
      " 233  | 0.1895  | 0.1040  | 1.3036  |  0 hr 50 min \n",
      " 234  | 0.1940  | 0.1064  | 1.2724  |  0 hr 50 min \n",
      " 235  | 0.2025  | 0.1140  | 1.2973  |  0 hr 50 min \n",
      " 236  | 0.1963  | 0.0987  | 1.2829  |  0 hr 51 min \n",
      " 237  | 0.1888  | 0.0991  | 1.2846  |  0 hr 51 min \n",
      " 238  | 0.1904  | 0.0979  | 1.2664  |  0 hr 51 min \n",
      " 239  | 0.1911  | 0.0962  | 1.2485  |  0 hr 51 min \n",
      " 240  | 0.1828  | 0.0911  | 1.2768  |  0 hr 51 min \n",
      " 241  | 0.1791  | 0.0941  | 1.2892  |  0 hr 52 min \n",
      " 242  | 0.1885  | 0.0955  | 1.2773  |  0 hr 52 min \n",
      " 243  | 0.1864  | 0.0946  | 1.3054  |  0 hr 52 min \n",
      " 244  | 0.1790  | 0.0967  | 1.2776  |  0 hr 52 min \n",
      " 245  | 0.2014  | 0.1044  | 1.3409  |  0 hr 52 min \n",
      " 246  | 0.1895  | 0.0926  | 1.3046  |  0 hr 53 min \n",
      " 247  | 0.1858  | 0.0889  | 1.2838  |  0 hr 53 min \n",
      " 248  | 0.1868  | 0.0909  | 1.2474  |  0 hr 53 min \n",
      " 249  | 0.1833  | 0.0993  | 1.2904  |  0 hr 53 min \n",
      " 250  | 0.1887  | 0.1008  | 1.3099  |  0 hr 53 min \n",
      " 251  | 0.1851  | 0.0937  | 1.2792  |  0 hr 54 min \n",
      " 252  | 0.1836  | 0.0905  | 1.2751  |  0 hr 54 min \n",
      " 253  | 0.1814  | 0.0932  | 1.2481  |  0 hr 54 min \n",
      " 254  | 0.1818  | 0.0896  | 1.3058  |  0 hr 54 min \n",
      " 255  | 0.1824  | 0.0920  | 1.3011  |  0 hr 54 min \n",
      " 256  | 0.1848  | 0.0919  | 1.2841  |  0 hr 55 min \n",
      " 257  | 0.1750  | 0.0837  | 1.2912  |  0 hr 55 min \n",
      " 258  | 0.1711  | 0.0843  | 1.2587  |  0 hr 55 min \n",
      " 259  | 0.1760  | 0.0881  | 1.3095  |  0 hr 55 min \n",
      " 260  | 0.1825  | 0.0970  | 1.2468  |  0 hr 55 min \n",
      " 261  | 0.1724  | 0.0883  | 1.3073  |  0 hr 56 min \n",
      " 262  | 0.1728  | 0.0896  | 1.2932  |  0 hr 56 min \n",
      " 263  | 0.1795  | 0.1056  | 1.2846  |  0 hr 56 min \n",
      " 264  | 0.1952  | 0.0853  | 1.2834  |  0 hr 56 min \n",
      " 265  | 0.1747  | 0.0982  | 1.2952  |  0 hr 56 min \n",
      " 266  | 0.1730  | 0.0881  | 1.2936  |  0 hr 57 min \n",
      " 267  | 0.1678  | 0.0819  | 1.2724  |  0 hr 57 min \n",
      " 268  | 0.1718  | 0.0850  | 1.2682  |  0 hr 57 min \n",
      " 269  | 0.1688  | 0.0865  | 1.3125  |  0 hr 57 min \n",
      " 270  | 0.1814  | 0.0942  | 1.3256  |  0 hr 57 min \n",
      " 271  | 0.1798  | 0.0875  | 1.3202  |  0 hr 58 min \n",
      " 272  | 0.1714  | 0.0811  | 1.3125  |  0 hr 58 min \n",
      " 273  | 0.1718  | 0.0936  | 1.3307  |  0 hr 58 min \n",
      " 274  | 0.1797  | 0.0858  | 1.3158  |  0 hr 58 min \n",
      " 275  | 0.1690  | 0.0874  | 1.3021  |  0 hr 59 min \n",
      " 276  | 0.1742  | 0.0816  | 1.2824  |  0 hr 59 min \n",
      " 277  | 0.1749  | 0.0912  | 1.2749  |  0 hr 59 min \n",
      " 278  | 0.1723  | 0.0786  | 1.2853  |  0 hr 59 min \n",
      " 279  | 0.1794  | 0.0848  | 1.3263  |  0 hr 59 min \n",
      " 280  | 0.1739  | 0.0844  | 1.2875  |  1 hr 00 min \n",
      " 281  | 0.1585  | 0.0810  | 1.3412  |  1 hr 00 min \n",
      " 282  | 0.1622  | 0.0909  | 1.3379  |  1 hr 00 min \n",
      " 283  | 0.1800  | 0.0834  | 1.3015  |  1 hr 00 min \n",
      " 284  | 0.1684  | 0.0824  | 1.2516  |  1 hr 00 min \n",
      " 285  | 0.1758  | 0.0930  | 1.3062  |  1 hr 01 min \n",
      " 286  | 0.1663  | 0.0861  | 1.2822  |  1 hr 01 min \n",
      " 287  | 0.1714  | 0.0950  | 1.3244  |  1 hr 01 min \n",
      " 288  | 0.1742  | 0.0892  | 1.3150  |  1 hr 01 min \n",
      " 289  | 0.1748  | 0.0845  | 1.3138  |  1 hr 02 min \n",
      " 290  | 0.1690  | 0.0788  | 1.3043  |  1 hr 02 min \n",
      " 291  | 0.1668  | 0.0823  | 1.3311  |  1 hr 02 min \n",
      " 292  | 0.1666  | 0.0813  | 1.3085  |  1 hr 02 min \n",
      " 293  | 0.1618  | 0.0756  | 1.3207  |  1 hr 02 min \n",
      " 294  | 0.1673  | 0.0881  | 1.3101  |  1 hr 03 min \n",
      " 295  | 0.1776  | 0.0790  | 1.3221  |  1 hr 03 min \n",
      " 296  | 0.1673  | 0.0786  | 1.2990  |  1 hr 03 min \n",
      " 297  | 0.1716  | 0.0893  | 1.2951  |  1 hr 03 min \n",
      " 298  | 0.1771  | 0.0866  | 1.3339  |  1 hr 03 min \n",
      " 299  | 0.1671  | 0.0804  | 1.2988  |  1 hr 04 min \n",
      " 300  | 0.1633  | 0.0865  | 1.3147  |  1 hr 04 min \n",
      " 301  | 0.1736  | 0.0794  | 1.3156  |  1 hr 04 min \n",
      " 302  | 0.1672  | 0.0738  | 1.2675  |  1 hr 04 min \n",
      " 303  | 0.1648  | 0.0973  | 1.3855  |  1 hr 05 min \n",
      " 304  | 0.1584  | 0.0763  | 1.2786  |  1 hr 05 min \n",
      " 305  | 0.1673  | 0.0775  | 1.2678  |  1 hr 05 min \n",
      " 306  | 0.1632  | 0.0800  | 1.2866  |  1 hr 05 min \n",
      " 307  | 0.1597  | 0.0757  | 1.3174  |  1 hr 05 min \n",
      " 308  | 0.1544  | 0.0765  | 1.2899  |  1 hr 06 min \n",
      " 309  | 0.1643  | 0.0782  | 1.3102  |  1 hr 06 min \n",
      " 310  | 0.1562  | 0.0755  | 1.2850  |  1 hr 06 min \n",
      " 311  | 0.1647  | 0.0820  | 1.2816  |  1 hr 06 min \n",
      " 312  | 0.1648  | 0.0832  | 1.3050  |  1 hr 06 min \n",
      " 313  | 0.1692  | 0.0713  | 1.2911  |  1 hr 07 min \n",
      " 314  | 0.1552  | 0.0718  | 1.2762  |  1 hr 07 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 315  | 0.1562  | 0.0720  | 1.2810  |  1 hr 07 min \n",
      " 316  | 0.1572  | 0.0770  | 1.2863  |  1 hr 07 min \n",
      " 317  | 0.1500  | 0.0749  | 1.2939  |  1 hr 08 min \n",
      " 318  | 0.1489  | 0.0717  | 1.2791  |  1 hr 08 min \n",
      " 319  | 0.1485  | 0.0793  | 1.2929  |  1 hr 08 min \n",
      " 320  | 0.1594  | 0.0717  | 1.2987  |  1 hr 08 min \n",
      " 321  | 0.1515  | 0.0771  | 1.2934  |  1 hr 08 min \n",
      " 322  | 0.1462  | 0.0792  | 1.3127  |  1 hr 09 min \n",
      " 323  | 0.1523  | 0.0692  | 1.2951  |  1 hr 09 min \n",
      " 324  | 0.1535  | 0.0759  | 1.3135  |  1 hr 09 min \n",
      " 325  | 0.1540  | 0.0775  | 1.2905  |  1 hr 09 min \n",
      " 326  | 0.1599  | 0.0802  | 1.2898  |  1 hr 09 min \n",
      " 327  | 0.1603  | 0.0801  | 1.2669  |  1 hr 10 min \n",
      " 328  | 0.1601  | 0.1025  | 1.2691  |  1 hr 10 min \n",
      " 329  | 0.1656  | 0.0757  | 1.2912  |  1 hr 10 min \n",
      " 330  | 0.1565  | 0.0769  | 1.2708  |  1 hr 10 min \n",
      " 331  | 0.1519  | 0.0741  | 1.3239  |  1 hr 11 min \n",
      " 332  | 0.1565  | 0.0689  | 1.3175  |  1 hr 11 min \n",
      " 333  | 0.1511  | 0.0722  | 1.3070  |  1 hr 11 min \n",
      " 334  | 0.1557  | 0.0748  | 1.2858  |  1 hr 11 min \n",
      " 335  | 0.1494  | 0.0719  | 1.2928  |  1 hr 11 min \n",
      " 336  | 0.1509  | 0.0814  | 1.2931  |  1 hr 12 min \n",
      " 337  | 0.1535  | 0.0793  | 1.3170  |  1 hr 12 min \n",
      " 338  | 0.1628  | 0.0704  | 1.2721  |  1 hr 12 min \n",
      " 339  | 0.1507  | 0.0689  | 1.3005  |  1 hr 12 min \n",
      " 340  | 0.1491  | 0.0677  | 1.2882  |  1 hr 12 min \n",
      " 341  | 0.1494  | 0.0625  | 1.3091  |  1 hr 12 min \n",
      " 342  | 0.1442  | 0.0622  | 1.2848  |  1 hr 13 min \n",
      " 343  | 0.1539  | 0.0743  | 1.3081  |  1 hr 13 min \n",
      " 344  | 0.1549  | 0.0753  | 1.3111  |  1 hr 13 min \n",
      " 345  | 0.1499  | 0.0691  | 1.2733  |  1 hr 13 min \n",
      " 346  | 0.1521  | 0.0709  | 1.3026  |  1 hr 13 min \n",
      " 347  | 0.1501  | 0.0779  | 1.2751  |  1 hr 14 min \n",
      " 348  | 0.1534  | 0.0717  | 1.2740  |  1 hr 14 min \n",
      " 349  | 0.1556  | 0.0711  | 1.2686  |  1 hr 14 min \n",
      " 350  | 0.1588  | 0.0983  | 1.2597  |  1 hr 14 min \n",
      " 351  | 0.1580  | 0.0678  | 1.2384  |  1 hr 14 min \n",
      " 352  | 0.1532  | 0.0683  | 1.2396  |  1 hr 15 min \n",
      " 353  | 0.1402  | 0.0673  | 1.2807  |  1 hr 15 min \n",
      " 354  | 0.1456  | 0.0652  | 1.2984  |  1 hr 15 min \n",
      " 355  | 0.1484  | 0.0812  | 1.3025  |  1 hr 15 min \n",
      " 356  | 0.1457  | 0.0635  | 1.2846  |  1 hr 15 min \n",
      " 357  | 0.1371  | 0.0600  | 1.2915  |  1 hr 15 min \n",
      " 358  | 0.1443  | 0.0666  | 1.2929  |  1 hr 16 min \n",
      " 359  | 0.1527  | 0.0650  | 1.2939  |  1 hr 16 min \n",
      " 360  | 0.1422  | 0.0639  | 1.2903  |  1 hr 16 min \n",
      " 361  | 0.1412  | 0.0734  | 1.2742  |  1 hr 16 min \n",
      " 362  | 0.1474  | 0.0798  | 1.3138  |  1 hr 16 min \n",
      " 363  | 0.1589  | 0.0679  | 1.2847  |  1 hr 17 min \n",
      " 364  | 0.1468  | 0.0639  | 1.2830  |  1 hr 17 min \n",
      " 365  | 0.1510  | 0.0706  | 1.3265  |  1 hr 17 min \n",
      " 366  | 0.1465  | 0.0703  | 1.3058  |  1 hr 17 min \n",
      " 367  | 0.1419  | 0.0647  | 1.2977  |  1 hr 17 min \n",
      " 368  | 0.1468  | 0.0708  | 1.3073  |  1 hr 18 min \n",
      " 369  | 0.1449  | 0.0646  | 1.2876  |  1 hr 18 min \n",
      " 370  | 0.1433  | 0.0678  | 1.2898  |  1 hr 18 min \n",
      " 371  | 0.1452  | 0.0605  | 1.2675  |  1 hr 18 min \n",
      " 372  | 0.1376  | 0.0703  | 1.3103  |  1 hr 18 min \n",
      " 373  | 0.1465  | 0.0636  | 1.2864  |  1 hr 19 min \n",
      " 374  | 0.1499  | 0.0739  | 1.2685  |  1 hr 19 min \n",
      " 375  | 0.1491  | 0.0644  | 1.2877  |  1 hr 19 min \n",
      " 376  | 0.1389  | 0.0666  | 1.2879  |  1 hr 19 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  0   |  19   | 0.0600  | 1.1315  \n",
      "  0   | 1.4260  | 1.2800  | 1.2101  |  1 hr 19 min \n",
      "  1   | 1.2891  | 1.2335  | 1.1781  |  1 hr 20 min \n",
      "  2   | 1.2674  | 1.2377  | 1.1740  |  1 hr 20 min \n",
      "  3   | 1.2342  | 1.1907  | 1.1610  |  1 hr 20 min \n",
      "  4   | 1.2009  | 1.1653  | 1.1534  |  1 hr 20 min \n",
      "  5   | 1.1865  | 1.1593  | 1.1813  |  1 hr 20 min \n",
      "  6   | 1.1532  | 1.1191  | 1.1333  |  1 hr 21 min \n",
      "  7   | 1.1393  | 1.0714  | 1.0828  |  1 hr 21 min \n",
      "  8   | 1.1258  | 1.0534  | 1.0735  |  1 hr 21 min \n",
      "  9   | 1.1178  | 1.0549  | 1.0935  |  1 hr 21 min \n",
      " 10   | 1.0973  | 1.0207  | 1.0715  |  1 hr 22 min \n",
      " 11   | 1.0879  | 1.0318  | 1.0848  |  1 hr 22 min \n",
      " 12   | 1.0721  | 0.9967  | 1.0821  |  1 hr 22 min \n",
      " 13   | 1.0606  | 0.9493  | 1.0486  |  1 hr 22 min \n",
      " 14   | 1.0550  | 0.9752  | 1.0631  |  1 hr 22 min \n",
      " 15   | 1.0188  | 0.9720  | 1.0764  |  1 hr 23 min \n",
      " 16   | 1.0158  | 0.9687  | 1.1045  |  1 hr 23 min \n",
      " 17   | 1.0060  | 0.9045  | 1.0655  |  1 hr 23 min \n",
      " 18   | 0.9838  | 0.8861  | 1.0358  |  1 hr 23 min \n",
      " 19   | 0.9693  | 0.8747  | 1.0791  |  1 hr 23 min \n",
      " 20   | 0.9722  | 0.8759  | 1.0739  |  1 hr 24 min \n",
      " 21   | 0.9522  | 0.8522  | 1.1069  |  1 hr 24 min \n",
      " 22   | 0.9363  | 0.8434  | 1.0921  |  1 hr 24 min \n",
      " 23   | 0.9396  | 0.8493  | 1.0686  |  1 hr 24 min \n",
      " 24   | 0.8987  | 0.7991  | 1.0646  |  1 hr 25 min \n",
      " 25   | 0.9000  | 0.8194  | 1.0877  |  1 hr 25 min \n",
      " 26   | 0.8924  | 0.7801  | 1.0378  |  1 hr 25 min \n",
      " 27   | 0.8770  | 0.8070  | 1.0403  |  1 hr 25 min \n",
      " 28   | 0.8656  | 0.7695  | 1.0980  |  1 hr 25 min \n",
      " 29   | 0.8498  | 0.7392  | 1.0710  |  1 hr 26 min \n",
      " 30   | 0.8321  | 0.7103  | 1.0498  |  1 hr 26 min \n",
      " 31   | 0.8339  | 0.7220  | 1.0795  |  1 hr 26 min \n",
      " 32   | 0.8340  | 0.7234  | 1.0980  |  1 hr 26 min \n",
      " 33   | 0.8019  | 0.6713  | 1.0721  |  1 hr 26 min \n",
      " 34   | 0.7790  | 0.6700  | 1.1125  |  1 hr 27 min \n",
      " 35   | 0.7755  | 0.6431  | 1.0756  |  1 hr 27 min \n",
      " 36   | 0.7654  | 0.6358  | 1.0996  |  1 hr 27 min \n",
      " 37   | 0.7481  | 0.6042  | 1.0863  |  1 hr 27 min \n",
      " 38   | 0.7426  | 0.6087  | 1.0989  |  1 hr 28 min \n",
      " 39   | 0.7322  | 0.6102  | 1.0792  |  1 hr 28 min \n",
      " 40   | 0.7496  | 0.6077  | 1.1498  |  1 hr 28 min \n",
      " 41   | 0.7213  | 0.5686  | 1.0926  |  1 hr 28 min \n",
      " 42   | 0.6921  | 0.5478  | 1.1203  |  1 hr 28 min \n",
      " 43   | 0.6820  | 0.5284  | 1.0871  |  1 hr 29 min \n",
      " 44   | 0.6734  | 0.5136  | 1.1058  |  1 hr 29 min \n",
      " 45   | 0.6709  | 0.5175  | 1.0774  |  1 hr 29 min \n",
      " 46   | 0.6439  | 0.5161  | 1.1515  |  1 hr 29 min \n",
      " 47   | 0.6425  | 0.5083  | 1.1661  |  1 hr 29 min \n",
      " 48   | 0.6517  | 0.4814  | 1.1261  |  1 hr 30 min \n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(5):\n",
    "    \n",
    "    model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_MSE\"] = 9e8\n",
    "    best_param[\"valid_MSE\"] = 9e8\n",
    "    for epoch in range(800):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'min')  \n",
    "        log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "        \n",
    "        if train_MSE < best_param[\"train_MSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_MSE\"] = train_MSE\n",
    "        if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_MSE\"] = valid_MSE\n",
    "#             if valid_MSE < 0.35:\n",
    "#                  torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "        if (epoch - best_param[\"train_epoch\"] >18) and (epoch - best_param[\"valid_epoch\"] >28):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train_MSE | valid MSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model\n",
    "# best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "# test_MAE, test_MSE = eval(model, test_df)\n",
    "# print(\"best epoch:\",best_param[\"test_epoch\"],\"\\n\",\"test MSE:\",test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(20):\n",
    "#     losses = train(smiles_list[valid_fold[fold_index]])\n",
    "#     print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
