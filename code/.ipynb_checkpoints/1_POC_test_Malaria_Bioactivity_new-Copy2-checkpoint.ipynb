{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP.featurizing import graph_dict\n",
    "from AttentiveFP.AttentiveLayers_new import Fingerprint, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "if cuda_aviable:\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  9999\n",
      "number of successfully processed smiles:  9999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'Malaria Bioactivity'\n",
    "tasks = ['Loge EC50']\n",
    "\n",
    "raw_filename = \"../data/malaria-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename, names = [\"Loge EC50\", \"smiles\"])\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 888 # 69，103, 107\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 128\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "radius = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/malaria-processed.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  200\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "while (len(train_fold[0]) % batch_size) / batch_size <0.8:\n",
    "    batch_size +=1\n",
    "print(\"batch size: \", batch_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24583\n",
      "preprocess.0.linear.weight torch.Size([16, 39])\n",
      "preprocess.0.linear.bias torch.Size([16])\n",
      "preprocess.0.bn.weight torch.Size([16])\n",
      "preprocess.0.bn.bias torch.Size([16])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.0.align.weight torch.Size([1, 32])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.0.attend.linear.bias torch.Size([16])\n",
      "propagate.0.attend.bn.weight torch.Size([16])\n",
      "propagate.0.attend.bn.bias torch.Size([16])\n",
      "propagate.0.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.0.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.0.gru.bias_ih torch.Size([48])\n",
      "propagate.0.gru.bias_hh torch.Size([48])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.1.align.weight torch.Size([1, 32])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.1.attend.linear.bias torch.Size([16])\n",
      "propagate.1.attend.bn.weight torch.Size([16])\n",
      "propagate.1.attend.bn.bias torch.Size([16])\n",
      "propagate.1.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.1.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.1.gru.bias_ih torch.Size([48])\n",
      "propagate.1.gru.bias_hh torch.Size([48])\n",
      "propagate.2.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.2.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.2.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.2.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.2.align.weight torch.Size([1, 32])\n",
      "propagate.2.align.bias torch.Size([1])\n",
      "propagate.2.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.2.attend.linear.bias torch.Size([16])\n",
      "propagate.2.attend.bn.weight torch.Size([16])\n",
      "propagate.2.attend.bn.bias torch.Size([16])\n",
      "propagate.2.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.2.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.2.gru.bias_ih torch.Size([48])\n",
      "propagate.2.gru.bias_hh torch.Size([48])\n",
      "propagate.3.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.3.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.3.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.3.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.3.align.weight torch.Size([1, 32])\n",
      "propagate.3.align.bias torch.Size([1])\n",
      "propagate.3.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.3.attend.linear.bias torch.Size([16])\n",
      "propagate.3.attend.bn.weight torch.Size([16])\n",
      "propagate.3.attend.bn.bias torch.Size([16])\n",
      "propagate.3.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.3.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.3.gru.bias_ih torch.Size([48])\n",
      "propagate.3.gru.bias_hh torch.Size([48])\n",
      "superGather.0.align.weight torch.Size([1, 32])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([16, 16])\n",
      "superGather.0.attend.linear.bias torch.Size([16])\n",
      "superGather.0.attend.bn.weight torch.Size([16])\n",
      "superGather.0.attend.bn.bias torch.Size([16])\n",
      "superGather.0.gru.weight_ih torch.Size([48, 16])\n",
      "superGather.0.gru.weight_hh torch.Size([48, 16])\n",
      "superGather.0.gru.bias_ih torch.Size([48])\n",
      "superGather.0.gru.bias_hh torch.Size([48])\n",
      "superGather.1.align.weight torch.Size([1, 32])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([16, 16])\n",
      "superGather.1.attend.linear.bias torch.Size([16])\n",
      "superGather.1.attend.bn.weight torch.Size([16])\n",
      "superGather.1.attend.bn.bias torch.Size([16])\n",
      "superGather.1.gru.weight_ih torch.Size([48, 16])\n",
      "superGather.1.gru.weight_hh torch.Size([48, 16])\n",
      "superGather.1.gru.bias_ih torch.Size([48])\n",
      "superGather.1.gru.bias_hh torch.Size([48])\n",
      "predict.0.linear.weight torch.Size([512, 16])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([1, 512])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(num_target=output_units_num, fingerprint_dim=32, K=4, T=2, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train MSE |  valid MSE |  time \n",
      "  0   | 1.3964  | 2.4526  | 2.5427  |  0 hr 00 min \n",
      "  1   | 1.2934  | 1.2332  | 1.3381  |  0 hr 00 min \n",
      "  2   | 1.2312  | 1.3173  | 1.4583  |  0 hr 00 min \n",
      "  3   | 1.2080  | 1.2123  | 1.3682  |  0 hr 00 min \n",
      "  4   | 1.1870  | 1.1871  | 1.3627  |  0 hr 00 min \n",
      "  5   | 1.1966  | 1.1452  | 1.2944  |  0 hr 00 min \n",
      "  6   | 1.1691  | 1.1122  | 1.2805  |  0 hr 00 min \n",
      "  7   | 1.1676  | 1.1235  | 1.2622  |  0 hr 00 min \n",
      "  8   | 1.1476  | 1.0867  | 1.2351  |  0 hr 00 min \n",
      "  9   | 1.1235  | 1.1310  | 1.2790  |  0 hr 00 min \n",
      " 10   | 1.1445  | 1.0892  | 1.2993  |  0 hr 00 min \n",
      " 11   | 1.1170  | 1.1200  | 1.3391  |  0 hr 01 min \n",
      " 12   | 1.1011  | 1.0659  | 1.2554  |  0 hr 01 min \n",
      " 13   | 1.1096  | 1.1733  | 1.3704  |  0 hr 01 min \n",
      " 14   | 1.0907  | 1.0407  | 1.2505  |  0 hr 01 min \n",
      " 15   | 1.0697  | 1.0538  | 1.2202  |  0 hr 01 min \n",
      " 16   | 1.0529  | 1.0473  | 1.2630  |  0 hr 01 min \n",
      " 17   | 1.0539  | 0.9882  | 1.1669  |  0 hr 01 min \n",
      " 18   | 1.0490  | 0.9770  | 1.1813  |  0 hr 01 min \n",
      " 19   | 1.0441  | 0.9678  | 1.2097  |  0 hr 01 min \n",
      " 20   | 1.0226  | 1.0059  | 1.2179  |  0 hr 01 min \n",
      " 21   | 1.0296  | 0.9783  | 1.1620  |  0 hr 01 min \n",
      " 22   | 1.0127  | 0.9517  | 1.2300  |  0 hr 01 min \n",
      " 23   | 1.0081  | 0.9719  | 1.2603  |  0 hr 02 min \n",
      " 24   | 0.9992  | 0.9830  | 1.1754  |  0 hr 02 min \n",
      " 25   | 1.0029  | 0.9428  | 1.2023  |  0 hr 02 min \n",
      " 26   | 0.9912  | 0.9412  | 1.1776  |  0 hr 02 min \n",
      " 27   | 0.9871  | 0.9362  | 1.1987  |  0 hr 02 min \n",
      " 28   | 0.9770  | 0.8853  | 1.1924  |  0 hr 02 min \n",
      " 29   | 0.9653  | 0.9674  | 1.2582  |  0 hr 02 min \n",
      " 30   | 0.9654  | 0.8815  | 1.1812  |  0 hr 02 min \n",
      " 31   | 0.9511  | 0.8956  | 1.1456  |  0 hr 02 min \n",
      " 32   | 0.9426  | 0.8826  | 1.2247  |  0 hr 02 min \n",
      " 33   | 0.9423  | 0.9154  | 1.2229  |  0 hr 02 min \n",
      " 34   | 0.9459  | 0.8621  | 1.1924  |  0 hr 02 min \n",
      " 35   | 0.9231  | 0.8692  | 1.1675  |  0 hr 03 min \n",
      " 36   | 0.9206  | 0.8655  | 1.2112  |  0 hr 03 min \n",
      " 37   | 0.9167  | 0.8329  | 1.1859  |  0 hr 03 min \n",
      " 38   | 0.9286  | 0.8309  | 1.1833  |  0 hr 03 min \n",
      " 39   | 0.9077  | 0.8594  | 1.1653  |  0 hr 03 min \n",
      " 40   | 0.8964  | 0.8123  | 1.1513  |  0 hr 03 min \n",
      " 41   | 0.8911  | 0.8465  | 1.2587  |  0 hr 03 min \n",
      " 42   | 0.8996  | 0.8524  | 1.2307  |  0 hr 03 min \n",
      " 43   | 0.8922  | 0.7997  | 1.2350  |  0 hr 03 min \n",
      " 44   | 0.8797  | 0.8370  | 1.2561  |  0 hr 03 min \n",
      " 45   | 0.8752  | 0.8027  | 1.2221  |  0 hr 03 min \n",
      " 46   | 0.8881  | 0.8019  | 1.1994  |  0 hr 03 min \n",
      " 47   | 0.8811  | 0.7950  | 1.1886  |  0 hr 04 min \n",
      " 48   | 0.8648  | 0.8484  | 1.2359  |  0 hr 04 min \n",
      " 49   | 0.8740  | 0.8164  | 1.2857  |  0 hr 04 min \n",
      " 50   | 0.8602  | 0.7619  | 1.1880  |  0 hr 04 min \n",
      " 51   | 0.8418  | 0.7869  | 1.2051  |  0 hr 04 min \n",
      " 52   | 0.8406  | 0.7759  | 1.1797  |  0 hr 04 min \n",
      " 53   | 0.8325  | 0.7684  | 1.2155  |  0 hr 04 min \n",
      " 54   | 0.8359  | 0.7599  | 1.2183  |  0 hr 04 min \n",
      " 55   | 0.8396  | 0.7995  | 1.2443  |  0 hr 04 min \n",
      " 56   | 0.8330  | 0.7472  | 1.1856  |  0 hr 04 min \n",
      " 57   | 0.8336  | 0.7690  | 1.2144  |  0 hr 04 min \n",
      " 58   | 0.8255  | 0.7283  | 1.2108  |  0 hr 04 min \n",
      " 59   | 0.8162  | 0.7390  | 1.1958  |  0 hr 05 min \n",
      " 60   | 0.8207  | 0.7345  | 1.2051  |  0 hr 05 min \n",
      " 61   | 0.8261  | 0.7386  | 1.2227  |  0 hr 05 min \n",
      " 62   | 0.8025  | 0.7078  | 1.1960  |  0 hr 05 min \n",
      " 63   | 0.7955  | 0.7033  | 1.2604  |  0 hr 05 min \n",
      " 64   | 0.7963  | 0.7567  | 1.2975  |  0 hr 05 min \n",
      " 65   | 0.7973  | 0.7104  | 1.1893  |  0 hr 05 min \n",
      " 66   | 0.7931  | 0.7057  | 1.1747  |  0 hr 05 min \n",
      " 67   | 0.7980  | 0.7225  | 1.1839  |  0 hr 05 min \n",
      " 68   | 0.8059  | 0.7127  | 1.2553  |  0 hr 05 min \n",
      " 69   | 0.7955  | 0.6893  | 1.2264  |  0 hr 05 min \n",
      " 70   | 0.7788  | 0.6701  | 1.2445  |  0 hr 05 min \n",
      " 71   | 0.7631  | 0.6613  | 1.2233  |  0 hr 06 min \n",
      " 72   | 0.7686  | 0.6869  | 1.2298  |  0 hr 06 min \n",
      " 73   | 0.7758  | 0.6690  | 1.2098  |  0 hr 06 min \n",
      " 74   | 0.7539  | 0.6785  | 1.2076  |  0 hr 06 min \n",
      " 75   | 0.7702  | 0.6727  | 1.2341  |  0 hr 06 min \n",
      " 76   | 0.7521  | 0.6665  | 1.2883  |  0 hr 06 min \n",
      " 77   | 0.7375  | 0.6496  | 1.3016  |  0 hr 06 min \n",
      " 78   | 0.7451  | 0.6512  | 1.2106  |  0 hr 06 min \n",
      " 79   | 0.7456  | 0.6352  | 1.2324  |  0 hr 06 min \n",
      " 80   | 0.7602  | 0.6979  | 1.2484  |  0 hr 06 min \n",
      " 81   | 0.7461  | 0.6744  | 1.2380  |  0 hr 06 min \n",
      " 82   | 0.7316  | 0.6454  | 1.2127  |  0 hr 07 min \n",
      " 83   | 0.7395  | 0.6676  | 1.2543  |  0 hr 07 min \n",
      " 84   | 0.7246  | 0.6327  | 1.2778  |  0 hr 07 min \n",
      " 85   | 0.7333  | 0.6553  | 1.2793  |  0 hr 07 min \n",
      " 86   | 0.7169  | 0.6436  | 1.2394  |  0 hr 07 min \n",
      " 87   | 0.7299  | 0.6315  | 1.2410  |  0 hr 07 min \n",
      " 88   | 0.7224  | 0.6083  | 1.2457  |  0 hr 07 min \n",
      " 89   | 0.7086  | 0.6130  | 1.2609  |  0 hr 07 min \n",
      " 90   | 0.7114  | 0.6308  | 1.3078  |  0 hr 07 min \n",
      " 91   | 0.7210  | 0.6079  | 1.2254  |  0 hr 07 min \n",
      " 92   | 0.7130  | 0.6394  | 1.1874  |  0 hr 07 min \n",
      " 93   | 0.7179  | 0.5963  | 1.2603  |  0 hr 07 min \n",
      " 94   | 0.7094  | 0.6332  | 1.3183  |  0 hr 08 min \n",
      " 95   | 0.6949  | 0.6504  | 1.4415  |  0 hr 08 min \n",
      " 96   | 0.6911  | 0.5939  | 1.2301  |  0 hr 08 min \n",
      " 97   | 0.6888  | 0.5977  | 1.2825  |  0 hr 08 min \n",
      " 98   | 0.6967  | 0.5735  | 1.1806  |  0 hr 08 min \n",
      " 99   | 0.6776  | 0.5754  | 1.2782  |  0 hr 08 min \n",
      " 100  | 0.6933  | 0.5646  | 1.2977  |  0 hr 08 min \n",
      " 101  | 0.6781  | 0.5684  | 1.2359  |  0 hr 08 min \n",
      " 102  | 0.6773  | 0.5769  | 1.2345  |  0 hr 08 min \n",
      " 103  | 0.6902  | 0.5967  | 1.2220  |  0 hr 08 min \n",
      " 104  | 0.6710  | 0.5752  | 1.2285  |  0 hr 08 min \n",
      " 105  | 0.6756  | 0.5731  | 1.2860  |  0 hr 08 min \n",
      " 106  | 0.6769  | 0.5804  | 1.2895  |  0 hr 09 min \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fd7c13712f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/erikxiong/miniconda3/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7580375fa564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_MSE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9e8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtraine_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_MSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvalid_MAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_MSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8990a8dfbe11>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(smiles_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m                               num_workers=8, shuffle=True, worker_init_fn=np.random.seed(SEED))\n\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbond_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0matom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/util.py\u001b[0m in \u001b[0;36m_flush_std_streams\u001b[0;34m()\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(5):\n",
    "    \n",
    "    model = Fingerprint(num_target=output_units_num, fingerprint_dim=16, K=4, T=2, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_MSE\"] = 9e8\n",
    "    best_param[\"valid_MSE\"] = 9e8\n",
    "    for epoch in range(800):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'min')  \n",
    "        log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "        \n",
    "        if train_MSE < best_param[\"train_MSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_MSE\"] = train_MSE\n",
    "        if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_MSE\"] = valid_MSE\n",
    "            if valid_MSE < 0.8:\n",
    "                 torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "        if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train_MSE | valid MSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "test_MAE, test_MSE = eval(model, test_df)\n",
    "print(\"best epoch:\",best_param[\"test_epoch\"],\"\\n\",\"test MSE:\",test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(20):\n",
    "#     losses = train(smiles_list[valid_fold[fold_index]])\n",
    "#     print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
