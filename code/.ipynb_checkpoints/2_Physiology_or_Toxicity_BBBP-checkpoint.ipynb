{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  2050\n",
      "failed to process smiles:  O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n",
      "failed to process smiles:  c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
      "failed to process smiles:  Cc1nc(sc1)\\[NH]=C(\\N)N\n",
      "failed to process smiles:  s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n",
      "failed to process smiles:  c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n",
      "failed to process smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n",
      "failed to process smiles:  s1cc(nc1\\[NH]=C(\\N)N)C\n",
      "failed to process smiles:  c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n",
      "number of successfully processed smiles:  2039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'BBBP'\n",
    "tasks = ['BBBP']\n",
    "raw_filename = \"../data/BBBP.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"failed to process smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBBP</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)C1OC(=O)C2=CCCN2C(=O)c3coc(CC(=O)CC(O)\\C=...</td>\n",
       "      <td>C/C1=C/C(O)CC(=O)Cc2nc(co2)C(=O)N2CCC=C2C(=O)O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BBBP                                             smiles  \\\n",
       "944     0  CC(C)C1OC(=O)C2=CCCN2C(=O)c3coc(CC(=O)CC(O)\\C=...   \n",
       "\n",
       "                                           cano_smiles  \n",
       "944  C/C1=C/C(O)CC(=O)Cc2nc(co2)C(=O)N2CCC=C2C(=O)O...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "remained_df = remained_df.reset_index(drop=True)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "class ScaffoldGenerator(object):\n",
    "    \"\"\"\n",
    "    Generate molecular scaffolds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    include_chirality : : bool, optional (default False)\n",
    "      Include chirality in scaffolds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, include_chirality=False):\n",
    "        self.include_chirality = include_chirality\n",
    "\n",
    "    def get_scaffold(self, mol):\n",
    "        \"\"\"\n",
    "        Get Murcko scaffolds for molecules.\n",
    "\n",
    "        Murcko scaffolds are described in DOI: 10.1021/jm9602928. They are\n",
    "        essentially that part of the molecule consisting of rings and the\n",
    "        linker atoms between them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mols : array_like\n",
    "            Molecules.\n",
    "        \"\"\"\n",
    "        return MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=self.include_chirality)\n",
    "\n",
    "\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    engine = ScaffoldGenerator(include_chirality=include_chirality)\n",
    "    scaffold = engine.get_scaffold(mol)\n",
    "    return scaffold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "scaffold_list = []\n",
    "all_scaffolds_dict = {}\n",
    "\n",
    "for index, smiles in enumerate(remained_df['cano_smiles']):\n",
    "    scaffold = generate_scaffold(smiles)\n",
    "    scaffold_list.append(scaffold)\n",
    "    if scaffold not in all_scaffolds_dict:\n",
    "        all_scaffolds_dict[scaffold] = [index]\n",
    "    else:\n",
    "        all_scaffolds_dict[scaffold].append(index)\n",
    "remained_df['scaffold'] = scaffold_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaffold</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>c1ccccc1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>O=C1C=CC2C(=C1)CCC1C3CCCC3CCC21</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>c1ccc2c(c1)Nc1ccccc1S2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>O=C1CN=C(c2ccccc2)c2ccccc2N1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>O=C1C=C2CCC3C4CCCC4CCC3C2CC1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>c1ccc(Cc2ccccc2)cc1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>O=C1CC(=O)NC(=O)N1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>O=C(Cc1ccccc1)N1CCNCC1CN1CCCC1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>c1ccncc1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            scaffold  count\n",
       "991                         c1ccccc1    137\n",
       "0                                        99\n",
       "379  O=C1C=CC2C(=C1)CCC1C3CCCC3CCC21     76\n",
       "945           c1ccc2c(c1)Nc1ccccc1S2     26\n",
       "496     O=C1CN=C(c2ccccc2)c2ccccc2N1     26\n",
       "357     O=C1C=C2CCC3C4CCCC4CCC3C2CC1     24\n",
       "833              c1ccc(Cc2ccccc2)cc1     21\n",
       "400               O=C1CC(=O)NC(=O)N1     18\n",
       "201   O=C(Cc1ccccc1)N1CCNCC1CN1CCCC1     17\n",
       "994                         c1ccncc1     16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_df.groupby(['scaffold'])['scaffold'].count() \\\n",
    "                     .reset_index(name='count') \\\n",
    "                     .sort_values(['count'], ascending=False) \\\n",
    "                     .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaffold_randomized_spliting(scaffolds_dict, random_seed = 0): \n",
    "    count = 0\n",
    "    negative_count = 0\n",
    "    while (count < 0.095*len(remained_df) or  count > 0.105*len(remained_df)) \\\n",
    "        or (negative_count < 45 or  negative_count > 55):\n",
    "        random_seed +=1\n",
    "        random.seed(random_seed)\n",
    "        scaffold = random.sample(list(scaffolds_dict.keys()), 100)\n",
    "        count = sum([len(scaffolds_dict[scaffold]) for scaffold in scaffold])\n",
    "        index = [index for scaffold in scaffold for index in scaffolds_dict[scaffold]]\n",
    "        negative_count = len(remained_df.iloc[index, :][remained_df['BBBP'] == 0])\n",
    "#     print(random)\n",
    "    print(random_seed, count, negative_count, index)\n",
    "    return scaffold, index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/erikxiong/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 204 47 [739, 923, 1921, 779, 301, 1342, 1805, 1877, 1886, 524, 69, 119, 365, 609, 646, 1074, 1075, 1122, 1481, 838, 1630, 376, 477, 543, 1462, 1627, 882, 974, 993, 362, 113, 1612, 1885, 640, 1647, 544, 665, 709, 1163, 1408, 1776, 1788, 355, 636, 1540, 1834, 1047, 76, 86, 335, 337, 614, 616, 1686, 7, 1293, 824, 1161, 1785, 1186, 1534, 769, 1441, 372, 1084, 1085, 1722, 1880, 635, 1067, 1782, 913, 27, 80, 285, 289, 1597, 1300, 1235, 1837, 810, 219, 531, 681, 1927, 141, 1181, 394, 1245, 1874, 1497, 1266, 121, 1439, 1394, 526, 696, 2010, 1327, 1137, 151, 1685, 1423, 1012, 1902, 14, 470, 578, 708, 851, 946, 967, 1049, 1155, 1274, 1370, 1606, 1693, 1697, 1703, 1708, 1725, 1741, 1857, 1887, 1917, 22, 660, 320, 1560, 1598, 1789, 990, 1867, 252, 1193, 1422, 1463, 1470, 1173, 1740, 817, 868, 869, 894, 1070, 879, 272, 925, 965, 996, 1323, 1792, 1799, 10, 66, 93, 264, 308, 387, 388, 1119, 1275, 948, 970, 1134, 1225, 1229, 1230, 1303, 1615, 1625, 1706, 1821, 1823, 1958, 2006, 2008, 755, 1747, 2027, 1459, 911, 1518, 1160, 718, 866, 910, 224, 1100, 1178, 271, 690, 727, 732, 736, 802, 828, 839, 892, 924, 1190, 1964, 1158]\n",
      "156 198 50 [1061, 927, 1999, 1591, 446, 1339, 1654, 791, 238, 395, 249, 1967, 1984, 213, 1638, 1603, 1218, 981, 827, 716, 719, 237, 677, 949, 1038, 1633, 1635, 1933, 133, 1044, 1194, 1343, 1576, 1767, 244, 428, 547, 574, 651, 1292, 1727, 1883, 1952, 211, 735, 792, 823, 17, 124, 257, 994, 1682, 968, 978, 1183, 1550, 1552, 1640, 1962, 1970, 1987, 47, 765, 766, 1167, 875, 843, 853, 1623, 1796, 2, 31, 409, 1257, 1258, 1781, 1431, 770, 169, 606, 670, 683, 1728, 798, 72, 82, 334, 338, 1395, 1906, 1287, 227, 386, 2031, 1086, 1717, 999, 273, 469, 33, 527, 61, 586, 618, 619, 620, 621, 465, 115, 106, 242, 1755, 1617, 1644, 997, 518, 607, 1614, 588, 198, 776, 1842, 964, 1358, 1853, 161, 1835, 947, 1637, 96, 267, 358, 1248, 1698, 438, 439, 458, 459, 460, 461, 462, 463, 464, 1265, 1778, 112, 1215, 1587, 1454, 1505, 26, 1529, 1668, 1026, 1572, 283, 284, 725, 832, 881, 1392, 1396, 1144, 202, 1156, 1687, 746, 750, 848, 1914, 830, 102, 1118, 888, 1651, 25, 48, 58, 114, 275, 325, 357, 559, 560, 610, 611, 641, 1397, 1398, 1564, 1856, 1820, 1124, 847, 1418, 1421, 1496, 168]\n"
     ]
    }
   ],
   "source": [
    "test_scaffold, test_index = scaffold_randomized_spliting(all_scaffolds_dict, random_seed=0)\n",
    "training_scaffolds_dict = {x: all_scaffolds_dict[x] for x in all_scaffolds_dict.keys() if x not in test_scaffold}\n",
    "valid_scaffold, valid_index = scaffold_randomized_spliting(training_scaffolds_dict, random_seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = remained_df.iloc[test_index,:] # test set\n",
    "valid_df = remained_df.iloc[valid_index,:] # valid set\n",
    "train_df = remained_df.drop(test_df.index).drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/erikxiong/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc:[0.6918368852631801]\n",
      "valid_roc:[0.7366891891891892]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.757334682434284]\n",
      "valid_roc:[0.7822297297297297]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.7816627669217311]\n",
      "valid_roc:[0.8029054054054054]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.7795885242100382]\n",
      "valid_roc:[0.831418918918919]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7968317207361032]\n",
      "valid_roc:[0.8168243243243243]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.8040367630009064]\n",
      "valid_roc:[0.8376351351351352]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.8115790805033833]\n",
      "valid_roc:[0.8412837837837837]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.8208478256287022]\n",
      "valid_roc:[0.8438513513513514]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.826031324437699]\n",
      "valid_roc:[0.8447972972972972]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.8359303526634204]\n",
      "valid_roc:[0.8546621621621622]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.8421804844115601]\n",
      "valid_roc:[0.8479054054054054]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.8474314382680916]\n",
      "valid_roc:[0.8608783783783783]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.8557790004005144]\n",
      "valid_roc:[0.8642567567567567]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.8579228061299775]\n",
      "valid_roc:[0.860472972972973]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.8555112881806108]\n",
      "valid_roc:[0.8738513513513513]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.862501317481397]\n",
      "valid_roc:[0.8703378378378377]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.865528362739518]\n",
      "valid_roc:[0.875472972972973]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.8696810641033748]\n",
      "valid_roc:[0.8729054054054054]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.8722000885347501]\n",
      "valid_roc:[0.8723648648648648]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.8729315542064546]\n",
      "valid_roc:[0.8803378378378378]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.8730285208372858]\n",
      "valid_roc:[0.8814189189189189]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.877233921457029]\n",
      "valid_roc:[0.8749324324324323]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.877050528046544]\n",
      "valid_roc:[0.8777702702702703]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.8778389089146061]\n",
      "valid_roc:[0.8802027027027027]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.8794746938173232]\n",
      "valid_roc:[0.8779054054054054]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.8824384999683803]\n",
      "valid_roc:[0.8838513513513514]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.8793608634246084]\n",
      "valid_roc:[0.8716891891891891]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.8836126393895318]\n",
      "valid_roc:[0.8856081081081082]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.8848352621260989]\n",
      "valid_roc:[0.8797972972972973]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.8860557768924303]\n",
      "valid_roc:[0.879527027027027]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.8854655452265013]\n",
      "valid_roc:[0.8837162162162162]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.8896013828284743]\n",
      "valid_roc:[0.888581081081081]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.8909589156601109]\n",
      "valid_roc:[0.8877702702702703]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.8903897636965366]\n",
      "valid_roc:[0.8830405405405405]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.8895381437214106]\n",
      "valid_roc:[0.8770945945945946]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.8921520268133813]\n",
      "valid_roc:[0.8829054054054055]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.8943422078880245]\n",
      "valid_roc:[0.8881756756756757]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.892466114378465]\n",
      "valid_roc:[0.8875]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.8936128501865553]\n",
      "valid_roc:[0.891554054054054]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.8950188663336074]\n",
      "valid_roc:[0.885472972972973]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8960644195703956]\n",
      "valid_roc:[0.8852027027027026]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.8975926979911044]\n",
      "valid_roc:[0.8833108108108109]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.8978077109551214]\n",
      "valid_roc:[0.8770945945945946]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.8927612302114294]\n",
      "valid_roc:[0.8916891891891893]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.897508379181686]\n",
      "valid_roc:[0.8838513513513513]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.8991673517569932]\n",
      "valid_roc:[0.8860135135135134]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.9002192289044879]\n",
      "valid_roc:[0.8866891891891892]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.9016220830961866]\n",
      "valid_roc:[0.8864189189189189]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.9012942937245727]\n",
      "valid_roc:[0.8847972972972973]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.9007630852252366]\n",
      "valid_roc:[0.8900675675675676]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.9013617487721073]\n",
      "valid_roc:[0.8823648648648649]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.9017622631168448]\n",
      "valid_roc:[0.8873648648648649]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.9030502329307111]\n",
      "valid_roc:[0.8825000000000001]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.9037542949893547]\n",
      "valid_roc:[0.893445945945946]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.9045953751133035]\n",
      "valid_roc:[0.8847972972972973]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.9040747064651447]\n",
      "valid_roc:[0.8853378378378378]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.9059233963616435]\n",
      "valid_roc:[0.8937162162162162]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.9063997976348572]\n",
      "valid_roc:[0.8892567567567566]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.9078058137819094]\n",
      "valid_roc:[0.8960135135135134]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.9072008263243322]\n",
      "valid_roc:[0.8868243243243243]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.9076287442821307]\n",
      "valid_roc:[0.887635135135135]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.9090410843398891]\n",
      "valid_roc:[0.8897972972972973]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.909361495815679]\n",
      "valid_roc:[0.8972297297297298]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.9077699782879066]\n",
      "valid_roc:[0.888581081081081]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.9076983072999009]\n",
      "valid_roc:[0.8893918918918918]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.9060772781888319]\n",
      "valid_roc:[0.8911486486486486]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.9060119311115327]\n",
      "valid_roc:[0.8965540540540541]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.9075992326988342]\n",
      "valid_roc:[0.891689189189189]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.9088597988996395]\n",
      "valid_roc:[0.8897972972972972]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.9097936297139484]\n",
      "valid_roc:[0.8899324324324325]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.9111132190813467]\n",
      "valid_roc:[0.8969594594594594]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.9101330129218576]\n",
      "valid_roc:[0.8918243243243243]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.9115327051582031]\n",
      "valid_roc:[0.8968243243243244]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.912173528109783]\n",
      "valid_roc:[0.8931756756756757]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.9125866902759333]\n",
      "valid_roc:[0.888581081081081]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.9135668964354223]\n",
      "valid_roc:[0.8960135135135135]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.914329981660659]\n",
      "valid_roc:[0.8965540540540541]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.9153207276713253]\n",
      "valid_roc:[0.8958783783783784]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.9141929635953541]\n",
      "valid_roc:[0.8899324324324323]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.915310187820148]\n",
      "valid_roc:[0.8942567567567568]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.9154198022723921]\n",
      "valid_roc:[0.8947972972972973]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.9156643268197053]\n",
      "valid_roc:[0.8945270270270269]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.9166888003541391]\n",
      "valid_roc:[0.9015540540540541]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.9171778494487658]\n",
      "valid_roc:[0.8993918918918918]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.9180674128881301]\n",
      "valid_roc:[0.9000675675675676]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.9177153818588082]\n",
      "valid_roc:[0.898445945945946]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.9176479268112734]\n",
      "valid_roc:[0.8953378378378378]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.915071987183541]\n",
      "valid_roc:[0.8993918918918918]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.9177554332932818]\n",
      "valid_roc:[0.8938513513513513]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.9169839161871034]\n",
      "valid_roc:[0.8943918918918919]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.9189633002382005]\n",
      "valid_roc:[0.8972297297297297]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.9195598558148359]\n",
      "valid_roc:[0.8989864864864865]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.9183667446615654]\n",
      "valid_roc:[0.8934459459459458]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.9196209869516643]\n",
      "valid_roc:[0.9069594594594594]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.9210354349796581]\n",
      "valid_roc:[0.903445945945946]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.9212462320032042]\n",
      "valid_roc:[0.8987162162162162]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.9217732245620691]\n",
      "valid_roc:[0.9006081081081081]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.9227218111680262]\n",
      "valid_roc:[0.9056081081081081]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.9226164126562533]\n",
      "valid_roc:[0.9012837837837837]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.9235375956491496]\n",
      "valid_roc:[0.905472972972973]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.9200193933261661]\n",
      "valid_roc:[0.9039864864864865]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.9224393431564746]\n",
      "valid_roc:[0.903445945945946]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.9245388815109931]\n",
      "valid_roc:[0.9050675675675676]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.9242838171125023]\n",
      "valid_roc:[0.9042567567567568]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.9248845886296085]\n",
      "valid_roc:[0.9073648648648649]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.9223803199898816]\n",
      "valid_roc:[0.9004729729729729]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.9239612976664767]\n",
      "valid_roc:[0.9061486486486486]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.9244292670587491]\n",
      "valid_roc:[0.9041216216216217]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.9230970298699382]\n",
      "valid_roc:[0.9045270270270269]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.9241784186007295]\n",
      "valid_roc:[0.9045270270270271]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.9260334324079345]\n",
      "valid_roc:[0.9047972972972973]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.927199139948144]\n",
      "valid_roc:[0.9052027027027026]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.9267543582284619]\n",
      "valid_roc:[0.9083108108108108]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t113\n",
      "train_roc:[0.9273635616265098]\n",
      "valid_roc:[0.9047972972972973]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.9280444360125635]\n",
      "valid_roc:[0.9049324324324324]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.9283269040241152]\n",
      "valid_roc:[0.9079054054054054]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.9287801176247391]\n",
      "valid_roc:[0.9093918918918918]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.9299120976411814]\n",
      "valid_roc:[0.9070945945945946]\n",
      "\n",
      "EPOCH:\t118\n",
      "train_roc:[0.9303105040156833]\n",
      "valid_roc:[0.907635135135135]\n",
      "\n",
      "EPOCH:\t119\n",
      "train_roc:[0.9308143089019583]\n",
      "valid_roc:[0.9069594594594594]\n",
      "\n",
      "EPOCH:\t120\n",
      "train_roc:[0.9307700415270136]\n",
      "valid_roc:[0.906554054054054]\n",
      "\n",
      "EPOCH:\t121\n",
      "train_roc:[0.9318999135732204]\n",
      "valid_roc:[0.9077702702702702]\n",
      "\n",
      "EPOCH:\t122\n",
      "train_roc:[0.932296211977487]\n",
      "valid_roc:[0.9087162162162162]\n",
      "\n",
      "EPOCH:\t123\n",
      "train_roc:[0.930519193068994]\n",
      "valid_roc:[0.905472972972973]\n",
      "\n",
      "EPOCH:\t124\n",
      "train_roc:[0.932686186471047]\n",
      "valid_roc:[0.9135810810810809]\n",
      "\n",
      "EPOCH:\t125\n",
      "train_roc:[0.9332996058095661]\n",
      "valid_roc:[0.904391891891892]\n",
      "\n",
      "EPOCH:\t126\n",
      "train_roc:[0.9325597082569195]\n",
      "valid_roc:[0.9088513513513513]\n",
      "\n",
      "EPOCH:\t127\n",
      "train_roc:[0.9308923038006703]\n",
      "valid_roc:[0.9070945945945945]\n",
      "\n",
      "EPOCH:\t137\n",
      "train_roc:[0.938048862750058]\n",
      "valid_roc:[0.9142567567567568]\n",
      "\n",
      "EPOCH:\t138\n",
      "train_roc:[0.9382744155652522]\n",
      "valid_roc:[0.9107432432432432]\n",
      "\n",
      "EPOCH:\t139\n",
      "train_roc:[0.9392145702902674]\n",
      "valid_roc:[0.9102027027027028]\n",
      "\n",
      "EPOCH:\t140\n",
      "train_roc:[0.9403402263960033]\n",
      "valid_roc:[0.9099324324324324]\n",
      "\n",
      "EPOCH:\t141\n",
      "train_roc:[0.9408482472227492]\n",
      "valid_roc:[0.9152027027027027]\n",
      "\n",
      "EPOCH:\t142\n",
      "train_roc:[0.9389531819810704]\n",
      "valid_roc:[0.9112837837837838]\n",
      "\n",
      "EPOCH:\t143\n",
      "train_roc:[0.9397921541347836]\n",
      "valid_roc:[0.9112837837837837]\n",
      "\n",
      "EPOCH:\t144\n",
      "train_roc:[0.9406648538122642]\n",
      "valid_roc:[0.9130405405405405]\n",
      "\n",
      "EPOCH:\t145\n",
      "train_roc:[0.940938889942874]\n",
      "valid_roc:[0.9076351351351352]\n",
      "\n",
      "EPOCH:\t146\n",
      "train_roc:[0.9427833638989017]\n",
      "valid_roc:[0.9129054054054054]\n",
      "\n",
      "EPOCH:\t147\n",
      "train_roc:[0.9418558569952992]\n",
      "valid_roc:[0.9166891891891892]\n",
      "\n",
      "EPOCH:\t148\n",
      "train_roc:[0.943626551993086]\n",
      "valid_roc:[0.9134459459459459]\n",
      "\n",
      "EPOCH:\t149\n",
      "train_roc:[0.9428339551845527]\n",
      "valid_roc:[0.9157432432432432]\n",
      "\n",
      "EPOCH:\t150\n",
      "train_roc:[0.9430152406248025]\n",
      "valid_roc:[0.9130405405405405]\n",
      "\n",
      "EPOCH:\t151\n",
      "train_roc:[0.944625729884694]\n",
      "valid_roc:[0.9170945945945946]\n",
      "\n",
      "EPOCH:\t152\n",
      "train_roc:[0.9422184278757983]\n",
      "valid_roc:[0.9080405405405405]\n",
      "\n",
      "EPOCH:\t153\n",
      "train_roc:[0.942083517780729]\n",
      "valid_roc:[0.9091216216216216]\n",
      "\n",
      "EPOCH:\t154\n",
      "train_roc:[0.9460612576150425]\n",
      "valid_roc:[0.9162837837837838]\n",
      "\n",
      "EPOCH:\t155\n",
      "train_roc:[0.9456733910917178]\n",
      "valid_roc:[0.9143918918918919]\n",
      "\n",
      "EPOCH:\t156\n",
      "train_roc:[0.9469761166972321]\n",
      "valid_roc:[0.913445945945946]\n",
      "\n",
      "EPOCH:\t157\n",
      "train_roc:[0.9465039313644891]\n",
      "valid_roc:[0.9131756756756756]\n",
      "\n",
      "EPOCH:\t158\n",
      "train_roc:[0.9458736482640865]\n",
      "valid_roc:[0.9092567567567568]\n",
      "\n",
      "EPOCH:\t159\n",
      "train_roc:[0.9460085583591561]\n",
      "valid_roc:[0.9165540540540541]\n",
      "\n",
      "EPOCH:\t160\n",
      "train_roc:[0.945614367925125]\n",
      "valid_roc:[0.9120945945945946]\n",
      "\n",
      "EPOCH:\t161\n",
      "train_roc:[0.9472733405004322]\n",
      "valid_roc:[0.9157432432432433]\n",
      "\n",
      "EPOCH:\t162\n",
      "train_roc:[0.947703366428466]\n",
      "valid_roc:[0.913445945945946]\n",
      "\n",
      "EPOCH:\t163\n",
      "train_roc:[0.9466852168047386]\n",
      "valid_roc:[0.9106081081081081]\n",
      "\n",
      "EPOCH:\t164\n",
      "train_roc:[0.9451632622947366]\n",
      "valid_roc:[0.9149324324324324]\n",
      "\n",
      "EPOCH:\t165\n",
      "train_roc:[0.9430426442378634]\n",
      "valid_roc:[0.9049324324324324]\n",
      "\n",
      "EPOCH:\t166\n",
      "train_roc:[0.9459305634604439]\n",
      "valid_roc:[0.9150675675675676]\n",
      "\n",
      "EPOCH:\t167\n",
      "train_roc:[0.9466662450726194]\n",
      "valid_roc:[0.9103378378378378]\n",
      "\n",
      "EPOCH:\t168\n",
      "train_roc:[0.9483926726954616]\n",
      "valid_roc:[0.913445945945946]\n",
      "\n",
      "EPOCH:\t169\n",
      "train_roc:[0.9476822867261114]\n",
      "valid_roc:[0.9077702702702704]\n",
      "\n",
      "EPOCH:\t170\n",
      "train_roc:[0.9493728788549506]\n",
      "valid_roc:[0.9108783783783784]\n",
      "\n",
      "EPOCH:\t171\n",
      "train_roc:[0.9501486119015999]\n",
      "valid_roc:[0.9165540540540541]\n",
      "\n",
      "EPOCH:\t172\n",
      "train_roc:[0.9503889205084425]\n",
      "valid_roc:[0.9120945945945945]\n",
      "\n",
      "EPOCH:\t173\n",
      "train_roc:[0.9479120554817765]\n",
      "valid_roc:[0.9099324324324324]\n",
      "\n",
      "EPOCH:\t174\n",
      "train_roc:[0.948445371951348]\n",
      "valid_roc:[0.9070945945945945]\n",
      "\n",
      "EPOCH:\t175\n",
      "train_roc:[0.9457134425261914]\n",
      "valid_roc:[0.908581081081081]\n",
      "\n",
      "EPOCH:\t176\n",
      "train_roc:[0.9504479436750353]\n",
      "valid_roc:[0.914391891891892]\n",
      "\n",
      "EPOCH:\t177\n",
      "train_roc:[0.951660026560425]\n",
      "valid_roc:[0.9116891891891892]\n",
      "\n",
      "EPOCH:\t178\n",
      "train_roc:[0.9510571470730834]\n",
      "valid_roc:[0.9100675675675676]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.87:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
