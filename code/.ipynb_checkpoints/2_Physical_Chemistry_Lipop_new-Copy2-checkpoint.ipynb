{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, graph_dict, graph_dataset, null_collate, Graph, Logger, time_to_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  4200\n",
      "number of successfully processed smiles:  4200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'lipophilicity'\n",
    "tasks = ['exp']\n",
    "\n",
    "raw_filename = \"../data/Lipophilicity.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \", len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "epochs = 80\n",
    "batch_size =50\n",
    "\n",
    "p_dropout= 0.1\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 3\n",
    "K = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/Lipophilicity.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  51\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "    \n",
    "# avoiding the last batch has too few samples by slightly tune the batch_size\n",
    "while (len(train_fold[0]) % batch_size) / batch_size <0.8:\n",
    "    batch_size +=1\n",
    "print(\"batch size: \", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601854\n",
      "sum_importance torch.Size([1])\n",
      "preprocess.0.linear.weight torch.Size([100, 39])\n",
      "preprocess.0.linear.bias torch.Size([100])\n",
      "preprocess.0.bn.weight torch.Size([100])\n",
      "preprocess.0.bn.bias torch.Size([100])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([10000, 10])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([10000])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([10000])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([10000])\n",
      "propagate.0.align.weight torch.Size([1, 200])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([100, 100])\n",
      "propagate.0.attend.linear.bias torch.Size([100])\n",
      "propagate.0.attend.bn.weight torch.Size([100])\n",
      "propagate.0.attend.bn.bias torch.Size([100])\n",
      "propagate.0.gru.weight_ih torch.Size([300, 100])\n",
      "propagate.0.gru.weight_hh torch.Size([300, 100])\n",
      "propagate.0.gru.bias_ih torch.Size([300])\n",
      "propagate.0.gru.bias_hh torch.Size([300])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([10000, 10])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([10000])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([10000])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([10000])\n",
      "propagate.1.align.weight torch.Size([1, 200])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([100, 100])\n",
      "propagate.1.attend.linear.bias torch.Size([100])\n",
      "propagate.1.attend.bn.weight torch.Size([100])\n",
      "propagate.1.attend.bn.bias torch.Size([100])\n",
      "propagate.1.gru.weight_ih torch.Size([300, 100])\n",
      "propagate.1.gru.weight_hh torch.Size([300, 100])\n",
      "propagate.1.gru.bias_ih torch.Size([300])\n",
      "propagate.1.gru.bias_hh torch.Size([300])\n",
      "superGather.0.align.weight torch.Size([1, 200])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([100, 100])\n",
      "superGather.0.attend.linear.bias torch.Size([100])\n",
      "superGather.0.attend.bn.weight torch.Size([100])\n",
      "superGather.0.attend.bn.bias torch.Size([100])\n",
      "superGather.0.gru.weight_ih torch.Size([300, 100])\n",
      "superGather.0.gru.weight_hh torch.Size([300, 100])\n",
      "superGather.0.gru.bias_ih torch.Size([300])\n",
      "superGather.0.gru.bias_hh torch.Size([300])\n",
      "superGather.1.align.weight torch.Size([1, 200])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([100, 100])\n",
      "superGather.1.attend.linear.bias torch.Size([100])\n",
      "superGather.1.attend.bn.weight torch.Size([100])\n",
      "superGather.1.attend.bn.bias torch.Size([100])\n",
      "superGather.1.gru.weight_ih torch.Size([300, 100])\n",
      "superGather.1.gru.weight_hh torch.Size([300, 100])\n",
      "superGather.1.gru.bias_ih torch.Size([300])\n",
      "superGather.1.gru.bias_hh torch.Size([300])\n",
      "predict.0.linear.weight torch.Size([512, 100])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([1, 512])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.sqrt(np.array(eval_MAE_list).mean()), np.sqrt(np.array(eval_MSE_list).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = Logger()\n",
    "# log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "# f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "# log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "# start = timer()\n",
    "\n",
    "# best_param ={}\n",
    "# best_param[\"train_epoch\"] = 0\n",
    "# best_param[\"valid_epoch\"] = 0\n",
    "# best_param[\"train_MSE\"] = 9e8\n",
    "# best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "# fold_index = 3\n",
    "# for epoch in range(800):\n",
    "#     losses = train(smiles_list[train_fold[fold_index]])\n",
    "#     traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "#     valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "\n",
    "#     timing = time_to_str((timer() - start), 'min')  \n",
    "#     log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "\n",
    "#     if train_MSE < best_param[\"train_MSE\"]:\n",
    "#         best_param[\"train_epoch\"] = epoch\n",
    "#         best_param[\"train_MSE\"] = train_MSE\n",
    "#     if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "#         best_param[\"valid_epoch\"] = epoch\n",
    "#         best_param[\"valid_MSE\"] = valid_MSE\n",
    "# #         if valid_MSE < 0.35:\n",
    "# #              torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "#     if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "#         break\n",
    "# print(best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train RMSE |  valid RMSE |  time \n",
      "  0   | 1.7159  | 1.1824  | 1.0916  |  0 hr 00 min \n",
      "  1   | 1.0324  | 1.0338  | 0.9955  |  0 hr 00 min \n",
      "  2   | 0.8129  | 0.8763  | 0.8495  |  0 hr 00 min \n",
      "  3   | 0.6796  | 0.9418  | 0.9865  |  0 hr 00 min \n",
      "  4   | 0.6392  | 0.7237  | 0.7684  |  0 hr 00 min \n",
      "  5   | 0.5721  | 0.7080  | 0.7451  |  0 hr 00 min \n",
      "  6   | 0.5452  | 0.6552  | 0.7169  |  0 hr 00 min \n",
      "  7   | 0.5023  | 0.6250  | 0.7444  |  0 hr 00 min \n",
      "  8   | 0.4719  | 0.6409  | 0.7504  |  0 hr 00 min \n",
      "  9   | 0.4531  | 0.6020  | 0.7106  |  0 hr 00 min \n",
      " 10   | 0.4244  | 0.5699  | 0.7037  |  0 hr 01 min \n",
      " 11   | 0.4014  | 0.5720  | 0.6889  |  0 hr 01 min \n",
      " 12   | 0.3992  | 0.5530  | 0.6745  |  0 hr 01 min \n",
      " 13   | 0.3676  | 0.5909  | 0.6915  |  0 hr 01 min \n",
      " 14   | 0.3528  | 0.5300  | 0.6829  |  0 hr 01 min \n",
      " 15   | 0.3404  | 0.5277  | 0.7063  |  0 hr 01 min \n",
      " 16   | 0.3111  | 0.4913  | 0.6708  |  0 hr 01 min \n",
      " 17   | 0.3117  | 0.4731  | 0.6669  |  0 hr 01 min \n",
      " 18   | 0.2868  | 0.4465  | 0.6754  |  0 hr 01 min \n",
      " 19   | 0.2781  | 0.4747  | 0.6687  |  0 hr 01 min \n",
      " 20   | 0.2823  | 0.5017  | 0.6971  |  0 hr 01 min \n",
      " 21   | 0.2667  | 0.4350  | 0.6476  |  0 hr 02 min \n",
      " 22   | 0.2588  | 0.4139  | 0.6356  |  0 hr 02 min \n",
      " 23   | 0.2551  | 0.4046  | 0.6613  |  0 hr 02 min \n",
      " 24   | 0.2429  | 0.4418  | 0.6861  |  0 hr 02 min \n",
      " 25   | 0.2190  | 0.4426  | 0.6753  |  0 hr 02 min \n",
      " 26   | 0.2129  | 0.4082  | 0.6816  |  0 hr 02 min \n",
      " 27   | 0.1985  | 0.3844  | 0.6643  |  0 hr 02 min \n",
      " 28   | 0.1882  | 0.3855  | 0.6840  |  0 hr 02 min \n",
      " 29   | 0.1918  | 0.3600  | 0.6597  |  0 hr 02 min \n",
      " 30   | 0.1916  | 0.3440  | 0.6437  |  0 hr 02 min \n",
      " 31   | 0.1846  | 0.3372  | 0.6462  |  0 hr 02 min \n",
      " 32   | 0.1877  | 0.3170  | 0.6436  |  0 hr 02 min \n",
      " 33   | 0.1708  | 0.3167  | 0.6287  |  0 hr 03 min \n",
      " 34   | 0.1607  | 0.3149  | 0.6295  |  0 hr 03 min \n",
      " 35   | 0.1630  | 0.2980  | 0.6296  |  0 hr 03 min \n",
      " 36   | 0.1579  | 0.2940  | 0.6429  |  0 hr 03 min \n",
      " 37   | 0.1554  | 0.3083  | 0.6794  |  0 hr 03 min \n",
      " 38   | 0.1431  | 0.2827  | 0.6362  |  0 hr 03 min \n",
      " 39   | 0.1411  | 0.3427  | 0.6754  |  0 hr 03 min \n",
      " 40   | 0.1414  | 0.2624  | 0.6285  |  0 hr 03 min \n",
      " 41   | 0.1387  | 0.2656  | 0.6532  |  0 hr 03 min \n",
      " 42   | 0.1386  | 0.2702  | 0.6587  |  0 hr 03 min \n",
      " 43   | 0.1264  | 0.2589  | 0.6546  |  0 hr 03 min \n",
      " 44   | 0.1271  | 0.2883  | 0.6496  |  0 hr 04 min \n",
      " 45   | 0.1259  | 0.2447  | 0.6212  |  0 hr 04 min \n",
      " 46   | 0.1279  | 0.2692  | 0.6377  |  0 hr 04 min \n",
      " 47   | 0.1172  | 0.2613  | 0.6479  |  0 hr 04 min \n",
      " 48   | 0.1233  | 0.2243  | 0.6153  |  0 hr 04 min \n",
      " 49   | 0.1227  | 0.2381  | 0.6265  |  0 hr 04 min \n",
      " 50   | 0.1108  | 0.2245  | 0.6349  |  0 hr 04 min \n",
      " 51   | 0.1210  | 0.2877  | 0.6437  |  0 hr 04 min \n",
      " 52   | 0.1143  | 0.2275  | 0.6538  |  0 hr 04 min \n",
      " 53   | 0.1114  | 0.2590  | 0.6419  |  0 hr 04 min \n",
      " 54   | 0.1100  | 0.2228  | 0.6328  |  0 hr 04 min \n",
      " 55   | 0.1044  | 0.2722  | 0.6606  |  0 hr 05 min \n",
      " 56   | 0.0967  | 0.2117  | 0.6274  |  0 hr 05 min \n",
      " 57   | 0.1046  | 0.2769  | 0.6409  |  0 hr 05 min \n",
      " 58   | 0.1120  | 0.2101  | 0.6239  |  0 hr 05 min \n",
      " 59   | 0.0938  | 0.2182  | 0.6301  |  0 hr 05 min \n",
      " 60   | 0.1090  | 0.2246  | 0.6336  |  0 hr 05 min \n",
      " 61   | 0.1332  | 0.2219  | 0.6315  |  0 hr 05 min \n",
      " 62   | 0.1105  | 0.2286  | 0.6343  |  0 hr 05 min \n",
      " 63   | 0.0994  | 0.2471  | 0.6482  |  0 hr 05 min \n",
      " 64   | 0.0943  | 0.2009  | 0.6122  |  0 hr 05 min \n",
      " 65   | 0.1032  | 0.1972  | 0.6238  |  0 hr 05 min \n",
      " 66   | 0.0880  | 0.2051  | 0.6115  |  0 hr 06 min \n",
      " 67   | 0.0891  | 0.1874  | 0.6193  |  0 hr 06 min \n",
      " 68   | 0.0848  | 0.1868  | 0.6114  |  0 hr 06 min \n",
      " 69   | 0.0913  | 0.2066  | 0.6355  |  0 hr 06 min \n",
      " 70   | 0.0837  | 0.1833  | 0.6151  |  0 hr 06 min \n",
      " 71   | 0.0948  | 0.2338  | 0.6531  |  0 hr 06 min \n",
      " 72   | 0.1005  | 0.2116  | 0.6216  |  0 hr 06 min \n",
      " 73   | 0.0863  | 0.2116  | 0.6400  |  0 hr 06 min \n",
      " 74   | 0.0882  | 0.2256  | 0.6295  |  0 hr 06 min \n",
      " 75   | 0.0879  | 0.1807  | 0.6107  |  0 hr 06 min \n",
      " 76   | 0.0871  | 0.2436  | 0.6414  |  0 hr 06 min \n",
      " 77   | 0.0818  | 0.2161  | 0.6200  |  0 hr 07 min \n",
      " 78   | 0.0910  | 0.1753  | 0.6269  |  0 hr 07 min \n",
      " 79   | 0.0923  | 0.2026  | 0.6242  |  0 hr 07 min \n",
      " 80   | 0.0815  | 0.1848  | 0.6046  |  0 hr 07 min \n",
      " 81   | 0.0777  | 0.1949  | 0.6319  |  0 hr 07 min \n",
      " 82   | 0.0899  | 0.1775  | 0.6229  |  0 hr 07 min \n",
      " 83   | 0.0774  | 0.1732  | 0.6167  |  0 hr 07 min \n",
      " 84   | 0.0838  | 0.1729  | 0.6210  |  0 hr 07 min \n",
      " 85   | 0.0831  | 0.2554  | 0.6556  |  0 hr 07 min \n",
      " 86   | 0.0773  | 0.1873  | 0.6151  |  0 hr 07 min \n",
      " 87   | 0.0687  | 0.1974  | 0.6343  |  0 hr 07 min \n",
      " 88   | 0.0781  | 0.1720  | 0.6089  |  0 hr 08 min \n",
      " 89   | 0.0699  | 0.2544  | 0.6408  |  0 hr 08 min \n",
      " 90   | 0.0881  | 0.1943  | 0.6346  |  0 hr 08 min \n",
      " 91   | 0.0748  | 0.1721  | 0.6146  |  0 hr 08 min \n",
      " 92   | 0.0767  | 0.1950  | 0.6249  |  0 hr 08 min \n",
      " 93   | 0.0757  | 0.1841  | 0.6347  |  0 hr 08 min \n",
      " 94   | 0.0741  | 0.2126  | 0.6271  |  0 hr 08 min \n",
      " 95   | 0.0797  | 0.1833  | 0.6239  |  0 hr 08 min \n",
      " 96   | 0.0785  | 0.1902  | 0.6289  |  0 hr 08 min \n",
      " 97   | 0.0804  | 0.2292  | 0.6384  |  0 hr 08 min \n",
      " 98   | 0.0755  | 0.1837  | 0.6323  |  0 hr 08 min \n",
      " 99   | 0.0681  | 0.1782  | 0.6197  |  0 hr 08 min \n",
      "fold | epoch | train RMSE | valid RMSE \n",
      "  0   |  80   | 0.1720  | 0.6046  \n",
      "  0   | 1.5701  | 0.9745  | 1.0289  |  0 hr 09 min \n",
      "  1   | 0.9016  | 0.8279  | 0.8929  |  0 hr 09 min \n",
      "  2   | 0.7121  | 0.7538  | 0.8219  |  0 hr 09 min \n",
      "  3   | 0.6269  | 0.8625  | 0.9316  |  0 hr 09 min \n",
      "  4   | 0.5644  | 0.6849  | 0.7731  |  0 hr 09 min \n",
      "  5   | 0.5146  | 0.6416  | 0.7516  |  0 hr 09 min \n",
      "  6   | 0.4538  | 0.6486  | 0.7614  |  0 hr 09 min \n",
      "  7   | 0.4343  | 0.6025  | 0.7354  |  0 hr 09 min \n",
      "  8   | 0.4240  | 0.6338  | 0.7456  |  0 hr 09 min \n",
      "  9   | 0.3735  | 0.5477  | 0.7070  |  0 hr 09 min \n",
      " 10   | 0.3563  | 0.5496  | 0.7180  |  0 hr 09 min \n",
      " 11   | 0.3436  | 0.5267  | 0.6967  |  0 hr 10 min \n",
      " 12   | 0.3283  | 0.4776  | 0.6827  |  0 hr 10 min \n",
      " 13   | 0.2951  | 0.4980  | 0.7022  |  0 hr 10 min \n",
      " 14   | 0.2752  | 0.4584  | 0.6807  |  0 hr 10 min \n",
      " 15   | 0.2704  | 0.4425  | 0.6537  |  0 hr 10 min \n",
      " 16   | 0.2536  | 0.4240  | 0.6561  |  0 hr 10 min \n",
      " 17   | 0.2721  | 0.4424  | 0.6755  |  0 hr 10 min \n",
      " 18   | 0.2397  | 0.3941  | 0.6503  |  0 hr 10 min \n",
      " 19   | 0.2281  | 0.3875  | 0.6640  |  0 hr 10 min \n",
      " 20   | 0.2273  | 0.4358  | 0.6761  |  0 hr 10 min \n",
      " 21   | 0.2227  | 0.3713  | 0.6318  |  0 hr 10 min \n",
      " 22   | 0.2069  | 0.3582  | 0.6448  |  0 hr 10 min \n",
      " 23   | 0.2088  | 0.3633  | 0.6462  |  0 hr 11 min \n",
      " 24   | 0.1917  | 0.3626  | 0.6630  |  0 hr 11 min \n",
      " 25   | 0.1861  | 0.3298  | 0.6398  |  0 hr 11 min \n",
      " 26   | 0.1716  | 0.3396  | 0.6419  |  0 hr 11 min \n",
      " 27   | 0.1697  | 0.3215  | 0.6427  |  0 hr 11 min \n",
      " 28   | 0.1702  | 0.3166  | 0.6487  |  0 hr 11 min \n",
      " 29   | 0.1653  | 0.3232  | 0.6542  |  0 hr 11 min \n",
      " 30   | 0.1568  | 0.3899  | 0.7025  |  0 hr 11 min \n",
      " 31   | 0.1704  | 0.3231  | 0.6699  |  0 hr 11 min \n",
      " 32   | 0.1659  | 0.3304  | 0.6682  |  0 hr 11 min \n",
      " 33   | 0.1418  | 0.2985  | 0.6512  |  0 hr 11 min \n",
      " 34   | 0.1594  | 0.2920  | 0.6604  |  0 hr 11 min \n",
      " 35   | 0.1373  | 0.2780  | 0.6455  |  0 hr 12 min \n",
      " 36   | 0.1214  | 0.2820  | 0.6442  |  0 hr 12 min \n",
      " 37   | 0.1363  | 0.2891  | 0.6500  |  0 hr 12 min \n",
      " 38   | 0.1382  | 0.2747  | 0.6362  |  0 hr 12 min \n",
      " 39   | 0.1312  | 0.2618  | 0.6309  |  0 hr 12 min \n",
      " 40   | 0.1244  | 0.2579  | 0.6381  |  0 hr 12 min \n",
      " 41   | 0.1232  | 0.2791  | 0.6489  |  0 hr 12 min \n",
      " 42   | 0.1215  | 0.2514  | 0.6459  |  0 hr 12 min \n",
      " 43   | 0.1063  | 0.2228  | 0.6330  |  0 hr 12 min \n",
      " 44   | 0.1129  | 0.2245  | 0.6318  |  0 hr 12 min \n",
      " 45   | 0.1074  | 0.2338  | 0.6261  |  0 hr 12 min \n",
      " 46   | 0.1018  | 0.2168  | 0.6507  |  0 hr 12 min \n",
      " 47   | 0.1057  | 0.3406  | 0.6943  |  0 hr 13 min \n",
      " 48   | 0.1165  | 0.2443  | 0.6342  |  0 hr 13 min \n",
      " 49   | 0.1128  | 0.4239  | 0.7275  |  0 hr 13 min \n",
      " 50   | 0.1101  | 0.2474  | 0.6583  |  0 hr 13 min \n",
      " 51   | 0.1017  | 0.2359  | 0.6415  |  0 hr 13 min \n",
      " 52   | 0.1070  | 0.2448  | 0.6386  |  0 hr 13 min \n",
      " 53   | 0.0970  | 0.2227  | 0.6490  |  0 hr 13 min \n",
      " 54   | 0.0966  | 0.2053  | 0.6470  |  0 hr 13 min \n",
      " 55   | 0.0963  | 0.2481  | 0.6459  |  0 hr 13 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56   | 0.0998  | 0.2131  | 0.6355  |  0 hr 13 min \n",
      " 57   | 0.0962  | 0.2021  | 0.6357  |  0 hr 13 min \n",
      " 58   | 0.0897  | 0.2115  | 0.6420  |  0 hr 14 min \n",
      " 59   | 0.0916  | 0.1954  | 0.6342  |  0 hr 14 min \n",
      " 60   | 0.0903  | 0.1999  | 0.6394  |  0 hr 14 min \n",
      " 61   | 0.0939  | 0.2048  | 0.6363  |  0 hr 14 min \n",
      " 62   | 0.0891  | 0.2084  | 0.6355  |  0 hr 14 min \n",
      " 63   | 0.0950  | 0.1993  | 0.6330  |  0 hr 14 min \n",
      " 64   | 0.0875  | 0.2090  | 0.6305  |  0 hr 14 min \n",
      " 65   | 0.0872  | 0.2172  | 0.6345  |  0 hr 14 min \n",
      " 66   | 0.0909  | 0.1987  | 0.6314  |  0 hr 14 min \n",
      " 67   | 0.0924  | 0.1901  | 0.6248  |  0 hr 14 min \n",
      " 68   | 0.0932  | 0.2002  | 0.6333  |  0 hr 14 min \n",
      " 69   | 0.0886  | 0.2031  | 0.6459  |  0 hr 14 min \n",
      " 70   | 0.0799  | 0.1890  | 0.6264  |  0 hr 15 min \n",
      " 71   | 0.0743  | 0.1862  | 0.6282  |  0 hr 15 min \n",
      " 72   | 0.0768  | 0.1873  | 0.6303  |  0 hr 15 min \n",
      " 73   | 0.0999  | 0.1874  | 0.6353  |  0 hr 15 min \n",
      " 74   | 0.0938  | 0.2190  | 0.6472  |  0 hr 15 min \n",
      " 75   | 0.0869  | 0.1957  | 0.6288  |  0 hr 15 min \n",
      " 76   | 0.0841  | 0.2121  | 0.6387  |  0 hr 15 min \n",
      " 77   | 0.0700  | 0.1846  | 0.6355  |  0 hr 15 min \n",
      " 78   | 0.0903  | 0.2072  | 0.6390  |  0 hr 15 min \n",
      " 79   | 0.0813  | 0.1842  | 0.6371  |  0 hr 15 min \n",
      " 80   | 0.0874  | 0.1834  | 0.6450  |  0 hr 15 min \n",
      " 81   | 0.0860  | 0.1897  | 0.6407  |  0 hr 15 min \n",
      " 82   | 0.0823  | 0.1860  | 0.6354  |  0 hr 16 min \n",
      " 83   | 0.0869  | 0.1905  | 0.6405  |  0 hr 16 min \n",
      " 84   | 0.0785  | 0.1742  | 0.6353  |  0 hr 16 min \n",
      " 85   | 0.0707  | 0.1695  | 0.6392  |  0 hr 16 min \n",
      " 86   | 0.0710  | 0.1838  | 0.6348  |  0 hr 16 min \n",
      " 87   | 0.0804  | 0.1886  | 0.6293  |  0 hr 16 min \n",
      " 88   | 0.0673  | 0.1763  | 0.6411  |  0 hr 16 min \n",
      " 89   | 0.0723  | 0.2710  | 0.6605  |  0 hr 16 min \n",
      " 90   | 0.0912  | 0.2027  | 0.6355  |  0 hr 16 min \n",
      " 91   | 0.0850  | 0.2510  | 0.6449  |  0 hr 16 min \n",
      " 92   | 0.0791  | 0.1867  | 0.6456  |  0 hr 17 min \n",
      " 93   | 0.0626  | 0.1655  | 0.6317  |  0 hr 17 min \n",
      " 94   | 0.0714  | 0.1684  | 0.6293  |  0 hr 17 min \n",
      " 95   | 0.0762  | 0.1622  | 0.6349  |  0 hr 17 min \n",
      " 96   | 0.0655  | 0.1642  | 0.6221  |  0 hr 17 min \n",
      " 97   | 0.0672  | 0.1687  | 0.6242  |  0 hr 17 min \n",
      " 98   | 0.0823  | 0.1711  | 0.6275  |  0 hr 17 min \n",
      " 99   | 0.0790  | 0.1689  | 0.6263  |  0 hr 17 min \n",
      " 100  | 0.0647  | 0.1732  | 0.6281  |  0 hr 17 min \n",
      " 101  | 0.0723  | 0.1715  | 0.6216  |  0 hr 17 min \n",
      " 102  | 0.0658  | 0.1643  | 0.6101  |  0 hr 17 min \n",
      " 103  | 0.0720  | 0.1517  | 0.6084  |  0 hr 18 min \n",
      " 104  | 0.0649  | 0.1598  | 0.6238  |  0 hr 18 min \n",
      " 105  | 0.0636  | 0.1537  | 0.6272  |  0 hr 18 min \n",
      " 106  | 0.0636  | 0.1677  | 0.6276  |  0 hr 18 min \n",
      " 107  | 0.0622  | 0.1679  | 0.6244  |  0 hr 18 min \n",
      " 108  | 0.0680  | 0.2167  | 0.6583  |  0 hr 18 min \n",
      " 109  | 0.0722  | 0.2874  | 0.6701  |  0 hr 18 min \n",
      " 110  | 0.0638  | 0.1425  | 0.6288  |  0 hr 18 min \n",
      " 111  | 0.0668  | 0.1611  | 0.6193  |  0 hr 18 min \n",
      " 112  | 0.0718  | 0.2248  | 0.6528  |  0 hr 18 min \n",
      " 113  | 0.0708  | 0.1620  | 0.6289  |  0 hr 19 min \n",
      " 114  | 0.0725  | 0.1732  | 0.6236  |  0 hr 19 min \n",
      " 115  | 0.0602  | 0.1444  | 0.6301  |  0 hr 19 min \n",
      " 116  | 0.0651  | 0.1654  | 0.6366  |  0 hr 19 min \n",
      " 117  | 0.0711  | 0.1802  | 0.6248  |  0 hr 19 min \n",
      " 118  | 0.0647  | 0.1623  | 0.6257  |  0 hr 19 min \n",
      " 119  | 0.0662  | 0.1485  | 0.6286  |  0 hr 19 min \n",
      " 120  | 0.0635  | 0.1919  | 0.6285  |  0 hr 19 min \n",
      " 121  | 0.0751  | 0.2070  | 0.6319  |  0 hr 19 min \n",
      " 122  | 0.0601  | 0.2022  | 0.6365  |  0 hr 19 min \n",
      "fold | epoch | train RMSE | valid RMSE \n",
      "  1   |  103  | 0.1425  | 0.6084  \n",
      "  0   | 1.5607  | 1.2232  | 1.2412  |  0 hr 19 min \n",
      "  1   | 1.0105  | 0.9839  | 1.0126  |  0 hr 19 min \n",
      "  2   | 0.8131  | 0.9418  | 0.9864  |  0 hr 20 min \n",
      "  3   | 0.6858  | 0.7699  | 0.8097  |  0 hr 20 min \n",
      "  4   | 0.6280  | 0.6974  | 0.7299  |  0 hr 20 min \n",
      "  5   | 0.5776  | 0.7174  | 0.7681  |  0 hr 20 min \n",
      "  6   | 0.5219  | 0.6257  | 0.6618  |  0 hr 20 min \n",
      "  7   | 0.4894  | 0.6214  | 0.6808  |  0 hr 20 min \n",
      "  8   | 0.4452  | 0.6307  | 0.6873  |  0 hr 20 min \n",
      "  9   | 0.4157  | 0.5696  | 0.6409  |  0 hr 20 min \n",
      " 10   | 0.4053  | 0.5583  | 0.6563  |  0 hr 20 min \n",
      " 11   | 0.3970  | 0.5414  | 0.6400  |  0 hr 20 min \n",
      " 12   | 0.3734  | 0.5030  | 0.6314  |  0 hr 20 min \n",
      " 13   | 0.3440  | 0.5516  | 0.6904  |  0 hr 21 min \n",
      " 14   | 0.3349  | 0.5523  | 0.6801  |  0 hr 21 min \n",
      " 15   | 0.3146  | 0.5358  | 0.6806  |  0 hr 21 min \n",
      " 16   | 0.3203  | 0.4495  | 0.6196  |  0 hr 21 min \n",
      " 17   | 0.2751  | 0.5114  | 0.6509  |  0 hr 21 min \n",
      " 18   | 0.2942  | 0.4548  | 0.6324  |  0 hr 21 min \n",
      " 19   | 0.2542  | 0.4267  | 0.6174  |  0 hr 21 min \n",
      " 20   | 0.2506  | 0.4431  | 0.6365  |  0 hr 21 min \n",
      " 21   | 0.2384  | 0.4943  | 0.6802  |  0 hr 21 min \n",
      " 22   | 0.2369  | 0.4179  | 0.6451  |  0 hr 21 min \n",
      " 23   | 0.2199  | 0.3983  | 0.6205  |  0 hr 21 min \n",
      " 24   | 0.2221  | 0.3750  | 0.6073  |  0 hr 22 min \n",
      " 25   | 0.2211  | 0.3554  | 0.6130  |  0 hr 22 min \n",
      " 26   | 0.2002  | 0.3690  | 0.6361  |  0 hr 22 min \n",
      " 27   | 0.1898  | 0.3325  | 0.6274  |  0 hr 22 min \n",
      " 28   | 0.1847  | 0.3487  | 0.6197  |  0 hr 22 min \n",
      " 29   | 0.1794  | 0.3334  | 0.6250  |  0 hr 22 min \n",
      " 30   | 0.1702  | 0.3399  | 0.6050  |  0 hr 22 min \n",
      " 31   | 0.1652  | 0.3859  | 0.6319  |  0 hr 22 min \n",
      " 32   | 0.1783  | 0.3090  | 0.6111  |  0 hr 22 min \n",
      " 33   | 0.1548  | 0.2890  | 0.6154  |  0 hr 22 min \n",
      " 34   | 0.1487  | 0.3270  | 0.6217  |  0 hr 22 min \n",
      " 35   | 0.1556  | 0.3007  | 0.6192  |  0 hr 23 min \n",
      " 36   | 0.1604  | 0.3653  | 0.6659  |  0 hr 23 min \n",
      " 37   | 0.1465  | 0.2650  | 0.6156  |  0 hr 23 min \n",
      " 38   | 0.1312  | 0.2855  | 0.6232  |  0 hr 23 min \n",
      " 39   | 0.1315  | 0.2796  | 0.6232  |  0 hr 23 min \n",
      " 40   | 0.1300  | 0.2644  | 0.6119  |  0 hr 23 min \n",
      " 41   | 0.1251  | 0.2639  | 0.6209  |  0 hr 23 min \n",
      " 42   | 0.1303  | 0.2365  | 0.6070  |  0 hr 23 min \n",
      " 43   | 0.1283  | 0.2801  | 0.6123  |  0 hr 23 min \n",
      " 44   | 0.1161  | 0.2420  | 0.6176  |  0 hr 23 min \n",
      " 45   | 0.1146  | 0.2429  | 0.6116  |  0 hr 23 min \n",
      " 46   | 0.1175  | 0.2339  | 0.6092  |  0 hr 24 min \n",
      " 47   | 0.1260  | 0.2623  | 0.6333  |  0 hr 24 min \n",
      " 48   | 0.1098  | 0.2422  | 0.6226  |  0 hr 24 min \n",
      " 49   | 0.1204  | 0.2380  | 0.6160  |  0 hr 24 min \n",
      " 50   | 0.1179  | 0.2334  | 0.6040  |  0 hr 24 min \n",
      " 51   | 0.1056  | 0.2575  | 0.6169  |  0 hr 24 min \n",
      " 52   | 0.0996  | 0.2698  | 0.6226  |  0 hr 24 min \n",
      " 53   | 0.0908  | 0.2124  | 0.6065  |  0 hr 24 min \n",
      " 54   | 0.1070  | 0.2180  | 0.5941  |  0 hr 24 min \n",
      " 55   | 0.1079  | 0.2102  | 0.6077  |  0 hr 24 min \n",
      " 56   | 0.1023  | 0.2037  | 0.6180  |  0 hr 24 min \n",
      " 57   | 0.0846  | 0.2197  | 0.6093  |  0 hr 25 min \n",
      " 58   | 0.0939  | 0.2308  | 0.6050  |  0 hr 25 min \n",
      " 59   | 0.0932  | 0.2154  | 0.6182  |  0 hr 25 min \n",
      " 60   | 0.0923  | 0.1937  | 0.6104  |  0 hr 25 min \n",
      " 61   | 0.0890  | 0.2104  | 0.6114  |  0 hr 25 min \n",
      " 62   | 0.1032  | 0.2054  | 0.6081  |  0 hr 25 min \n",
      " 63   | 0.0912  | 0.2133  | 0.6045  |  0 hr 25 min \n",
      " 64   | 0.0851  | 0.2123  | 0.6143  |  0 hr 25 min \n",
      " 65   | 0.1104  | 0.2438  | 0.6096  |  0 hr 25 min \n",
      " 66   | 0.0982  | 0.1961  | 0.6103  |  0 hr 25 min \n",
      " 67   | 0.0992  | 0.2111  | 0.6131  |  0 hr 25 min \n",
      " 68   | 0.0967  | 0.2163  | 0.6046  |  0 hr 25 min \n",
      " 69   | 0.0824  | 0.2114  | 0.6137  |  0 hr 26 min \n",
      " 70   | 0.0847  | 0.1863  | 0.6090  |  0 hr 26 min \n",
      " 71   | 0.0810  | 0.2153  | 0.6128  |  0 hr 26 min \n",
      " 72   | 0.0912  | 0.2216  | 0.6222  |  0 hr 26 min \n",
      " 73   | 0.0837  | 0.1976  | 0.6083  |  0 hr 26 min \n",
      " 74   | 0.0873  | 0.1799  | 0.6054  |  0 hr 26 min \n",
      " 75   | 0.0759  | 0.2056  | 0.6092  |  0 hr 26 min \n",
      " 76   | 0.0893  | 0.2709  | 0.6437  |  0 hr 26 min \n",
      " 77   | 0.0783  | 0.1766  | 0.6021  |  0 hr 26 min \n",
      " 78   | 0.0883  | 0.1810  | 0.6095  |  0 hr 26 min \n",
      " 79   | 0.0777  | 0.1891  | 0.6075  |  0 hr 26 min \n",
      " 80   | 0.0831  | 0.1977  | 0.6110  |  0 hr 27 min \n",
      " 81   | 0.0937  | 0.2396  | 0.6145  |  0 hr 27 min \n",
      " 82   | 0.0782  | 0.1755  | 0.6041  |  0 hr 27 min \n",
      " 83   | 0.0768  | 0.1878  | 0.6140  |  0 hr 27 min \n",
      " 84   | 0.0804  | 0.2298  | 0.6352  |  0 hr 27 min \n",
      " 85   | 0.0716  | 0.1927  | 0.5976  |  0 hr 27 min \n",
      " 86   | 0.0757  | 0.2069  | 0.6221  |  0 hr 27 min \n",
      " 87   | 0.0753  | 0.1701  | 0.5961  |  0 hr 27 min \n",
      " 88   | 0.0710  | 0.1661  | 0.5993  |  0 hr 27 min \n",
      " 89   | 0.0714  | 0.2129  | 0.6030  |  0 hr 27 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90   | 0.0770  | 0.1857  | 0.6095  |  0 hr 27 min \n",
      " 91   | 0.0693  | 0.1719  | 0.6006  |  0 hr 28 min \n",
      " 92   | 0.0796  | 0.1746  | 0.6028  |  0 hr 28 min \n",
      " 93   | 0.0723  | 0.1666  | 0.5991  |  0 hr 28 min \n",
      " 94   | 0.0757  | 0.1687  | 0.5965  |  0 hr 28 min \n",
      " 95   | 0.0755  | 0.1659  | 0.6084  |  0 hr 28 min \n",
      " 96   | 0.0624  | 0.1564  | 0.6045  |  0 hr 28 min \n",
      " 97   | 0.0753  | 0.1816  | 0.6206  |  0 hr 28 min \n",
      " 98   | 0.0673  | 0.2004  | 0.6159  |  0 hr 28 min \n",
      " 99   | 0.0756  | 0.1677  | 0.6078  |  0 hr 28 min \n",
      " 100  | 0.0683  | 0.1742  | 0.6134  |  0 hr 28 min \n",
      " 101  | 0.0699  | 0.2283  | 0.6191  |  0 hr 29 min \n",
      " 102  | 0.0686  | 0.1604  | 0.6040  |  0 hr 29 min \n",
      " 103  | 0.0637  | 0.1606  | 0.5977  |  0 hr 29 min \n",
      " 104  | 0.0751  | 0.2361  | 0.6130  |  0 hr 29 min \n",
      " 105  | 0.0724  | 0.1501  | 0.6016  |  0 hr 29 min \n",
      " 106  | 0.0824  | 0.1739  | 0.5971  |  0 hr 29 min \n",
      " 107  | 0.0636  | 0.3050  | 0.6480  |  0 hr 29 min \n",
      " 108  | 0.0666  | 0.1592  | 0.6003  |  0 hr 29 min \n",
      " 109  | 0.0640  | 0.1573  | 0.6011  |  0 hr 29 min \n",
      " 110  | 0.0693  | 0.1598  | 0.6038  |  0 hr 29 min \n",
      " 111  | 0.0554  | 0.1563  | 0.5917  |  0 hr 29 min \n",
      " 112  | 0.0650  | 0.2111  | 0.6149  |  0 hr 29 min \n",
      " 113  | 0.0683  | 0.1670  | 0.5977  |  0 hr 30 min \n",
      " 114  | 0.0670  | 0.1659  | 0.5954  |  0 hr 30 min \n",
      " 115  | 0.0703  | 0.1727  | 0.6008  |  0 hr 30 min \n",
      " 116  | 0.0644  | 0.1580  | 0.5853  |  0 hr 30 min \n",
      " 117  | 0.0675  | 0.1761  | 0.6099  |  0 hr 30 min \n",
      " 118  | 0.0616  | 0.2130  | 0.5999  |  0 hr 30 min \n",
      " 119  | 0.0620  | 0.1662  | 0.6076  |  0 hr 30 min \n",
      " 120  | 0.0615  | 0.1676  | 0.5984  |  0 hr 30 min \n",
      " 121  | 0.0632  | 0.1506  | 0.5917  |  0 hr 30 min \n",
      " 122  | 0.0628  | 0.1614  | 0.6003  |  0 hr 30 min \n",
      " 123  | 0.0629  | 0.1722  | 0.5944  |  0 hr 31 min \n",
      " 124  | 0.0605  | 0.1355  | 0.5900  |  0 hr 31 min \n",
      " 125  | 0.0551  | 0.1624  | 0.5945  |  0 hr 31 min \n",
      " 126  | 0.0522  | 0.1599  | 0.5985  |  0 hr 31 min \n",
      " 127  | 0.0555  | 0.1434  | 0.5993  |  0 hr 31 min \n",
      " 128  | 0.0623  | 0.1620  | 0.6055  |  0 hr 31 min \n",
      " 129  | 0.0518  | 0.1450  | 0.6000  |  0 hr 31 min \n",
      " 130  | 0.0579  | 0.1419  | 0.5940  |  0 hr 31 min \n",
      " 131  | 0.0569  | 0.1474  | 0.6031  |  0 hr 31 min \n",
      " 132  | 0.0695  | 0.2097  | 0.6218  |  0 hr 31 min \n",
      " 133  | 0.0640  | 0.1700  | 0.6008  |  0 hr 32 min \n",
      " 134  | 0.0666  | 0.2342  | 0.6137  |  0 hr 32 min \n",
      " 135  | 0.0585  | 0.1634  | 0.5988  |  0 hr 32 min \n",
      "fold | epoch | train RMSE | valid RMSE \n",
      "  2   |  116  | 0.1355  | 0.5853  \n",
      "  0   | 1.6858  | 0.9884  | 1.0205  |  0 hr 32 min \n",
      "  1   | 0.9004  | 0.8921  | 0.9355  |  0 hr 32 min \n",
      "  2   | 0.7184  | 0.9188  | 0.9451  |  0 hr 32 min \n",
      "  3   | 0.6486  | 0.7416  | 0.7905  |  0 hr 32 min \n",
      "  4   | 0.5991  | 0.6889  | 0.7514  |  0 hr 32 min \n",
      "  5   | 0.5545  | 0.6514  | 0.7316  |  0 hr 32 min \n",
      "  6   | 0.4870  | 0.6748  | 0.7853  |  0 hr 33 min \n",
      "  7   | 0.4633  | 0.5806  | 0.6742  |  0 hr 33 min \n",
      "  8   | 0.4187  | 0.6174  | 0.7243  |  0 hr 33 min \n",
      "  9   | 0.3949  | 0.5618  | 0.6896  |  0 hr 33 min \n",
      " 10   | 0.3823  | 0.5307  | 0.6697  |  0 hr 33 min \n",
      " 11   | 0.3719  | 0.5282  | 0.7018  |  0 hr 33 min \n",
      " 12   | 0.3666  | 0.5145  | 0.7097  |  0 hr 33 min \n",
      " 13   | 0.3277  | 0.4747  | 0.6609  |  0 hr 33 min \n",
      " 14   | 0.2924  | 0.5650  | 0.7013  |  0 hr 33 min \n",
      " 15   | 0.3036  | 0.4890  | 0.6791  |  0 hr 34 min \n",
      " 16   | 0.2871  | 0.4499  | 0.6888  |  0 hr 34 min \n",
      " 17   | 0.2919  | 0.4269  | 0.6639  |  0 hr 34 min \n",
      " 18   | 0.2783  | 0.4260  | 0.6607  |  0 hr 34 min \n",
      " 19   | 0.2572  | 0.4383  | 0.6647  |  0 hr 34 min \n",
      " 20   | 0.2268  | 0.4146  | 0.6561  |  0 hr 34 min \n",
      " 21   | 0.2303  | 0.3996  | 0.6577  |  0 hr 34 min \n",
      " 22   | 0.2375  | 0.4045  | 0.6873  |  0 hr 34 min \n",
      " 23   | 0.2116  | 0.3956  | 0.6922  |  0 hr 35 min \n",
      " 24   | 0.2191  | 0.3855  | 0.6618  |  0 hr 35 min \n",
      " 25   | 0.1970  | 0.3629  | 0.6650  |  0 hr 35 min \n",
      " 26   | 0.1833  | 0.3442  | 0.6728  |  0 hr 35 min \n",
      " 27   | 0.1800  | 0.3196  | 0.6541  |  0 hr 35 min \n",
      " 28   | 0.1745  | 0.3065  | 0.6553  |  0 hr 35 min \n",
      " 29   | 0.1713  | 0.3483  | 0.6746  |  0 hr 35 min \n",
      " 30   | 0.1507  | 0.3272  | 0.6600  |  0 hr 35 min \n",
      " 31   | 0.1811  | 0.3332  | 0.6637  |  0 hr 35 min \n",
      " 32   | 0.1831  | 0.3429  | 0.6776  |  0 hr 35 min \n",
      " 33   | 0.1646  | 0.2866  | 0.6425  |  0 hr 36 min \n",
      " 34   | 0.1432  | 0.3339  | 0.6612  |  0 hr 36 min \n",
      " 35   | 0.1437  | 0.2625  | 0.6488  |  0 hr 36 min \n",
      " 36   | 0.1325  | 0.2931  | 0.6513  |  0 hr 36 min \n",
      " 37   | 0.1473  | 0.2700  | 0.6629  |  0 hr 36 min \n",
      " 38   | 0.1325  | 0.2715  | 0.6600  |  0 hr 36 min \n",
      " 39   | 0.1370  | 0.2977  | 0.6818  |  0 hr 36 min \n",
      " 40   | 0.1305  | 0.2539  | 0.6405  |  0 hr 36 min \n",
      " 41   | 0.1256  | 0.2960  | 0.6631  |  0 hr 36 min \n",
      " 42   | 0.1252  | 0.2467  | 0.6380  |  0 hr 37 min \n",
      " 43   | 0.1182  | 0.2452  | 0.6555  |  0 hr 37 min \n",
      " 44   | 0.1134  | 0.2541  | 0.6385  |  0 hr 37 min \n",
      " 45   | 0.1281  | 0.2653  | 0.6711  |  0 hr 37 min \n",
      " 46   | 0.1152  | 0.2530  | 0.6768  |  0 hr 37 min \n",
      " 47   | 0.1097  | 0.2840  | 0.6866  |  0 hr 37 min \n",
      " 48   | 0.1056  | 0.2604  | 0.6574  |  0 hr 37 min \n",
      " 49   | 0.1022  | 0.2331  | 0.6523  |  0 hr 37 min \n",
      " 50   | 0.0924  | 0.2633  | 0.6583  |  0 hr 38 min \n",
      " 51   | 0.1085  | 0.2244  | 0.6498  |  0 hr 38 min \n",
      " 52   | 0.1050  | 0.2410  | 0.6606  |  0 hr 38 min \n",
      " 53   | 0.1021  | 0.2629  | 0.6501  |  0 hr 38 min \n",
      " 54   | 0.1007  | 0.2117  | 0.6581  |  0 hr 38 min \n",
      " 55   | 0.0944  | 0.2218  | 0.6507  |  0 hr 38 min \n",
      " 56   | 0.0957  | 0.2444  | 0.6733  |  0 hr 38 min \n",
      " 57   | 0.1027  | 0.2461  | 0.6803  |  0 hr 39 min \n",
      " 58   | 0.0951  | 0.2127  | 0.6472  |  0 hr 39 min \n",
      " 59   | 0.0965  | 0.2598  | 0.6725  |  0 hr 39 min \n",
      " 60   | 0.0868  | 0.2710  | 0.6887  |  0 hr 39 min \n",
      " 61   | 0.1025  | 0.2375  | 0.6658  |  0 hr 39 min \n",
      " 62   | 0.1013  | 0.2207  | 0.6695  |  0 hr 39 min \n",
      " 63   | 0.0972  | 0.2077  | 0.6505  |  0 hr 39 min \n",
      " 64   | 0.0885  | 0.1998  | 0.6491  |  0 hr 39 min \n",
      " 65   | 0.0898  | 0.2055  | 0.6562  |  0 hr 40 min \n",
      " 66   | 0.0836  | 0.2044  | 0.6639  |  0 hr 40 min \n",
      " 67   | 0.0802  | 0.2039  | 0.6690  |  0 hr 40 min \n",
      " 68   | 0.1151  | 0.1998  | 0.6556  |  0 hr 40 min \n",
      " 69   | 0.0830  | 0.1882  | 0.6541  |  0 hr 40 min \n",
      " 70   | 0.0759  | 0.2111  | 0.6709  |  0 hr 40 min \n",
      " 71   | 0.0835  | 0.1943  | 0.6633  |  0 hr 40 min \n",
      " 72   | 0.0775  | 0.1897  | 0.6672  |  0 hr 41 min \n",
      " 73   | 0.0923  | 0.1951  | 0.6594  |  0 hr 41 min \n",
      " 74   | 0.0979  | 0.2121  | 0.6604  |  0 hr 41 min \n",
      " 75   | 0.0782  | 0.1960  | 0.6524  |  0 hr 41 min \n",
      " 76   | 0.0766  | 0.1734  | 0.6583  |  0 hr 41 min \n",
      " 77   | 0.0757  | 0.1736  | 0.6477  |  0 hr 41 min \n",
      " 78   | 0.0821  | 0.2047  | 0.6648  |  0 hr 41 min \n",
      " 79   | 0.0785  | 0.1790  | 0.6433  |  0 hr 42 min \n",
      " 80   | 0.0739  | 0.2240  | 0.6650  |  0 hr 42 min \n",
      " 81   | 0.0798  | 0.1692  | 0.6379  |  0 hr 42 min \n",
      " 82   | 0.0763  | 0.1828  | 0.6388  |  0 hr 42 min \n",
      " 83   | 0.0693  | 0.1722  | 0.6520  |  0 hr 42 min \n",
      " 84   | 0.0720  | 0.1789  | 0.6509  |  0 hr 42 min \n",
      " 85   | 0.0757  | 0.1847  | 0.6454  |  0 hr 42 min \n",
      " 86   | 0.0744  | 0.1708  | 0.6522  |  0 hr 43 min \n",
      " 87   | 0.0710  | 0.1932  | 0.6519  |  0 hr 43 min \n",
      " 88   | 0.0714  | 0.1927  | 0.6516  |  0 hr 43 min \n",
      " 89   | 0.0717  | 0.2062  | 0.6605  |  0 hr 43 min \n",
      " 90   | 0.0621  | 0.1767  | 0.6539  |  0 hr 43 min \n",
      " 91   | 0.0693  | 0.1796  | 0.6421  |  0 hr 43 min \n",
      " 92   | 0.0742  | 0.1877  | 0.6424  |  0 hr 43 min \n",
      " 93   | 0.0738  | 0.2210  | 0.6661  |  0 hr 44 min \n",
      " 94   | 0.0720  | 0.2207  | 0.6555  |  0 hr 44 min \n",
      " 95   | 0.0760  | 0.1779  | 0.6449  |  0 hr 44 min \n",
      " 96   | 0.0679  | 0.1700  | 0.6325  |  0 hr 44 min \n",
      " 97   | 0.0756  | 0.1610  | 0.6415  |  0 hr 44 min \n",
      " 98   | 0.0656  | 0.2411  | 0.6714  |  0 hr 44 min \n",
      " 99   | 0.0767  | 0.2202  | 0.6617  |  0 hr 44 min \n",
      " 100  | 0.0782  | 0.1724  | 0.6339  |  0 hr 45 min \n",
      " 101  | 0.0648  | 0.1794  | 0.6443  |  0 hr 45 min \n",
      " 102  | 0.0637  | 0.1907  | 0.6588  |  0 hr 45 min \n",
      " 103  | 0.0647  | 0.1836  | 0.6393  |  0 hr 45 min \n",
      " 104  | 0.0685  | 0.2101  | 0.6574  |  0 hr 45 min \n",
      " 105  | 0.0684  | 0.1592  | 0.6412  |  0 hr 45 min \n",
      " 106  | 0.0667  | 0.1713  | 0.6566  |  0 hr 46 min \n",
      " 107  | 0.0736  | 0.1620  | 0.6462  |  0 hr 46 min \n",
      " 108  | 0.0876  | 0.1475  | 0.6422  |  0 hr 46 min \n",
      " 109  | 0.0638  | 0.1596  | 0.6397  |  0 hr 46 min \n",
      " 110  | 0.0675  | 0.1825  | 0.6570  |  0 hr 46 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 111  | 0.0596  | 0.1702  | 0.6517  |  0 hr 46 min \n",
      " 112  | 0.0683  | 0.2011  | 0.6523  |  0 hr 47 min \n",
      " 113  | 0.0655  | 0.1736  | 0.6508  |  0 hr 47 min \n",
      " 114  | 0.0740  | 0.1937  | 0.6546  |  0 hr 47 min \n",
      " 115  | 0.0711  | 0.1968  | 0.6580  |  0 hr 47 min \n",
      " 116  | 0.0587  | 0.2134  | 0.6637  |  0 hr 47 min \n",
      " 117  | 0.0645  | 0.1557  | 0.6408  |  0 hr 47 min \n",
      " 118  | 0.0691  | 0.1556  | 0.6376  |  0 hr 48 min \n",
      " 119  | 0.0628  | 0.1660  | 0.6404  |  0 hr 48 min \n",
      "fold | epoch | train RMSE | valid RMSE \n",
      "  3   |  96   | 0.1475  | 0.6325  \n",
      "  0   | 1.6110  | 1.3965  | 1.4880  |  0 hr 48 min \n",
      "  1   | 0.7799  | 0.9757  | 1.0576  |  0 hr 48 min \n",
      "  2   | 0.7005  | 0.7806  | 0.8694  |  0 hr 48 min \n",
      "  3   | 0.5538  | 0.6950  | 0.7882  |  0 hr 48 min \n",
      "  4   | 0.4953  | 0.6831  | 0.7772  |  0 hr 49 min \n",
      "  5   | 0.4681  | 0.5827  | 0.7308  |  0 hr 49 min \n",
      "  6   | 0.4384  | 0.5702  | 0.7132  |  0 hr 49 min \n",
      "  7   | 0.4062  | 0.5842  | 0.7519  |  0 hr 49 min \n",
      "  8   | 0.3869  | 0.5873  | 0.7752  |  0 hr 49 min \n",
      "  9   | 0.3618  | 0.5524  | 0.7132  |  0 hr 49 min \n",
      " 10   | 0.3366  | 0.5458  | 0.7327  |  0 hr 50 min \n",
      " 11   | 0.3365  | 0.5587  | 0.7200  |  0 hr 50 min \n",
      " 12   | 0.3291  | 0.5228  | 0.7510  |  0 hr 50 min \n",
      " 13   | 0.3055  | 0.5355  | 0.7598  |  0 hr 50 min \n",
      " 14   | 0.2993  | 0.4708  | 0.7024  |  0 hr 50 min \n",
      " 15   | 0.2878  | 0.4586  | 0.6791  |  0 hr 50 min \n",
      " 16   | 0.2796  | 0.4430  | 0.6775  |  0 hr 50 min \n",
      " 17   | 0.2755  | 0.4888  | 0.7594  |  0 hr 50 min \n",
      " 18   | 0.2579  | 0.4054  | 0.6610  |  0 hr 51 min \n",
      " 19   | 0.2422  | 0.4307  | 0.6885  |  0 hr 51 min \n",
      " 20   | 0.2516  | 0.4143  | 0.6780  |  0 hr 51 min \n",
      " 21   | 0.2599  | 0.4524  | 0.7310  |  0 hr 51 min \n",
      " 22   | 0.2168  | 0.3924  | 0.6728  |  0 hr 51 min \n",
      " 23   | 0.2102  | 0.3881  | 0.6688  |  0 hr 51 min \n",
      " 24   | 0.2061  | 0.3458  | 0.6709  |  0 hr 51 min \n",
      " 25   | 0.1889  | 0.3502  | 0.6892  |  0 hr 52 min \n",
      " 26   | 0.1795  | 0.3382  | 0.6835  |  0 hr 52 min \n",
      " 27   | 0.1952  | 0.4443  | 0.6973  |  0 hr 52 min \n",
      " 28   | 0.1785  | 0.3387  | 0.6709  |  0 hr 52 min \n",
      " 29   | 0.1797  | 0.3127  | 0.6737  |  0 hr 52 min \n",
      " 30   | 0.1643  | 0.3306  | 0.6672  |  0 hr 52 min \n",
      " 31   | 0.1660  | 0.3078  | 0.6714  |  0 hr 52 min \n",
      " 32   | 0.1511  | 0.2870  | 0.6763  |  0 hr 53 min \n",
      " 33   | 0.1555  | 0.3274  | 0.6753  |  0 hr 53 min \n",
      " 34   | 0.1524  | 0.3860  | 0.6901  |  0 hr 53 min \n",
      " 35   | 0.1464  | 0.2968  | 0.6662  |  0 hr 53 min \n",
      " 36   | 0.1324  | 0.2634  | 0.6737  |  0 hr 53 min \n",
      " 37   | 0.1332  | 0.2978  | 0.6642  |  0 hr 53 min \n",
      " 38   | 0.1318  | 0.2762  | 0.6866  |  0 hr 53 min \n",
      " 39   | 0.1310  | 0.2676  | 0.6857  |  0 hr 54 min \n",
      " 40   | 0.1280  | 0.2648  | 0.6878  |  0 hr 54 min \n",
      " 41   | 0.1257  | 0.3594  | 0.6978  |  0 hr 54 min \n",
      " 42   | 0.1251  | 0.2578  | 0.6782  |  0 hr 54 min \n",
      " 43   | 0.1195  | 0.2725  | 0.6774  |  0 hr 54 min \n",
      " 44   | 0.1210  | 0.2609  | 0.6652  |  0 hr 54 min \n",
      " 45   | 0.1129  | 0.2593  | 0.6691  |  0 hr 54 min \n",
      " 46   | 0.1243  | 0.2324  | 0.6585  |  0 hr 55 min \n",
      " 47   | 0.1038  | 0.2339  | 0.6612  |  0 hr 55 min \n",
      " 48   | 0.1083  | 0.2344  | 0.6622  |  0 hr 55 min \n",
      " 49   | 0.1116  | 0.2403  | 0.6547  |  0 hr 55 min \n",
      " 50   | 0.1184  | 0.2172  | 0.6537  |  0 hr 55 min \n",
      " 51   | 0.0968  | 0.2270  | 0.6653  |  0 hr 55 min \n",
      " 52   | 0.1130  | 0.2353  | 0.6568  |  0 hr 55 min \n",
      " 53   | 0.0935  | 0.2387  | 0.6585  |  0 hr 55 min \n",
      " 54   | 0.0876  | 0.2090  | 0.6444  |  0 hr 56 min \n",
      " 55   | 0.1088  | 0.2503  | 0.6695  |  0 hr 56 min \n",
      " 56   | 0.0946  | 0.2256  | 0.6533  |  0 hr 56 min \n",
      " 57   | 0.0928  | 0.2139  | 0.6680  |  0 hr 56 min \n",
      " 58   | 0.1094  | 0.2425  | 0.6571  |  0 hr 56 min \n",
      " 59   | 0.1071  | 0.2012  | 0.6696  |  0 hr 56 min \n",
      " 60   | 0.0924  | 0.2312  | 0.6881  |  0 hr 56 min \n",
      " 61   | 0.0892  | 0.2057  | 0.6745  |  0 hr 56 min \n",
      " 62   | 0.0935  | 0.2046  | 0.6593  |  0 hr 56 min \n",
      " 63   | 0.0941  | 0.2017  | 0.6723  |  0 hr 57 min \n",
      " 64   | 0.0892  | 0.2625  | 0.6828  |  0 hr 57 min \n",
      " 65   | 0.0883  | 0.1899  | 0.6635  |  0 hr 57 min \n",
      " 66   | 0.1006  | 0.2227  | 0.6866  |  0 hr 57 min \n",
      " 67   | 0.0824  | 0.2202  | 0.6863  |  0 hr 57 min \n",
      " 68   | 0.0950  | 0.2118  | 0.6776  |  0 hr 57 min \n",
      " 69   | 0.1048  | 0.2253  | 0.6764  |  0 hr 57 min \n",
      " 70   | 0.0827  | 0.2143  | 0.6458  |  0 hr 57 min \n",
      " 71   | 0.0797  | 0.1919  | 0.6584  |  0 hr 58 min \n",
      " 72   | 0.0803  | 0.2004  | 0.6667  |  0 hr 58 min \n",
      " 73   | 0.0933  | 0.2154  | 0.6784  |  0 hr 58 min \n",
      " 74   | 0.0725  | 0.1791  | 0.6551  |  0 hr 58 min \n",
      " 75   | 0.0734  | 0.1751  | 0.6679  |  0 hr 58 min \n",
      " 76   | 0.0742  | 0.1958  | 0.6662  |  0 hr 58 min \n",
      " 77   | 0.0770  | 0.2222  | 0.6625  |  0 hr 58 min \n",
      " 78   | 0.0825  | 0.2086  | 0.6577  |  0 hr 58 min \n",
      " 79   | 0.0703  | 0.1739  | 0.6770  |  0 hr 59 min \n",
      " 80   | 0.0676  | 0.2215  | 0.6880  |  0 hr 59 min \n",
      " 81   | 0.0800  | 0.2402  | 0.6580  |  0 hr 59 min \n",
      " 82   | 0.0876  | 0.1820  | 0.6712  |  0 hr 59 min \n",
      " 83   | 0.0909  | 0.2092  | 0.6627  |  0 hr 59 min \n",
      " 84   | 0.0758  | 0.1887  | 0.6730  |  0 hr 59 min \n",
      " 85   | 0.0863  | 0.2109  | 0.6819  |  0 hr 59 min \n",
      " 86   | 0.0840  | 0.1934  | 0.6610  |  0 hr 59 min \n",
      " 87   | 0.0775  | 0.1871  | 0.6672  |  1 hr 00 min \n",
      " 88   | 0.0753  | 0.1852  | 0.6816  |  1 hr 00 min \n",
      " 89   | 0.0747  | 0.1858  | 0.6703  |  1 hr 00 min \n",
      " 90   | 0.0699  | 0.2550  | 0.7084  |  1 hr 00 min \n",
      "fold | epoch | train RMSE | valid RMSE \n",
      "  4   |  54   | 0.1739  | 0.6444  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'log/{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train RMSE |  valid RMSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(5):\n",
    "    \n",
    "    model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_RMSE\"] = 800\n",
    "    best_param[\"valid_RMSE\"] = 800\n",
    "    for epoch in range(800):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_RMSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_RMSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'min')  \n",
    "        log.write(f.format(epoch, losses, train_RMSE, valid_RMSE, timing))\n",
    "        \n",
    "        if train_RMSE < best_param[\"train_RMSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_RMSE\"] = train_RMSE\n",
    "        if valid_RMSE < best_param[\"valid_RMSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_RMSE\"] = valid_RMSE\n",
    "#             if valid_RMSE < 0.35:\n",
    "#                  torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "        if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train RMSE | valid RMSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_RMSE\"],best_param[\"valid_RMSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model\n",
    "# best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "# test_MAE, test_MSE = eval(model, test_df)\n",
    "# print(\"best epoch:\",best_param[\"test_epoch\"],\"\\n\",\"test MSE:\",test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(20):\n",
    "#     losses = train(smiles_list[valid_fold[fold_index]])\n",
    "#     print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
