{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP.featurizing import graph_dict\n",
    "from AttentiveFP.AttentiveLayers_new import Fingerprint, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1128\n",
      "number of successfully processed smiles:  1128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'solubility'\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "raw_filename = \"../data/delaney-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \", len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 16\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "K = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/delaney-processed.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19717\n",
      "preprocess.0.linear.weight torch.Size([16, 39])\n",
      "preprocess.0.linear.bias torch.Size([16])\n",
      "preprocess.0.bn.weight torch.Size([16])\n",
      "preprocess.0.bn.bias torch.Size([16])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.0.align.weight torch.Size([1, 32])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.0.attend.linear.bias torch.Size([16])\n",
      "propagate.0.attend.bn.weight torch.Size([16])\n",
      "propagate.0.attend.bn.bias torch.Size([16])\n",
      "propagate.0.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.0.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.0.gru.bias_ih torch.Size([48])\n",
      "propagate.0.gru.bias_hh torch.Size([48])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([16, 26])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([16])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([16])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([16])\n",
      "propagate.1.align.weight torch.Size([1, 32])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([16, 16])\n",
      "propagate.1.attend.linear.bias torch.Size([16])\n",
      "propagate.1.attend.bn.weight torch.Size([16])\n",
      "propagate.1.attend.bn.bias torch.Size([16])\n",
      "propagate.1.gru.weight_ih torch.Size([48, 16])\n",
      "propagate.1.gru.weight_hh torch.Size([48, 16])\n",
      "propagate.1.gru.bias_ih torch.Size([48])\n",
      "propagate.1.gru.bias_hh torch.Size([48])\n",
      "superGather.0.align.weight torch.Size([1, 32])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([16, 16])\n",
      "superGather.0.attend.linear.bias torch.Size([16])\n",
      "superGather.0.attend.bn.weight torch.Size([16])\n",
      "superGather.0.attend.bn.bias torch.Size([16])\n",
      "superGather.0.gru.weight_ih torch.Size([48, 16])\n",
      "superGather.0.gru.weight_hh torch.Size([48, 16])\n",
      "superGather.0.gru.bias_ih torch.Size([48])\n",
      "superGather.0.gru.bias_hh torch.Size([48])\n",
      "superGather.1.align.weight torch.Size([1, 32])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([16, 16])\n",
      "superGather.1.attend.linear.bias torch.Size([16])\n",
      "superGather.1.attend.bn.weight torch.Size([16])\n",
      "superGather.1.attend.bn.bias torch.Size([16])\n",
      "superGather.1.gru.weight_ih torch.Size([48, 16])\n",
      "superGather.1.gru.weight_hh torch.Size([48, 16])\n",
      "superGather.1.gru.bias_ih torch.Size([48])\n",
      "superGather.1.gru.bias_hh torch.Size([48])\n",
      "predict.0.linear.weight torch.Size([512, 16])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([1, 512])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = Logger()\n",
    "# log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "# f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "# log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "# start = timer()\n",
    "\n",
    "# best_param ={}\n",
    "# best_param[\"train_epoch\"] = 0\n",
    "# best_param[\"valid_epoch\"] = 0\n",
    "# best_param[\"train_MSE\"] = 9e8\n",
    "# best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "# fold_index = 0\n",
    "# for epoch in range(800):\n",
    "#     losses = train(smiles_list[train_fold[fold_index]])\n",
    "#     traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "#     valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "\n",
    "#     timing = time_to_str((timer() - start), 'min')  \n",
    "#     log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "\n",
    "#     if train_MSE < best_param[\"train_MSE\"]:\n",
    "#         best_param[\"train_epoch\"] = epoch\n",
    "#         best_param[\"train_MSE\"] = train_MSE\n",
    "#     if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "#         best_param[\"valid_epoch\"] = epoch\n",
    "#         best_param[\"valid_MSE\"] = valid_MSE\n",
    "# #         if valid_MSE < 0.35:\n",
    "# #              torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "#     if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "#         break\n",
    "# print(best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train MSE |  valid MSE |  time \n",
      "  0   | 9.9449  | 9.4764  | 9.6670  |  0 hr 00 min \n",
      "  1   | 3.1866  | 4.5071  | 5.0465  |  0 hr 00 min \n",
      "  2   | 2.1711  | 2.9224  | 3.5353  |  0 hr 00 min \n",
      "  3   | 2.2668  | 2.2630  | 2.8585  |  0 hr 00 min \n",
      "  4   | 1.4736  | 2.4344  | 2.9446  |  0 hr 00 min \n",
      "  5   | 1.1951  | 2.1671  | 2.6415  |  0 hr 00 min \n",
      "  6   | 1.1982  | 1.9368  | 2.3459  |  0 hr 00 min \n",
      "  7   | 0.9696  | 1.2259  | 1.5812  |  0 hr 00 min \n",
      "  8   | 0.8360  | 0.9126  | 1.1658  |  0 hr 00 min \n",
      "  9   | 0.7735  | 0.7212  | 0.8642  |  0 hr 00 min \n",
      " 10   | 0.6908  | 0.6329  | 0.7842  |  0 hr 00 min \n",
      " 11   | 0.6582  | 0.7852  | 0.9463  |  0 hr 00 min \n",
      " 12   | 0.5970  | 0.5293  | 0.6171  |  0 hr 00 min \n",
      " 13   | 0.5828  | 0.4551  | 0.5811  |  0 hr 00 min \n",
      " 14   | 0.5293  | 0.4343  | 0.5389  |  0 hr 00 min \n",
      " 15   | 0.5196  | 0.3808  | 0.5125  |  0 hr 00 min \n",
      " 16   | 0.5158  | 0.4200  | 0.5714  |  0 hr 00 min \n",
      " 17   | 0.4944  | 0.3849  | 0.5042  |  0 hr 00 min \n",
      " 18   | 0.4624  | 0.3788  | 0.5321  |  0 hr 00 min \n",
      " 19   | 0.4630  | 0.3619  | 0.5373  |  0 hr 00 min \n",
      " 20   | 0.4666  | 0.3203  | 0.4836  |  0 hr 00 min \n",
      " 21   | 0.5691  | 0.3485  | 0.5389  |  0 hr 00 min \n",
      " 22   | 0.4417  | 0.3461  | 0.4849  |  0 hr 00 min \n",
      " 23   | 0.4628  | 0.3405  | 0.4555  |  0 hr 00 min \n",
      " 24   | 0.4771  | 0.3178  | 0.5087  |  0 hr 00 min \n",
      " 25   | 0.4528  | 0.3152  | 0.4757  |  0 hr 00 min \n",
      " 26   | 0.4890  | 0.3617  | 0.5457  |  0 hr 00 min \n",
      " 27   | 0.4606  | 0.3374  | 0.4865  |  0 hr 00 min \n",
      " 28   | 0.4075  | 0.2870  | 0.4371  |  0 hr 00 min \n",
      " 29   | 0.4034  | 0.3022  | 0.4594  |  0 hr 00 min \n",
      " 30   | 0.3532  | 0.3177  | 0.5195  |  0 hr 00 min \n",
      " 31   | 0.3723  | 0.2631  | 0.4786  |  0 hr 00 min \n",
      " 32   | 0.3503  | 0.2838  | 0.4437  |  0 hr 00 min \n",
      " 33   | 0.3880  | 0.2714  | 0.5035  |  0 hr 00 min \n",
      " 34   | 0.3512  | 0.2820  | 0.4733  |  0 hr 00 min \n",
      " 35   | 0.3565  | 0.2386  | 0.4349  |  0 hr 00 min \n",
      " 36   | 0.3445  | 0.2802  | 0.5039  |  0 hr 00 min \n",
      " 37   | 0.3363  | 0.2495  | 0.4327  |  0 hr 01 min \n",
      " 38   | 0.3950  | 0.2304  | 0.4387  |  0 hr 01 min \n",
      " 39   | 0.3192  | 0.2375  | 0.4530  |  0 hr 01 min \n",
      " 40   | 0.3043  | 0.2540  | 0.4731  |  0 hr 01 min \n",
      " 41   | 0.3368  | 0.2149  | 0.4113  |  0 hr 01 min \n",
      " 42   | 0.3108  | 0.2280  | 0.4641  |  0 hr 01 min \n",
      " 43   | 0.3284  | 0.2096  | 0.4253  |  0 hr 01 min \n",
      " 44   | 0.3112  | 0.2104  | 0.3862  |  0 hr 01 min \n",
      " 45   | 0.2967  | 0.2271  | 0.4630  |  0 hr 01 min \n",
      " 46   | 0.2876  | 0.2089  | 0.4264  |  0 hr 01 min \n",
      " 47   | 0.2977  | 0.2229  | 0.4657  |  0 hr 01 min \n",
      " 48   | 0.2941  | 0.2300  | 0.4574  |  0 hr 01 min \n",
      " 49   | 0.3051  | 0.1951  | 0.4310  |  0 hr 01 min \n",
      " 50   | 0.2921  | 0.1920  | 0.4347  |  0 hr 01 min \n",
      " 51   | 0.3172  | 0.1919  | 0.4204  |  0 hr 01 min \n",
      " 52   | 0.3330  | 0.1896  | 0.4039  |  0 hr 01 min \n",
      " 53   | 0.3792  | 0.2194  | 0.4856  |  0 hr 01 min \n",
      " 54   | 0.2756  | 0.1906  | 0.4219  |  0 hr 01 min \n",
      " 55   | 0.3061  | 0.1884  | 0.4224  |  0 hr 01 min \n",
      " 56   | 0.2985  | 0.2037  | 0.4640  |  0 hr 01 min \n",
      " 57   | 0.3225  | 0.1849  | 0.4259  |  0 hr 01 min \n",
      " 58   | 0.3462  | 0.1737  | 0.4448  |  0 hr 01 min \n",
      " 59   | 0.3077  | 0.2147  | 0.4763  |  0 hr 01 min \n",
      " 60   | 0.2913  | 0.2001  | 0.4448  |  0 hr 01 min \n",
      " 61   | 0.2727  | 0.1780  | 0.4168  |  0 hr 01 min \n",
      " 62   | 0.2722  | 0.2162  | 0.4866  |  0 hr 01 min \n",
      " 63   | 0.2707  | 0.2197  | 0.4798  |  0 hr 01 min \n",
      " 64   | 0.2249  | 0.1730  | 0.4348  |  0 hr 01 min \n",
      " 65   | 0.2377  | 0.1773  | 0.4059  |  0 hr 01 min \n",
      " 66   | 0.2621  | 0.1710  | 0.3939  |  0 hr 01 min \n",
      " 67   | 0.3046  | 0.1588  | 0.4111  |  0 hr 01 min \n",
      " 68   | 0.2905  | 0.1627  | 0.4003  |  0 hr 01 min \n",
      " 69   | 0.2909  | 0.1895  | 0.4309  |  0 hr 01 min \n",
      " 70   | 0.2866  | 0.1724  | 0.4098  |  0 hr 01 min \n",
      " 71   | 0.3134  | 0.1880  | 0.3935  |  0 hr 01 min \n",
      " 72   | 0.2654  | 0.1746  | 0.4289  |  0 hr 01 min \n",
      " 73   | 0.3299  | 0.2125  | 0.4931  |  0 hr 01 min \n",
      " 74   | 0.3134  | 0.1653  | 0.4024  |  0 hr 02 min \n",
      " 75   | 0.2509  | 0.1653  | 0.4235  |  0 hr 02 min \n",
      " 76   | 0.2508  | 0.1524  | 0.4010  |  0 hr 02 min \n",
      " 77   | 0.2155  | 0.2017  | 0.4273  |  0 hr 02 min \n",
      " 78   | 0.2246  | 0.1411  | 0.4114  |  0 hr 02 min \n",
      " 79   | 0.2464  | 0.1620  | 0.4283  |  0 hr 02 min \n",
      " 80   | 0.2399  | 0.1502  | 0.4133  |  0 hr 02 min \n",
      " 81   | 0.2497  | 0.1377  | 0.4091  |  0 hr 02 min \n",
      " 82   | 0.2374  | 0.1682  | 0.4598  |  0 hr 02 min \n",
      " 83   | 0.2285  | 0.1465  | 0.4475  |  0 hr 02 min \n",
      " 84   | 0.2315  | 0.1533  | 0.4067  |  0 hr 02 min \n",
      " 85   | 0.2208  | 0.1489  | 0.3925  |  0 hr 02 min \n",
      " 86   | 0.2368  | 0.1450  | 0.3953  |  0 hr 02 min \n",
      " 87   | 0.2246  | 0.1567  | 0.4042  |  0 hr 02 min \n",
      " 88   | 0.2420  | 0.1489  | 0.3961  |  0 hr 02 min \n",
      " 89   | 0.2671  | 0.1540  | 0.4366  |  0 hr 02 min \n",
      " 90   | 0.2562  | 0.1362  | 0.4259  |  0 hr 02 min \n",
      " 91   | 0.2176  | 0.1578  | 0.4484  |  0 hr 02 min \n",
      " 92   | 0.2257  | 0.1278  | 0.4017  |  0 hr 02 min \n",
      " 93   | 0.2095  | 0.1703  | 0.4428  |  0 hr 02 min \n",
      " 94   | 0.2469  | 0.1409  | 0.3884  |  0 hr 02 min \n",
      " 95   | 0.2551  | 0.1801  | 0.4693  |  0 hr 02 min \n",
      " 96   | 0.3013  | 0.1845  | 0.4859  |  0 hr 02 min \n",
      " 97   | 0.2670  | 0.1603  | 0.4463  |  0 hr 02 min \n",
      " 98   | 0.2870  | 0.1386  | 0.3828  |  0 hr 02 min \n",
      " 99   | 0.2324  | 0.1690  | 0.4253  |  0 hr 02 min \n",
      " 100  | 0.2380  | 0.1347  | 0.3974  |  0 hr 02 min \n",
      " 101  | 0.2210  | 0.1819  | 0.4580  |  0 hr 02 min \n",
      " 102  | 0.2073  | 0.1370  | 0.4235  |  0 hr 02 min \n",
      " 103  | 0.2157  | 0.1393  | 0.3949  |  0 hr 02 min \n",
      " 104  | 0.2009  | 0.1337  | 0.4165  |  0 hr 02 min \n",
      " 105  | 0.2203  | 0.1266  | 0.4131  |  0 hr 02 min \n",
      " 106  | 0.2058  | 0.1217  | 0.3787  |  0 hr 02 min \n",
      " 107  | 0.2550  | 0.1292  | 0.3942  |  0 hr 02 min \n",
      " 108  | 0.2251  | 0.1374  | 0.4066  |  0 hr 02 min \n",
      " 109  | 0.2439  | 0.1377  | 0.4001  |  0 hr 02 min \n",
      " 110  | 0.2331  | 0.1455  | 0.4095  |  0 hr 02 min \n",
      " 111  | 0.2122  | 0.1340  | 0.4356  |  0 hr 02 min \n",
      " 112  | 0.2661  | 0.1375  | 0.4446  |  0 hr 03 min \n",
      " 113  | 0.2101  | 0.1283  | 0.4204  |  0 hr 03 min \n",
      " 114  | 0.2675  | 0.1459  | 0.4354  |  0 hr 03 min \n",
      " 115  | 0.2054  | 0.1147  | 0.3938  |  0 hr 03 min \n",
      " 116  | 0.2083  | 0.1380  | 0.4278  |  0 hr 03 min \n",
      " 117  | 0.1986  | 0.1135  | 0.3808  |  0 hr 03 min \n",
      " 118  | 0.2071  | 0.1207  | 0.4032  |  0 hr 03 min \n",
      " 119  | 0.2776  | 0.1121  | 0.3985  |  0 hr 03 min \n",
      " 120  | 0.1949  | 0.1177  | 0.4166  |  0 hr 03 min \n",
      " 121  | 0.1834  | 0.1091  | 0.3897  |  0 hr 03 min \n",
      " 122  | 0.1817  | 0.1042  | 0.4025  |  0 hr 03 min \n",
      " 123  | 0.2079  | 0.1096  | 0.3908  |  0 hr 03 min \n",
      " 124  | 0.1929  | 0.1023  | 0.3697  |  0 hr 03 min \n",
      " 125  | 0.2330  | 0.1095  | 0.3962  |  0 hr 03 min \n",
      " 126  | 0.2164  | 0.1069  | 0.4024  |  0 hr 03 min \n",
      " 127  | 0.1809  | 0.1292  | 0.4206  |  0 hr 03 min \n",
      " 128  | 0.2033  | 0.1092  | 0.4034  |  0 hr 03 min \n",
      " 129  | 0.1863  | 0.1478  | 0.4168  |  0 hr 03 min \n",
      " 130  | 0.2131  | 0.1490  | 0.4367  |  0 hr 03 min \n",
      " 131  | 0.2037  | 0.1309  | 0.3714  |  0 hr 03 min \n",
      " 132  | 0.2080  | 0.1178  | 0.3794  |  0 hr 03 min \n",
      " 133  | 0.2323  | 0.1099  | 0.3904  |  0 hr 03 min \n",
      " 134  | 0.2382  | 0.1084  | 0.3786  |  0 hr 03 min \n",
      " 135  | 0.2071  | 0.1234  | 0.4376  |  0 hr 03 min \n",
      " 136  | 0.1867  | 0.1190  | 0.4314  |  0 hr 03 min \n",
      " 137  | 0.1928  | 0.1232  | 0.4275  |  0 hr 03 min \n",
      " 138  | 0.2227  | 0.1051  | 0.3928  |  0 hr 03 min \n",
      " 139  | 0.2079  | 0.1031  | 0.3860  |  0 hr 03 min \n",
      " 140  | 0.1713  | 0.1094  | 0.4199  |  0 hr 03 min \n",
      " 141  | 0.1761  | 0.1004  | 0.3932  |  0 hr 03 min \n",
      " 142  | 0.1933  | 0.1029  | 0.3752  |  0 hr 03 min \n",
      " 143  | 0.2027  | 0.1099  | 0.4210  |  0 hr 03 min \n",
      " 144  | 0.1899  | 0.1032  | 0.4175  |  0 hr 03 min \n",
      " 145  | 0.2065  | 0.1067  | 0.4034  |  0 hr 03 min \n",
      " 146  | 0.1769  | 0.1254  | 0.4398  |  0 hr 03 min \n",
      " 147  | 0.2260  | 0.1071  | 0.3986  |  0 hr 03 min \n",
      " 148  | 0.1627  | 0.1102  | 0.3899  |  0 hr 03 min \n",
      " 149  | 0.1887  | 0.1128  | 0.4180  |  0 hr 04 min \n",
      " 150  | 0.1399  | 0.1048  | 0.4000  |  0 hr 04 min \n",
      " 151  | 0.1539  | 0.1178  | 0.4403  |  0 hr 04 min \n",
      " 152  | 0.1821  | 0.0981  | 0.4100  |  0 hr 04 min \n",
      " 153  | 0.1592  | 0.0951  | 0.3860  |  0 hr 04 min \n",
      " 154  | 0.1883  | 0.1020  | 0.3753  |  0 hr 04 min \n",
      " 155  | 0.1650  | 0.1022  | 0.3697  |  0 hr 04 min \n",
      " 156  | 0.1877  | 0.1107  | 0.4124  |  0 hr 04 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 157  | 0.1901  | 0.0953  | 0.3999  |  0 hr 04 min \n",
      " 158  | 0.2278  | 0.1196  | 0.3871  |  0 hr 04 min \n",
      " 159  | 0.1862  | 0.1601  | 0.4452  |  0 hr 04 min \n",
      " 160  | 0.2016  | 0.1074  | 0.4026  |  0 hr 04 min \n",
      " 161  | 0.2186  | 0.0997  | 0.3809  |  0 hr 04 min \n",
      " 162  | 0.1744  | 0.1084  | 0.3980  |  0 hr 04 min \n",
      " 163  | 0.1753  | 0.0972  | 0.3939  |  0 hr 04 min \n",
      " 164  | 0.1730  | 0.0977  | 0.3969  |  0 hr 04 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  0   |  124  | 0.0951  | 0.3697  \n",
      "  0   | 10.7846 | 10.4501 | 9.9002  |  0 hr 04 min \n",
      "  1   | 3.5335  | 7.6066  | 7.0141  |  0 hr 04 min \n",
      "  2   | 2.2404  | 5.3792  | 4.7930  |  0 hr 04 min \n",
      "  3   | 2.3341  | 5.0949  | 4.4701  |  0 hr 04 min \n",
      "  4   | 1.7747  | 4.6048  | 4.1204  |  0 hr 04 min \n",
      "  5   | 1.3363  | 3.6509  | 3.3601  |  0 hr 04 min \n",
      "  6   | 1.2848  | 2.7330  | 2.5454  |  0 hr 04 min \n",
      "  7   | 1.1305  | 1.8177  | 1.7965  |  0 hr 04 min \n",
      "  8   | 0.9583  | 1.2957  | 1.3492  |  0 hr 04 min \n",
      "  9   | 0.8127  | 1.1350  | 1.2158  |  0 hr 04 min \n",
      " 10   | 0.8222  | 0.7886  | 0.8535  |  0 hr 04 min \n",
      " 11   | 0.7364  | 0.7581  | 0.8704  |  0 hr 04 min \n",
      " 12   | 0.8189  | 0.6114  | 0.6953  |  0 hr 04 min \n",
      " 13   | 0.6490  | 0.5998  | 0.7281  |  0 hr 04 min \n",
      " 14   | 0.5812  | 0.6066  | 0.7366  |  0 hr 04 min \n",
      " 15   | 0.6240  | 0.4653  | 0.6095  |  0 hr 04 min \n",
      " 16   | 0.5687  | 0.4508  | 0.6170  |  0 hr 04 min \n",
      " 17   | 0.5133  | 0.3861  | 0.5276  |  0 hr 04 min \n",
      " 18   | 0.5147  | 0.3726  | 0.5178  |  0 hr 04 min \n",
      " 19   | 0.5973  | 0.3702  | 0.5065  |  0 hr 04 min \n",
      " 20   | 0.4509  | 0.3550  | 0.4694  |  0 hr 04 min \n",
      " 21   | 0.4555  | 0.3742  | 0.5038  |  0 hr 05 min \n",
      " 22   | 0.4771  | 0.3208  | 0.4591  |  0 hr 05 min \n",
      " 23   | 0.4416  | 0.3146  | 0.4408  |  0 hr 05 min \n",
      " 24   | 0.4856  | 0.3554  | 0.4807  |  0 hr 05 min \n",
      " 25   | 0.4959  | 0.2980  | 0.4305  |  0 hr 05 min \n",
      " 26   | 0.3751  | 0.2972  | 0.4546  |  0 hr 05 min \n",
      " 27   | 0.3981  | 0.2791  | 0.4383  |  0 hr 05 min \n",
      " 28   | 0.3727  | 0.3160  | 0.4404  |  0 hr 05 min \n",
      " 29   | 0.3671  | 0.2807  | 0.4487  |  0 hr 05 min \n",
      " 30   | 0.4038  | 0.3169  | 0.4527  |  0 hr 05 min \n",
      " 31   | 0.4222  | 0.2864  | 0.4384  |  0 hr 05 min \n",
      " 32   | 0.4052  | 0.2652  | 0.4180  |  0 hr 05 min \n",
      " 33   | 0.3586  | 0.2716  | 0.4353  |  0 hr 05 min \n",
      " 34   | 0.4589  | 0.2639  | 0.4368  |  0 hr 05 min \n",
      " 35   | 0.3479  | 0.3065  | 0.4623  |  0 hr 05 min \n",
      " 36   | 0.3569  | 0.2361  | 0.4231  |  0 hr 05 min \n",
      " 37   | 0.3707  | 0.2511  | 0.4445  |  0 hr 05 min \n",
      " 38   | 0.3455  | 0.2473  | 0.4058  |  0 hr 05 min \n",
      " 39   | 0.3175  | 0.2282  | 0.4058  |  0 hr 05 min \n",
      " 40   | 0.3268  | 0.2162  | 0.4038  |  0 hr 05 min \n",
      " 41   | 0.3342  | 0.2156  | 0.3730  |  0 hr 05 min \n",
      " 42   | 0.3228  | 0.2131  | 0.3796  |  0 hr 05 min \n",
      " 43   | 0.3144  | 0.2405  | 0.4410  |  0 hr 05 min \n",
      " 44   | 0.3695  | 0.2536  | 0.4338  |  0 hr 05 min \n",
      " 45   | 0.3630  | 0.2702  | 0.4606  |  0 hr 05 min \n",
      " 46   | 0.3121  | 0.2194  | 0.3847  |  0 hr 05 min \n",
      " 47   | 0.3169  | 0.2302  | 0.4351  |  0 hr 05 min \n",
      " 48   | 0.3321  | 0.2092  | 0.3872  |  0 hr 05 min \n",
      " 49   | 0.3347  | 0.2132  | 0.4185  |  0 hr 05 min \n",
      " 50   | 0.3507  | 0.2347  | 0.4242  |  0 hr 05 min \n",
      " 51   | 0.3065  | 0.2028  | 0.4153  |  0 hr 05 min \n",
      " 52   | 0.3509  | 0.2471  | 0.4103  |  0 hr 05 min \n",
      " 53   | 0.2940  | 0.2406  | 0.4398  |  0 hr 05 min \n",
      " 54   | 0.2970  | 0.2119  | 0.3969  |  0 hr 05 min \n",
      " 55   | 0.2635  | 0.1898  | 0.3718  |  0 hr 05 min \n",
      " 56   | 0.3024  | 0.2124  | 0.4056  |  0 hr 05 min \n",
      " 57   | 0.2805  | 0.2056  | 0.3942  |  0 hr 05 min \n",
      " 58   | 0.2919  | 0.2254  | 0.4777  |  0 hr 06 min \n",
      " 59   | 0.3552  | 0.2016  | 0.4189  |  0 hr 06 min \n",
      " 60   | 0.2849  | 0.2073  | 0.4302  |  0 hr 06 min \n",
      " 61   | 0.2914  | 0.1922  | 0.3768  |  0 hr 06 min \n",
      " 62   | 0.2976  | 0.2035  | 0.4254  |  0 hr 06 min \n",
      " 63   | 0.2599  | 0.1978  | 0.3980  |  0 hr 06 min \n",
      " 64   | 0.2580  | 0.1726  | 0.3947  |  0 hr 06 min \n",
      " 65   | 0.2932  | 0.1726  | 0.4313  |  0 hr 06 min \n",
      " 66   | 0.2674  | 0.2276  | 0.4288  |  0 hr 06 min \n",
      " 67   | 0.2517  | 0.1772  | 0.4361  |  0 hr 06 min \n",
      " 68   | 0.2959  | 0.2608  | 0.4641  |  0 hr 06 min \n",
      " 69   | 0.2701  | 0.1839  | 0.4653  |  0 hr 06 min \n",
      " 70   | 0.2817  | 0.2488  | 0.4230  |  0 hr 06 min \n",
      " 71   | 0.2914  | 0.2028  | 0.4784  |  0 hr 06 min \n",
      " 72   | 0.2737  | 0.2075  | 0.3974  |  0 hr 06 min \n",
      " 73   | 0.3258  | 0.1732  | 0.4161  |  0 hr 06 min \n",
      " 74   | 0.3314  | 0.1902  | 0.3889  |  0 hr 06 min \n",
      " 75   | 0.2586  | 0.1797  | 0.4061  |  0 hr 06 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  1   |  55   | 0.1726  | 0.3718  \n",
      "  0   | 8.3925  | 9.2930  | 9.5972  |  0 hr 06 min \n",
      "  1   | 2.6021  | 6.1263  | 6.3033  |  0 hr 06 min \n",
      "  2   | 2.2433  | 4.4616  | 4.6061  |  0 hr 06 min \n",
      "  3   | 1.9883  | 3.8907  | 4.0795  |  0 hr 06 min \n",
      "  4   | 1.3846  | 2.7548  | 3.0000  |  0 hr 06 min \n",
      "  5   | 1.2352  | 1.9461  | 2.2437  |  0 hr 06 min \n",
      "  6   | 1.1555  | 1.4719  | 1.8270  |  0 hr 06 min \n",
      "  7   | 0.9593  | 1.1285  | 1.5416  |  0 hr 06 min \n",
      "  8   | 0.8602  | 0.8909  | 1.2526  |  0 hr 06 min \n",
      "  9   | 0.7559  | 0.8420  | 1.1282  |  0 hr 06 min \n",
      " 10   | 0.7271  | 0.6184  | 0.9243  |  0 hr 06 min \n",
      " 11   | 0.7905  | 0.6248  | 0.9312  |  0 hr 06 min \n",
      " 12   | 0.6404  | 0.6265  | 0.9842  |  0 hr 06 min \n",
      " 13   | 0.5606  | 0.5194  | 0.7154  |  0 hr 06 min \n",
      " 14   | 0.5849  | 0.4407  | 0.6874  |  0 hr 06 min \n",
      " 15   | 0.4952  | 0.3881  | 0.6298  |  0 hr 06 min \n",
      " 16   | 0.5550  | 0.4599  | 0.6712  |  0 hr 06 min \n",
      " 17   | 0.5099  | 0.4594  | 0.6481  |  0 hr 06 min \n",
      " 18   | 0.4985  | 0.3722  | 0.5416  |  0 hr 06 min \n",
      " 19   | 0.4276  | 0.4381  | 0.6285  |  0 hr 06 min \n",
      " 20   | 0.4333  | 0.3592  | 0.5404  |  0 hr 07 min \n",
      " 21   | 0.4608  | 0.3327  | 0.5283  |  0 hr 07 min \n",
      " 22   | 0.4391  | 0.3182  | 0.5116  |  0 hr 07 min \n",
      " 23   | 0.4057  | 0.3054  | 0.5110  |  0 hr 07 min \n",
      " 24   | 0.4507  | 0.2879  | 0.4979  |  0 hr 07 min \n",
      " 25   | 0.4012  | 0.3045  | 0.5155  |  0 hr 07 min \n",
      " 26   | 0.4188  | 0.3015  | 0.5340  |  0 hr 07 min \n",
      " 27   | 0.3942  | 0.2888  | 0.4716  |  0 hr 07 min \n",
      " 28   | 0.3611  | 0.2851  | 0.5109  |  0 hr 07 min \n",
      " 29   | 0.3768  | 0.2682  | 0.4959  |  0 hr 07 min \n",
      " 30   | 0.4712  | 0.3190  | 0.5503  |  0 hr 07 min \n",
      " 31   | 0.4216  | 0.3494  | 0.6216  |  0 hr 07 min \n",
      " 32   | 0.4006  | 0.2584  | 0.4958  |  0 hr 07 min \n",
      " 33   | 0.3453  | 0.3115  | 0.5327  |  0 hr 07 min \n",
      " 34   | 0.3923  | 0.2823  | 0.5271  |  0 hr 07 min \n",
      " 35   | 0.3803  | 0.2578  | 0.5071  |  0 hr 07 min \n",
      " 36   | 0.4057  | 0.2668  | 0.5144  |  0 hr 07 min \n",
      " 37   | 0.4267  | 0.2531  | 0.5111  |  0 hr 07 min \n",
      " 38   | 0.3883  | 0.2608  | 0.4603  |  0 hr 07 min \n",
      " 39   | 0.4041  | 0.2437  | 0.5011  |  0 hr 07 min \n",
      " 40   | 0.3747  | 0.2359  | 0.4868  |  0 hr 07 min \n",
      " 41   | 0.3482  | 0.2657  | 0.5145  |  0 hr 07 min \n",
      " 42   | 0.3106  | 0.2540  | 0.5376  |  0 hr 07 min \n",
      " 43   | 0.3671  | 0.2333  | 0.4690  |  0 hr 07 min \n",
      " 44   | 0.3853  | 0.2336  | 0.4599  |  0 hr 07 min \n",
      " 45   | 0.3215  | 0.3003  | 0.6100  |  0 hr 07 min \n",
      " 46   | 0.3156  | 0.2147  | 0.4806  |  0 hr 07 min \n",
      " 47   | 0.3547  | 0.2284  | 0.5358  |  0 hr 07 min \n",
      " 48   | 0.3686  | 0.2109  | 0.5198  |  0 hr 07 min \n",
      " 49   | 0.3224  | 0.2148  | 0.5044  |  0 hr 07 min \n",
      " 50   | 0.2909  | 0.2402  | 0.4887  |  0 hr 07 min \n",
      " 51   | 0.3131  | 0.1974  | 0.4617  |  0 hr 07 min \n",
      " 52   | 0.2837  | 0.2253  | 0.4877  |  0 hr 07 min \n",
      " 53   | 0.2832  | 0.2147  | 0.4550  |  0 hr 07 min \n",
      " 54   | 0.3303  | 0.2000  | 0.4411  |  0 hr 07 min \n",
      " 55   | 0.2796  | 0.2098  | 0.4650  |  0 hr 07 min \n",
      " 56   | 0.3125  | 0.1946  | 0.4957  |  0 hr 07 min \n",
      " 57   | 0.2593  | 0.2386  | 0.5587  |  0 hr 07 min \n",
      " 58   | 0.3079  | 0.2312  | 0.5339  |  0 hr 08 min \n",
      " 59   | 0.3111  | 0.1917  | 0.4546  |  0 hr 08 min \n",
      " 60   | 0.3031  | 0.1915  | 0.4477  |  0 hr 08 min \n",
      " 61   | 0.3341  | 0.1773  | 0.4569  |  0 hr 08 min \n",
      " 62   | 0.3006  | 0.1899  | 0.4588  |  0 hr 08 min \n",
      " 63   | 0.3142  | 0.2121  | 0.5090  |  0 hr 08 min \n",
      " 64   | 0.3774  | 0.2216  | 0.5091  |  0 hr 08 min \n",
      " 65   | 0.3073  | 0.2389  | 0.5751  |  0 hr 08 min \n",
      " 66   | 0.3238  | 0.2262  | 0.5280  |  0 hr 08 min \n",
      " 67   | 0.3516  | 0.1867  | 0.4448  |  0 hr 08 min \n",
      " 68   | 0.2800  | 0.1739  | 0.4673  |  0 hr 08 min \n",
      " 69   | 0.2791  | 0.1701  | 0.4329  |  0 hr 08 min \n",
      " 70   | 0.2594  | 0.1667  | 0.4402  |  0 hr 08 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71   | 0.2951  | 0.1680  | 0.4396  |  0 hr 08 min \n",
      " 72   | 0.2322  | 0.1621  | 0.4439  |  0 hr 08 min \n",
      " 73   | 0.3302  | 0.1952  | 0.4657  |  0 hr 08 min \n",
      " 74   | 0.2617  | 0.1716  | 0.4663  |  0 hr 08 min \n",
      " 75   | 0.3028  | 0.2486  | 0.5338  |  0 hr 08 min \n",
      " 76   | 0.2648  | 0.1644  | 0.4689  |  0 hr 08 min \n",
      " 77   | 0.3439  | 0.1603  | 0.4605  |  0 hr 08 min \n",
      " 78   | 0.3622  | 0.1849  | 0.4828  |  0 hr 08 min \n",
      " 79   | 0.3878  | 0.2183  | 0.5605  |  0 hr 08 min \n",
      " 80   | 0.2928  | 0.2619  | 0.5264  |  0 hr 08 min \n",
      " 81   | 0.3468  | 0.1527  | 0.4321  |  0 hr 08 min \n",
      " 82   | 0.2853  | 0.1721  | 0.4722  |  0 hr 08 min \n",
      " 83   | 0.2657  | 0.1630  | 0.4501  |  0 hr 08 min \n",
      " 84   | 0.2316  | 0.1732  | 0.4478  |  0 hr 08 min \n",
      " 85   | 0.2962  | 0.1798  | 0.4798  |  0 hr 08 min \n",
      " 86   | 0.2889  | 0.1632  | 0.4478  |  0 hr 08 min \n",
      " 87   | 0.2371  | 0.1532  | 0.4507  |  0 hr 08 min \n",
      " 88   | 0.2214  | 0.1406  | 0.4526  |  0 hr 08 min \n",
      " 89   | 0.2103  | 0.1439  | 0.4550  |  0 hr 08 min \n",
      " 90   | 0.2453  | 0.1710  | 0.4919  |  0 hr 08 min \n",
      " 91   | 0.2801  | 0.1438  | 0.4442  |  0 hr 08 min \n",
      " 92   | 0.2730  | 0.1429  | 0.4150  |  0 hr 08 min \n",
      " 93   | 0.2407  | 0.1343  | 0.4374  |  0 hr 08 min \n",
      " 94   | 0.2530  | 0.1472  | 0.5118  |  0 hr 08 min \n",
      " 95   | 0.2519  | 0.1513  | 0.4480  |  0 hr 08 min \n",
      " 96   | 0.2442  | 0.1374  | 0.4430  |  0 hr 08 min \n",
      " 97   | 0.2311  | 0.1342  | 0.4436  |  0 hr 09 min \n",
      " 98   | 0.2390  | 0.1902  | 0.4712  |  0 hr 09 min \n",
      " 99   | 0.2226  | 0.1466  | 0.5002  |  0 hr 09 min \n",
      " 100  | 0.2512  | 0.1468  | 0.4539  |  0 hr 09 min \n",
      " 101  | 0.2122  | 0.1396  | 0.4364  |  0 hr 09 min \n",
      " 102  | 0.2399  | 0.1989  | 0.5077  |  0 hr 09 min \n",
      " 103  | 0.2131  | 0.1382  | 0.4672  |  0 hr 09 min \n",
      " 104  | 0.2451  | 0.1334  | 0.4508  |  0 hr 09 min \n",
      " 105  | 0.1984  | 0.1409  | 0.4606  |  0 hr 09 min \n",
      " 106  | 0.2200  | 0.1316  | 0.4691  |  0 hr 09 min \n",
      " 107  | 0.2189  | 0.1270  | 0.4400  |  0 hr 09 min \n",
      " 108  | 0.2162  | 0.1194  | 0.4282  |  0 hr 09 min \n",
      " 109  | 0.1869  | 0.1221  | 0.4349  |  0 hr 09 min \n",
      " 110  | 0.2451  | 0.1205  | 0.4357  |  0 hr 09 min \n",
      " 111  | 0.2275  | 0.1297  | 0.4390  |  0 hr 09 min \n",
      " 112  | 0.1855  | 0.1278  | 0.4808  |  0 hr 09 min \n",
      " 113  | 0.2350  | 0.1288  | 0.4388  |  0 hr 09 min \n",
      " 114  | 0.2480  | 0.1530  | 0.4303  |  0 hr 09 min \n",
      " 115  | 0.2429  | 0.1497  | 0.5075  |  0 hr 09 min \n",
      " 116  | 0.2112  | 0.1986  | 0.5015  |  0 hr 09 min \n",
      " 117  | 0.2592  | 0.1299  | 0.4402  |  0 hr 09 min \n",
      " 118  | 0.2637  | 0.1468  | 0.4790  |  0 hr 09 min \n",
      " 119  | 0.2374  | 0.1653  | 0.4655  |  0 hr 09 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  2   |  92   | 0.1194  | 0.4150  \n",
      "  0   | 9.9077  | 10.2478 | 7.7625  |  0 hr 09 min \n",
      "  1   | 3.5074  | 7.2350  | 5.4871  |  0 hr 09 min \n",
      "  2   | 2.4189  | 6.0946  | 4.5675  |  0 hr 09 min \n",
      "  3   | 2.1568  | 5.3079  | 4.0330  |  0 hr 09 min \n",
      "  4   | 1.4370  | 4.6922  | 3.6508  |  0 hr 09 min \n",
      "  5   | 1.1699  | 3.2827  | 2.5865  |  0 hr 09 min \n",
      "  6   | 1.1307  | 1.8826  | 1.5278  |  0 hr 09 min \n",
      "  7   | 0.9505  | 1.1534  | 1.0326  |  0 hr 09 min \n",
      "  8   | 0.8274  | 0.9373  | 0.9686  |  0 hr 09 min \n",
      "  9   | 0.7361  | 0.6962  | 0.7287  |  0 hr 09 min \n",
      " 10   | 0.6654  | 0.5995  | 0.6473  |  0 hr 09 min \n",
      " 11   | 0.5810  | 0.4485  | 0.5245  |  0 hr 09 min \n",
      " 12   | 0.5451  | 0.5527  | 0.5980  |  0 hr 09 min \n",
      " 13   | 0.6128  | 0.4095  | 0.4669  |  0 hr 09 min \n",
      " 14   | 0.4706  | 0.3630  | 0.4062  |  0 hr 09 min \n",
      " 15   | 0.4831  | 0.4688  | 0.5442  |  0 hr 09 min \n",
      " 16   | 0.4736  | 0.3390  | 0.3910  |  0 hr 10 min \n",
      " 17   | 0.5384  | 0.4125  | 0.4811  |  0 hr 10 min \n",
      " 18   | 0.4515  | 0.3524  | 0.3732  |  0 hr 10 min \n",
      " 19   | 0.4524  | 0.3622  | 0.4078  |  0 hr 10 min \n",
      " 20   | 0.4265  | 0.3042  | 0.3596  |  0 hr 10 min \n",
      " 21   | 0.4086  | 0.2949  | 0.3715  |  0 hr 10 min \n",
      " 22   | 0.3946  | 0.2784  | 0.3423  |  0 hr 10 min \n",
      " 23   | 0.4156  | 0.3153  | 0.3725  |  0 hr 10 min \n",
      " 24   | 0.4318  | 0.2999  | 0.3773  |  0 hr 10 min \n",
      " 25   | 0.4238  | 0.2647  | 0.3389  |  0 hr 10 min \n",
      " 26   | 0.4031  | 0.3425  | 0.4026  |  0 hr 10 min \n",
      " 27   | 0.3623  | 0.2823  | 0.3699  |  0 hr 10 min \n",
      " 28   | 0.4352  | 0.2869  | 0.3523  |  0 hr 10 min \n",
      " 29   | 0.3669  | 0.2872  | 0.3985  |  0 hr 10 min \n",
      " 30   | 0.3864  | 0.2544  | 0.3631  |  0 hr 10 min \n",
      " 31   | 0.3623  | 0.2975  | 0.3533  |  0 hr 10 min \n",
      " 32   | 0.3992  | 0.2550  | 0.3458  |  0 hr 10 min \n",
      " 33   | 0.3434  | 0.2970  | 0.3784  |  0 hr 10 min \n",
      " 34   | 0.3786  | 0.2501  | 0.3492  |  0 hr 10 min \n",
      " 35   | 0.3510  | 0.2332  | 0.3357  |  0 hr 10 min \n",
      " 36   | 0.3395  | 0.2650  | 0.3423  |  0 hr 10 min \n",
      " 37   | 0.3259  | 0.2558  | 0.3459  |  0 hr 10 min \n",
      " 38   | 0.3480  | 0.2216  | 0.3224  |  0 hr 10 min \n",
      " 39   | 0.3330  | 0.2773  | 0.3723  |  0 hr 10 min \n",
      " 40   | 0.3327  | 0.2358  | 0.3187  |  0 hr 10 min \n",
      " 41   | 0.3386  | 0.2358  | 0.3253  |  0 hr 10 min \n",
      " 42   | 0.3197  | 0.2296  | 0.3138  |  0 hr 10 min \n",
      " 43   | 0.3305  | 0.2290  | 0.3111  |  0 hr 10 min \n",
      " 44   | 0.3474  | 0.2306  | 0.3284  |  0 hr 10 min \n",
      " 45   | 0.3333  | 0.2526  | 0.3206  |  0 hr 10 min \n",
      " 46   | 0.3301  | 0.2715  | 0.3591  |  0 hr 10 min \n",
      " 47   | 0.3684  | 0.2921  | 0.3728  |  0 hr 10 min \n",
      " 48   | 0.3555  | 0.1981  | 0.3067  |  0 hr 10 min \n",
      " 49   | 0.3227  | 0.2171  | 0.3176  |  0 hr 10 min \n",
      " 50   | 0.3468  | 0.2661  | 0.3661  |  0 hr 10 min \n",
      " 51   | 0.3635  | 0.2269  | 0.3219  |  0 hr 10 min \n",
      " 52   | 0.3106  | 0.2166  | 0.2934  |  0 hr 10 min \n",
      " 53   | 0.3118  | 0.2055  | 0.3041  |  0 hr 10 min \n",
      " 54   | 0.2908  | 0.1943  | 0.3086  |  0 hr 10 min \n",
      " 55   | 0.2908  | 0.2054  | 0.2995  |  0 hr 11 min \n",
      " 56   | 0.2997  | 0.1896  | 0.2958  |  0 hr 11 min \n",
      " 57   | 0.3112  | 0.1940  | 0.3073  |  0 hr 11 min \n",
      " 58   | 0.2751  | 0.2130  | 0.3155  |  0 hr 11 min \n",
      " 59   | 0.2896  | 0.2090  | 0.3074  |  0 hr 11 min \n",
      " 60   | 0.2826  | 0.2008  | 0.3099  |  0 hr 11 min \n",
      " 61   | 0.2916  | 0.1899  | 0.3090  |  0 hr 11 min \n",
      " 62   | 0.3094  | 0.1970  | 0.2811  |  0 hr 11 min \n",
      " 63   | 0.3403  | 0.1972  | 0.2920  |  0 hr 11 min \n",
      " 64   | 0.2819  | 0.2068  | 0.3162  |  0 hr 11 min \n",
      " 65   | 0.2951  | 0.1909  | 0.2788  |  0 hr 11 min \n",
      " 66   | 0.2790  | 0.1799  | 0.2773  |  0 hr 11 min \n",
      " 67   | 0.2553  | 0.1798  | 0.2851  |  0 hr 11 min \n",
      " 68   | 0.2827  | 0.1908  | 0.2954  |  0 hr 11 min \n",
      " 69   | 0.2552  | 0.1720  | 0.2750  |  0 hr 11 min \n",
      " 70   | 0.2795  | 0.1874  | 0.3124  |  0 hr 11 min \n",
      " 71   | 0.3156  | 0.2941  | 0.5513  |  0 hr 11 min \n",
      " 72   | 0.3538  | 0.3325  | 0.4070  |  0 hr 11 min \n",
      " 73   | 0.3248  | 0.3083  | 0.3957  |  0 hr 11 min \n",
      " 74   | 0.2929  | 0.2656  | 0.3610  |  0 hr 11 min \n",
      " 75   | 0.3227  | 0.2147  | 0.2871  |  0 hr 11 min \n",
      " 76   | 0.2670  | 0.2657  | 0.3820  |  0 hr 11 min \n",
      " 77   | 0.2610  | 0.1677  | 0.2810  |  0 hr 11 min \n",
      " 78   | 0.2328  | 0.1984  | 0.2906  |  0 hr 11 min \n",
      " 79   | 0.2593  | 0.1636  | 0.2639  |  0 hr 11 min \n",
      " 80   | 0.3039  | 0.1543  | 0.2606  |  0 hr 11 min \n",
      " 81   | 0.2648  | 0.1675  | 0.2694  |  0 hr 11 min \n",
      " 82   | 0.2691  | 0.1574  | 0.2605  |  0 hr 11 min \n",
      " 83   | 0.2909  | 0.1529  | 0.2650  |  0 hr 11 min \n",
      " 84   | 0.3238  | 0.1897  | 0.2810  |  0 hr 11 min \n",
      " 85   | 0.2440  | 0.1861  | 0.2774  |  0 hr 11 min \n",
      " 86   | 0.2575  | 0.1676  | 0.2669  |  0 hr 11 min \n",
      " 87   | 0.2399  | 0.1582  | 0.2785  |  0 hr 11 min \n",
      " 88   | 0.2460  | 0.1638  | 0.2741  |  0 hr 11 min \n",
      " 89   | 0.2625  | 0.1518  | 0.2623  |  0 hr 11 min \n",
      " 90   | 0.2578  | 0.1802  | 0.2964  |  0 hr 11 min \n",
      " 91   | 0.2775  | 0.1770  | 0.3033  |  0 hr 11 min \n",
      " 92   | 0.2577  | 0.1589  | 0.2667  |  0 hr 11 min \n",
      " 93   | 0.2421  | 0.2319  | 0.3148  |  0 hr 11 min \n",
      " 94   | 0.2608  | 0.1567  | 0.2514  |  0 hr 12 min \n",
      " 95   | 0.2659  | 0.1671  | 0.2800  |  0 hr 12 min \n",
      " 96   | 0.2909  | 0.1588  | 0.2742  |  0 hr 12 min \n",
      " 97   | 0.2652  | 0.1980  | 0.2967  |  0 hr 12 min \n",
      " 98   | 0.2304  | 0.1707  | 0.2568  |  0 hr 12 min \n",
      " 99   | 0.2460  | 0.1846  | 0.2604  |  0 hr 12 min \n",
      " 100  | 0.2366  | 0.1485  | 0.2469  |  0 hr 12 min \n",
      " 101  | 0.2191  | 0.1477  | 0.2663  |  0 hr 12 min \n",
      " 102  | 0.2397  | 0.1459  | 0.2517  |  0 hr 12 min \n",
      " 103  | 0.2145  | 0.1478  | 0.2384  |  0 hr 12 min \n",
      " 104  | 0.2018  | 0.1384  | 0.2452  |  0 hr 12 min \n",
      " 105  | 0.2341  | 0.1598  | 0.2560  |  0 hr 12 min \n",
      " 106  | 0.2289  | 0.1630  | 0.2513  |  0 hr 12 min \n",
      " 107  | 0.2155  | 0.1402  | 0.2377  |  0 hr 12 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 108  | 0.2820  | 0.1790  | 0.2672  |  0 hr 12 min \n",
      " 109  | 0.2172  | 0.1331  | 0.2449  |  0 hr 12 min \n",
      " 110  | 0.1940  | 0.1275  | 0.2503  |  0 hr 12 min \n",
      " 111  | 0.2520  | 0.1273  | 0.2298  |  0 hr 12 min \n",
      " 112  | 0.2659  | 0.1409  | 0.2396  |  0 hr 12 min \n",
      " 113  | 0.2860  | 0.1470  | 0.2567  |  0 hr 12 min \n",
      " 114  | 0.2344  | 0.1316  | 0.2380  |  0 hr 12 min \n",
      " 115  | 0.2603  | 0.1571  | 0.2592  |  0 hr 12 min \n",
      " 116  | 0.2530  | 0.1411  | 0.2463  |  0 hr 12 min \n",
      " 117  | 0.2891  | 0.1509  | 0.2606  |  0 hr 12 min \n",
      " 118  | 0.2624  | 0.1670  | 0.2768  |  0 hr 12 min \n",
      " 119  | 0.2253  | 0.1488  | 0.2718  |  0 hr 12 min \n",
      " 120  | 0.2267  | 0.1445  | 0.2652  |  0 hr 12 min \n",
      " 121  | 0.2133  | 0.1619  | 0.2894  |  0 hr 12 min \n",
      " 122  | 0.2203  | 0.1316  | 0.2622  |  0 hr 12 min \n",
      " 123  | 0.2126  | 0.1354  | 0.2463  |  0 hr 12 min \n",
      " 124  | 0.2037  | 0.1260  | 0.2325  |  0 hr 12 min \n",
      " 125  | 0.2244  | 0.1260  | 0.2294  |  0 hr 12 min \n",
      " 126  | 0.2110  | 0.1718  | 0.2639  |  0 hr 12 min \n",
      " 127  | 0.2042  | 0.1258  | 0.2391  |  0 hr 12 min \n",
      " 128  | 0.1881  | 0.1184  | 0.2357  |  0 hr 12 min \n",
      " 129  | 0.2254  | 0.1255  | 0.2409  |  0 hr 12 min \n",
      " 130  | 0.2472  | 0.1211  | 0.2558  |  0 hr 12 min \n",
      " 131  | 0.2292  | 0.1346  | 0.2819  |  0 hr 12 min \n",
      " 132  | 0.1938  | 0.1170  | 0.2551  |  0 hr 12 min \n",
      " 133  | 0.2277  | 0.1163  | 0.2221  |  0 hr 13 min \n",
      " 134  | 0.1967  | 0.1367  | 0.2338  |  0 hr 13 min \n",
      " 135  | 0.1934  | 0.1323  | 0.2334  |  0 hr 13 min \n",
      " 136  | 0.2020  | 0.1204  | 0.2323  |  0 hr 13 min \n",
      " 137  | 0.2061  | 0.1251  | 0.2434  |  0 hr 13 min \n",
      " 138  | 0.1926  | 0.1133  | 0.2211  |  0 hr 13 min \n",
      " 139  | 0.2066  | 0.1169  | 0.2313  |  0 hr 13 min \n",
      " 140  | 0.2238  | 0.1128  | 0.2446  |  0 hr 13 min \n",
      " 141  | 0.2505  | 0.1593  | 0.2674  |  0 hr 13 min \n",
      " 142  | 0.2121  | 0.1486  | 0.2554  |  0 hr 13 min \n",
      " 143  | 0.2100  | 0.1065  | 0.2260  |  0 hr 13 min \n",
      " 144  | 0.2366  | 0.1543  | 0.2804  |  0 hr 13 min \n",
      " 145  | 0.1722  | 0.1440  | 0.2494  |  0 hr 13 min \n",
      " 146  | 0.2065  | 0.1133  | 0.2161  |  0 hr 13 min \n",
      " 147  | 0.2582  | 0.1406  | 0.2466  |  0 hr 13 min \n",
      " 148  | 0.2644  | 0.1611  | 0.2699  |  0 hr 13 min \n",
      " 149  | 0.1991  | 0.1397  | 0.2710  |  0 hr 13 min \n",
      " 150  | 0.2046  | 0.1252  | 0.2419  |  0 hr 13 min \n",
      " 151  | 0.2436  | 0.1555  | 0.2633  |  0 hr 13 min \n",
      " 152  | 0.2061  | 0.1340  | 0.2435  |  0 hr 13 min \n",
      " 153  | 0.2102  | 0.1088  | 0.2372  |  0 hr 13 min \n",
      " 154  | 0.2117  | 0.1571  | 0.2797  |  0 hr 13 min \n",
      " 155  | 0.2101  | 0.1250  | 0.2499  |  0 hr 13 min \n",
      " 156  | 0.1787  | 0.1138  | 0.2405  |  0 hr 13 min \n",
      " 157  | 0.1878  | 0.1126  | 0.2281  |  0 hr 13 min \n",
      " 158  | 0.1762  | 0.1007  | 0.2384  |  0 hr 13 min \n",
      " 159  | 0.1734  | 0.1259  | 0.2644  |  0 hr 13 min \n",
      " 160  | 0.2478  | 0.1165  | 0.2509  |  0 hr 13 min \n",
      " 161  | 0.1991  | 0.1057  | 0.2575  |  0 hr 13 min \n",
      " 162  | 0.2072  | 0.1002  | 0.2480  |  0 hr 13 min \n",
      " 163  | 0.2035  | 0.1309  | 0.2603  |  0 hr 13 min \n",
      " 164  | 0.2157  | 0.1104  | 0.2278  |  0 hr 13 min \n",
      " 165  | 0.1929  | 0.1068  | 0.2588  |  0 hr 13 min \n",
      " 166  | 0.1948  | 0.1010  | 0.2709  |  0 hr 13 min \n",
      " 167  | 0.2013  | 0.0971  | 0.2352  |  0 hr 13 min \n",
      " 168  | 0.1819  | 0.1095  | 0.2567  |  0 hr 13 min \n",
      " 169  | 0.1786  | 0.1045  | 0.2494  |  0 hr 13 min \n",
      " 170  | 0.2019  | 0.1118  | 0.2874  |  0 hr 13 min \n",
      " 171  | 0.1892  | 0.1123  | 0.2587  |  0 hr 13 min \n",
      " 172  | 0.1531  | 0.1180  | 0.2329  |  0 hr 13 min \n",
      " 173  | 0.2095  | 0.1240  | 0.2531  |  0 hr 14 min \n",
      " 174  | 0.2165  | 0.1006  | 0.2270  |  0 hr 14 min \n",
      " 175  | 0.1988  | 0.1260  | 0.2367  |  0 hr 14 min \n",
      " 176  | 0.1618  | 0.1132  | 0.2506  |  0 hr 14 min \n",
      " 177  | 0.1798  | 0.0964  | 0.2180  |  0 hr 14 min \n",
      " 178  | 0.1664  | 0.1074  | 0.2429  |  0 hr 14 min \n",
      " 179  | 0.2109  | 0.0965  | 0.2412  |  0 hr 14 min \n",
      " 180  | 0.2127  | 0.1044  | 0.2594  |  0 hr 14 min \n",
      " 181  | 0.1680  | 0.1075  | 0.2472  |  0 hr 14 min \n",
      " 182  | 0.2732  | 0.1096  | 0.2382  |  0 hr 14 min \n",
      " 183  | 0.1981  | 0.1063  | 0.2267  |  0 hr 14 min \n",
      " 184  | 0.1863  | 0.1198  | 0.2344  |  0 hr 14 min \n",
      " 185  | 0.1783  | 0.0928  | 0.2266  |  0 hr 14 min \n",
      " 186  | 0.2102  | 0.1027  | 0.2416  |  0 hr 14 min \n",
      " 187  | 0.1795  | 0.0954  | 0.2307  |  0 hr 14 min \n",
      " 188  | 0.1762  | 0.0922  | 0.2319  |  0 hr 14 min \n",
      " 189  | 0.1875  | 0.1024  | 0.2481  |  0 hr 14 min \n",
      " 190  | 0.2298  | 0.1161  | 0.2494  |  0 hr 14 min \n",
      " 191  | 0.1875  | 0.1245  | 0.2701  |  0 hr 14 min \n",
      " 192  | 0.2028  | 0.1473  | 0.2550  |  0 hr 14 min \n",
      " 193  | 0.1927  | 0.1105  | 0.2445  |  0 hr 14 min \n",
      " 194  | 0.2187  | 0.0987  | 0.2294  |  0 hr 14 min \n",
      " 195  | 0.1875  | 0.0988  | 0.2339  |  0 hr 14 min \n",
      " 196  | 0.1881  | 0.1078  | 0.2341  |  0 hr 14 min \n",
      " 197  | 0.2265  | 0.1408  | 0.2674  |  0 hr 14 min \n",
      " 198  | 0.1759  | 0.1044  | 0.2487  |  0 hr 14 min \n",
      " 199  | 0.2091  | 0.1000  | 0.2417  |  0 hr 14 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  3   |  146  | 0.0922  | 0.2161  \n",
      "  0   | 9.2879  | 9.1082  | 11.7773 |  0 hr 14 min \n",
      "  1   | 2.7863  | 6.3228  | 8.2068  |  0 hr 14 min \n",
      "  2   | 1.9758  | 5.0036  | 6.4465  |  0 hr 14 min \n",
      "  3   | 1.8452  | 4.0393  | 5.1095  |  0 hr 14 min \n",
      "  4   | 1.2714  | 3.2673  | 4.0757  |  0 hr 14 min \n",
      "  5   | 0.9917  | 2.4098  | 3.0217  |  0 hr 14 min \n",
      "  6   | 0.9374  | 1.3410  | 1.6327  |  0 hr 14 min \n",
      "  7   | 0.7290  | 0.8317  | 0.9277  |  0 hr 14 min \n",
      "  8   | 0.6557  | 0.7503  | 0.9481  |  0 hr 14 min \n",
      "  9   | 0.7206  | 0.5708  | 0.6906  |  0 hr 14 min \n",
      " 10   | 0.5879  | 0.6299  | 0.8026  |  0 hr 14 min \n",
      " 11   | 0.5255  | 0.4522  | 0.5909  |  0 hr 14 min \n",
      " 12   | 0.5313  | 0.3875  | 0.5410  |  0 hr 15 min \n",
      " 13   | 0.4603  | 0.3832  | 0.5221  |  0 hr 15 min \n",
      " 14   | 0.4737  | 0.3901  | 0.5957  |  0 hr 15 min \n",
      " 15   | 0.4835  | 0.3565  | 0.5552  |  0 hr 15 min \n",
      " 16   | 0.4938  | 0.3522  | 0.5116  |  0 hr 15 min \n",
      " 17   | 0.4414  | 0.3689  | 0.5058  |  0 hr 15 min \n",
      " 18   | 0.4056  | 0.3149  | 0.4847  |  0 hr 15 min \n",
      " 19   | 0.4294  | 0.3091  | 0.5564  |  0 hr 15 min \n",
      " 20   | 0.4225  | 0.2910  | 0.5023  |  0 hr 15 min \n",
      " 21   | 0.4250  | 0.3263  | 0.4987  |  0 hr 15 min \n",
      " 22   | 0.4014  | 0.2886  | 0.5181  |  0 hr 15 min \n",
      " 23   | 0.3814  | 0.3425  | 0.5031  |  0 hr 15 min \n",
      " 24   | 0.4136  | 0.3132  | 0.6104  |  0 hr 15 min \n",
      " 25   | 0.4282  | 0.3429  | 0.4818  |  0 hr 15 min \n",
      " 26   | 0.4436  | 0.2740  | 0.4800  |  0 hr 15 min \n",
      " 27   | 0.4184  | 0.2803  | 0.4806  |  0 hr 15 min \n",
      " 28   | 0.4340  | 0.2795  | 0.5192  |  0 hr 15 min \n",
      " 29   | 0.3462  | 0.2565  | 0.4733  |  0 hr 15 min \n",
      " 30   | 0.3770  | 0.2575  | 0.4693  |  0 hr 15 min \n",
      " 31   | 0.3713  | 0.2443  | 0.4513  |  0 hr 15 min \n",
      " 32   | 0.3345  | 0.2343  | 0.4129  |  0 hr 15 min \n",
      " 33   | 0.3442  | 0.2269  | 0.4304  |  0 hr 15 min \n",
      " 34   | 0.3742  | 0.2286  | 0.4481  |  0 hr 15 min \n",
      " 35   | 0.3439  | 0.2929  | 0.4512  |  0 hr 15 min \n",
      " 36   | 0.3169  | 0.2643  | 0.4814  |  0 hr 15 min \n",
      " 37   | 0.3872  | 0.2330  | 0.4462  |  0 hr 15 min \n",
      " 38   | 0.3585  | 0.2432  | 0.4363  |  0 hr 15 min \n",
      " 39   | 0.3293  | 0.2283  | 0.4723  |  0 hr 15 min \n",
      " 40   | 0.3171  | 0.2475  | 0.4111  |  0 hr 15 min \n",
      " 41   | 0.3659  | 0.2149  | 0.4168  |  0 hr 15 min \n",
      " 42   | 0.2938  | 0.2165  | 0.4033  |  0 hr 15 min \n",
      " 43   | 0.2902  | 0.2363  | 0.5133  |  0 hr 15 min \n",
      " 44   | 0.3245  | 0.2046  | 0.4015  |  0 hr 15 min \n",
      " 45   | 0.3153  | 0.2379  | 0.4092  |  0 hr 15 min \n",
      " 46   | 0.2911  | 0.2121  | 0.4961  |  0 hr 15 min \n",
      " 47   | 0.2949  | 0.2187  | 0.4242  |  0 hr 15 min \n",
      " 48   | 0.3179  | 0.2040  | 0.4718  |  0 hr 15 min \n",
      " 49   | 0.2970  | 0.2230  | 0.4371  |  0 hr 15 min \n",
      " 50   | 0.2999  | 0.2102  | 0.5032  |  0 hr 15 min \n",
      " 51   | 0.3036  | 0.2035  | 0.4171  |  0 hr 15 min \n",
      " 52   | 0.2985  | 0.2252  | 0.4779  |  0 hr 16 min \n",
      " 53   | 0.3339  | 0.1901  | 0.4159  |  0 hr 16 min \n",
      " 54   | 0.3033  | 0.1878  | 0.4252  |  0 hr 16 min \n",
      " 55   | 0.3106  | 0.1918  | 0.4269  |  0 hr 16 min \n",
      " 56   | 0.3222  | 0.1996  | 0.4533  |  0 hr 16 min \n",
      " 57   | 0.2958  | 0.1862  | 0.4430  |  0 hr 16 min \n",
      " 58   | 0.2806  | 0.2035  | 0.4603  |  0 hr 16 min \n",
      " 59   | 0.2914  | 0.1795  | 0.4612  |  0 hr 16 min \n",
      " 60   | 0.2677  | 0.1751  | 0.4317  |  0 hr 16 min \n",
      " 61   | 0.2645  | 0.1830  | 0.4416  |  0 hr 16 min \n",
      " 62   | 0.2498  | 0.1863  | 0.4013  |  0 hr 16 min \n",
      " 63   | 0.2509  | 0.1791  | 0.4343  |  0 hr 16 min \n",
      " 64   | 0.2507  | 0.1678  | 0.4226  |  0 hr 16 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65   | 0.2514  | 0.1597  | 0.4001  |  0 hr 16 min \n",
      " 66   | 0.2335  | 0.1709  | 0.4479  |  0 hr 16 min \n",
      " 67   | 0.2720  | 0.1960  | 0.4332  |  0 hr 16 min \n",
      " 68   | 0.3018  | 0.1597  | 0.4199  |  0 hr 16 min \n",
      " 69   | 0.2918  | 0.1645  | 0.4223  |  0 hr 16 min \n",
      " 70   | 0.3524  | 0.2182  | 0.4858  |  0 hr 16 min \n",
      " 71   | 0.2606  | 0.1916  | 0.4543  |  0 hr 16 min \n",
      " 72   | 0.2962  | 0.1628  | 0.3848  |  0 hr 16 min \n",
      " 73   | 0.2603  | 0.1726  | 0.4642  |  0 hr 16 min \n",
      " 74   | 0.2271  | 0.1565  | 0.4619  |  0 hr 16 min \n",
      " 75   | 0.2911  | 0.1534  | 0.3953  |  0 hr 16 min \n",
      " 76   | 0.2503  | 0.1688  | 0.4308  |  0 hr 16 min \n",
      " 77   | 0.2324  | 0.1508  | 0.4083  |  0 hr 16 min \n",
      " 78   | 0.2605  | 0.1653  | 0.4425  |  0 hr 16 min \n",
      " 79   | 0.2428  | 0.1569  | 0.3938  |  0 hr 16 min \n",
      " 80   | 0.2542  | 0.1810  | 0.4646  |  0 hr 16 min \n",
      " 81   | 0.2374  | 0.1463  | 0.3978  |  0 hr 16 min \n",
      " 82   | 0.2118  | 0.1502  | 0.4514  |  0 hr 16 min \n",
      " 83   | 0.2519  | 0.1436  | 0.4024  |  0 hr 16 min \n",
      " 84   | 0.2135  | 0.1423  | 0.4335  |  0 hr 16 min \n",
      " 85   | 0.2693  | 0.1452  | 0.4230  |  0 hr 16 min \n",
      " 86   | 0.2739  | 0.1356  | 0.4160  |  0 hr 16 min \n",
      " 87   | 0.2018  | 0.2068  | 0.4711  |  0 hr 16 min \n",
      " 88   | 0.2748  | 0.1481  | 0.3879  |  0 hr 16 min \n",
      " 89   | 0.2036  | 0.1484  | 0.4160  |  0 hr 16 min \n",
      " 90   | 0.2268  | 0.1429  | 0.4295  |  0 hr 16 min \n",
      " 91   | 0.2410  | 0.1281  | 0.4066  |  0 hr 16 min \n",
      " 92   | 0.1969  | 0.1369  | 0.4258  |  0 hr 17 min \n",
      " 93   | 0.2447  | 0.1314  | 0.3918  |  0 hr 17 min \n",
      " 94   | 0.2365  | 0.1389  | 0.4011  |  0 hr 17 min \n",
      " 95   | 0.2387  | 0.1727  | 0.5286  |  0 hr 17 min \n",
      " 96   | 0.2634  | 0.1496  | 0.4225  |  0 hr 17 min \n",
      " 97   | 0.2767  | 0.1401  | 0.4172  |  0 hr 17 min \n",
      " 98   | 0.2167  | 0.1591  | 0.4332  |  0 hr 17 min \n",
      " 99   | 0.2098  | 0.1411  | 0.4605  |  0 hr 17 min \n",
      " 100  | 0.2102  | 0.1333  | 0.3819  |  0 hr 17 min \n",
      " 101  | 0.1936  | 0.1308  | 0.3879  |  0 hr 17 min \n",
      " 102  | 0.2082  | 0.1244  | 0.4186  |  0 hr 17 min \n",
      " 103  | 0.2556  | 0.1277  | 0.4162  |  0 hr 17 min \n",
      " 104  | 0.2102  | 0.1197  | 0.3872  |  0 hr 17 min \n",
      " 105  | 0.1918  | 0.1308  | 0.4632  |  0 hr 17 min \n",
      " 106  | 0.1905  | 0.1280  | 0.4279  |  0 hr 17 min \n",
      " 107  | 0.1835  | 0.1312  | 0.4575  |  0 hr 17 min \n",
      " 108  | 0.2261  | 0.1246  | 0.4111  |  0 hr 17 min \n",
      " 109  | 0.2014  | 0.1310  | 0.4801  |  0 hr 17 min \n",
      " 110  | 0.2049  | 0.1239  | 0.4200  |  0 hr 17 min \n",
      " 111  | 0.2356  | 0.1547  | 0.4704  |  0 hr 17 min \n",
      " 112  | 0.2830  | 0.1345  | 0.4251  |  0 hr 17 min \n",
      " 113  | 0.2412  | 0.1289  | 0.4502  |  0 hr 17 min \n",
      " 114  | 0.2287  | 0.1146  | 0.4299  |  0 hr 17 min \n",
      " 115  | 0.2018  | 0.1178  | 0.4437  |  0 hr 17 min \n",
      " 116  | 0.2164  | 0.1164  | 0.4066  |  0 hr 17 min \n",
      " 117  | 0.1874  | 0.1260  | 0.4000  |  0 hr 17 min \n",
      " 118  | 0.1961  | 0.1385  | 0.4667  |  0 hr 17 min \n",
      " 119  | 0.2121  | 0.1187  | 0.4285  |  0 hr 17 min \n",
      " 120  | 0.1834  | 0.1096  | 0.4011  |  0 hr 17 min \n",
      " 121  | 0.2120  | 0.1163  | 0.4111  |  0 hr 17 min \n",
      " 122  | 0.1843  | 0.1400  | 0.4789  |  0 hr 17 min \n",
      " 123  | 0.2052  | 0.1060  | 0.4302  |  0 hr 17 min \n",
      " 124  | 0.2085  | 0.1163  | 0.3969  |  0 hr 17 min \n",
      " 125  | 0.2222  | 0.1070  | 0.4258  |  0 hr 17 min \n",
      " 126  | 0.1806  | 0.1146  | 0.4058  |  0 hr 17 min \n",
      " 127  | 0.2107  | 0.1250  | 0.4801  |  0 hr 17 min \n",
      " 128  | 0.2154  | 0.1320  | 0.4073  |  0 hr 17 min \n",
      " 129  | 0.2266  | 0.1127  | 0.4132  |  0 hr 17 min \n",
      " 130  | 0.2780  | 0.1607  | 0.4319  |  0 hr 17 min \n",
      " 131  | 0.2093  | 0.1377  | 0.4870  |  0 hr 17 min \n",
      " 132  | 0.1991  | 0.1158  | 0.4105  |  0 hr 18 min \n",
      " 133  | 0.1743  | 0.1147  | 0.4319  |  0 hr 18 min \n",
      " 134  | 0.2006  | 0.1258  | 0.4678  |  0 hr 18 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  4   |  100  | 0.1060  | 0.3819  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(5):\n",
    "    \n",
    "    model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_MSE\"] = 9e8\n",
    "    best_param[\"valid_MSE\"] = 9e8\n",
    "    for epoch in range(800):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'min')  \n",
    "        log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "        \n",
    "        if train_MSE < best_param[\"train_MSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_MSE\"] = train_MSE\n",
    "        if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_MSE\"] = valid_MSE\n",
    "            if valid_MSE < 0.35:\n",
    "                 torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "        if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train_MSE | valid MSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model\n",
    "# best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "# test_MAE, test_MSE = eval(model, test_df)\n",
    "# print(\"best epoch:\",best_param[\"test_epoch\"],\"\\n\",\"test MSE:\",test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(20):\n",
    "#     losses = train(smiles_list[valid_fold[fold_index]])\n",
    "#     print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
