{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, graph_dict, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1128\n",
      "number of successfully processed smiles:  1128\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'solubility'\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "\n",
    "raw_filename = \"../data/delaney-processed.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \", len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "epochs = 80\n",
    "batch_size =100\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 50\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 3\n",
    "K = 2\n",
    "T = 2\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/delaney-processed.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  101\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "train_fold = []\n",
    "valid_fold = []\n",
    "for k, (train_idx, valid_idx) in enumerate(kfold.split(smiles_list)):\n",
    "    train_fold.append(train_idx)\n",
    "    valid_fold.append(valid_idx)\n",
    "    \n",
    "# avoiding the last batch has too few samples by slightly tune the batch_size\n",
    "while (len(train_fold[0]) % batch_size) / batch_size <0.8:\n",
    "    batch_size +=1\n",
    "print(\"batch size: \", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166954\n",
      "sum_importance torch.Size([1])\n",
      "preprocess.0.linear.weight torch.Size([50, 39])\n",
      "preprocess.0.linear.bias torch.Size([50])\n",
      "preprocess.0.bn.weight torch.Size([50])\n",
      "preprocess.0.bn.bias torch.Size([50])\n",
      "propagate.0.encoder.0.linear.weight torch.Size([2500, 10])\n",
      "propagate.0.encoder.0.linear.bias torch.Size([2500])\n",
      "propagate.0.encoder.0.bn.weight torch.Size([2500])\n",
      "propagate.0.encoder.0.bn.bias torch.Size([2500])\n",
      "propagate.0.align.weight torch.Size([1, 100])\n",
      "propagate.0.align.bias torch.Size([1])\n",
      "propagate.0.attend.linear.weight torch.Size([50, 50])\n",
      "propagate.0.attend.linear.bias torch.Size([50])\n",
      "propagate.0.attend.bn.weight torch.Size([50])\n",
      "propagate.0.attend.bn.bias torch.Size([50])\n",
      "propagate.0.gru.weight_ih torch.Size([150, 50])\n",
      "propagate.0.gru.weight_hh torch.Size([150, 50])\n",
      "propagate.0.gru.bias_ih torch.Size([150])\n",
      "propagate.0.gru.bias_hh torch.Size([150])\n",
      "propagate.1.encoder.0.linear.weight torch.Size([2500, 10])\n",
      "propagate.1.encoder.0.linear.bias torch.Size([2500])\n",
      "propagate.1.encoder.0.bn.weight torch.Size([2500])\n",
      "propagate.1.encoder.0.bn.bias torch.Size([2500])\n",
      "propagate.1.align.weight torch.Size([1, 100])\n",
      "propagate.1.align.bias torch.Size([1])\n",
      "propagate.1.attend.linear.weight torch.Size([50, 50])\n",
      "propagate.1.attend.linear.bias torch.Size([50])\n",
      "propagate.1.attend.bn.weight torch.Size([50])\n",
      "propagate.1.attend.bn.bias torch.Size([50])\n",
      "propagate.1.gru.weight_ih torch.Size([150, 50])\n",
      "propagate.1.gru.weight_hh torch.Size([150, 50])\n",
      "propagate.1.gru.bias_ih torch.Size([150])\n",
      "propagate.1.gru.bias_hh torch.Size([150])\n",
      "superGather.0.align.weight torch.Size([1, 100])\n",
      "superGather.0.align.bias torch.Size([1])\n",
      "superGather.0.attend.linear.weight torch.Size([50, 50])\n",
      "superGather.0.attend.linear.bias torch.Size([50])\n",
      "superGather.0.attend.bn.weight torch.Size([50])\n",
      "superGather.0.attend.bn.bias torch.Size([50])\n",
      "superGather.0.gru.weight_ih torch.Size([150, 50])\n",
      "superGather.0.gru.weight_hh torch.Size([150, 50])\n",
      "superGather.0.gru.bias_ih torch.Size([150])\n",
      "superGather.0.gru.bias_hh torch.Size([150])\n",
      "superGather.1.align.weight torch.Size([1, 100])\n",
      "superGather.1.align.bias torch.Size([1])\n",
      "superGather.1.attend.linear.weight torch.Size([50, 50])\n",
      "superGather.1.attend.linear.bias torch.Size([50])\n",
      "superGather.1.attend.bn.weight torch.Size([50])\n",
      "superGather.1.attend.bn.bias torch.Size([50])\n",
      "superGather.1.gru.weight_ih torch.Size([150, 50])\n",
      "superGather.1.gru.weight_hh torch.Size([150, 50])\n",
      "superGather.1.gru.bias_ih torch.Size([150])\n",
      "superGather.1.gru.bias_hh torch.Size([150])\n",
      "predict.0.linear.weight torch.Size([512, 50])\n",
      "predict.0.linear.bias torch.Size([512])\n",
      "predict.0.bn.weight torch.Size([512])\n",
      "predict.0.bn.bias torch.Size([512])\n",
      "predict.3.weight torch.Size([1, 512])\n",
      "predict.3.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED))\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(train_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = loss_function(mol_prediction, label.view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(smiles_list):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in enumerate(eval_loader):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        MAE = F.l1_loss(mol_prediction, label.view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, label.view(-1,1), reduction='none')\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log = Logger()\n",
    "# log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "# f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "# log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "# start = timer()\n",
    "\n",
    "# best_param ={}\n",
    "# best_param[\"train_epoch\"] = 0\n",
    "# best_param[\"valid_epoch\"] = 0\n",
    "# best_param[\"train_MSE\"] = 9e8\n",
    "# best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "# fold_index = 3\n",
    "# for epoch in range(800):\n",
    "#     losses = train(smiles_list[train_fold[fold_index]])\n",
    "#     traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "#     valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "\n",
    "#     timing = time_to_str((timer() - start), 'min')  \n",
    "#     log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "\n",
    "#     if train_MSE < best_param[\"train_MSE\"]:\n",
    "#         best_param[\"train_epoch\"] = epoch\n",
    "#         best_param[\"train_MSE\"] = train_MSE\n",
    "#     if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "#         best_param[\"valid_epoch\"] = epoch\n",
    "#         best_param[\"valid_MSE\"] = valid_MSE\n",
    "# #         if valid_MSE < 0.35:\n",
    "# #              torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "#     if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "#         break\n",
    "# print(best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | loss | train MSE |  valid MSE |  time \n",
      "  0   | 9.6158  | 9.0537  | 9.2480  |  0 hr 00 min \n",
      "  1   | 4.0558  | 3.0172  | 3.9857  |  0 hr 00 min \n",
      "  2   | 1.8282  | 4.9734  | 6.3893  |  0 hr 00 min \n",
      "  3   | 1.2649  | 4.2551  | 5.4988  |  0 hr 00 min \n",
      "  4   | 1.0251  | 2.4785  | 2.9928  |  0 hr 00 min \n",
      "  5   | 0.7896  | 0.8784  | 0.9691  |  0 hr 00 min \n",
      "  6   | 0.7194  | 0.6223  | 0.7199  |  0 hr 00 min \n",
      "  7   | 0.6675  | 0.5568  | 0.7001  |  0 hr 00 min \n",
      "  8   | 0.5290  | 0.3468  | 0.4687  |  0 hr 00 min \n",
      "  9   | 0.4904  | 0.3225  | 0.4655  |  0 hr 00 min \n",
      " 10   | 0.4699  | 0.3357  | 0.4954  |  0 hr 00 min \n",
      " 11   | 0.4607  | 0.3045  | 0.4165  |  0 hr 00 min \n",
      " 12   | 0.5360  | 0.2613  | 0.3795  |  0 hr 00 min \n",
      " 13   | 0.4829  | 0.3762  | 0.4782  |  0 hr 00 min \n",
      " 14   | 0.4325  | 0.2942  | 0.4484  |  0 hr 00 min \n",
      " 15   | 0.3933  | 0.2413  | 0.3861  |  0 hr 00 min \n",
      " 16   | 0.4260  | 0.2588  | 0.4238  |  0 hr 00 min \n",
      " 17   | 0.3726  | 0.2591  | 0.3729  |  0 hr 01 min \n",
      " 18   | 0.4171  | 0.2511  | 0.4223  |  0 hr 01 min \n",
      " 19   | 0.3508  | 0.2422  | 0.4037  |  0 hr 01 min \n",
      " 20   | 0.4051  | 0.2160  | 0.3732  |  0 hr 01 min \n",
      " 21   | 0.4170  | 0.2395  | 0.3714  |  0 hr 01 min \n",
      " 22   | 0.3248  | 0.2211  | 0.3859  |  0 hr 01 min \n",
      " 23   | 0.3523  | 0.2059  | 0.3439  |  0 hr 01 min \n",
      " 24   | 0.3572  | 0.2079  | 0.4063  |  0 hr 01 min \n",
      " 25   | 0.3667  | 0.2031  | 0.4007  |  0 hr 01 min \n",
      " 26   | 0.3113  | 0.1785  | 0.3496  |  0 hr 01 min \n",
      " 27   | 0.2827  | 0.1854  | 0.3875  |  0 hr 01 min \n",
      " 28   | 0.3179  | 0.1791  | 0.3792  |  0 hr 01 min \n",
      " 29   | 0.3591  | 0.1849  | 0.3495  |  0 hr 01 min \n",
      " 30   | 0.3035  | 0.2395  | 0.4373  |  0 hr 01 min \n",
      " 31   | 0.2802  | 0.1760  | 0.3678  |  0 hr 02 min \n",
      " 32   | 0.2561  | 0.1739  | 0.3938  |  0 hr 02 min \n",
      " 33   | 0.3424  | 0.2078  | 0.4393  |  0 hr 02 min \n",
      " 34   | 0.3086  | 0.1635  | 0.3880  |  0 hr 02 min \n",
      " 35   | 0.2766  | 0.1556  | 0.3818  |  0 hr 02 min \n",
      " 36   | 0.2762  | 0.1404  | 0.3508  |  0 hr 02 min \n",
      " 37   | 0.2695  | 0.1570  | 0.3811  |  0 hr 02 min \n",
      " 38   | 0.3262  | 0.1463  | 0.3487  |  0 hr 02 min \n",
      " 39   | 0.2431  | 0.1510  | 0.3861  |  0 hr 02 min \n",
      " 40   | 0.2446  | 0.1365  | 0.3379  |  0 hr 02 min \n",
      " 41   | 0.2825  | 0.1399  | 0.3705  |  0 hr 02 min \n",
      " 42   | 0.2567  | 0.1611  | 0.3602  |  0 hr 02 min \n",
      " 43   | 0.2658  | 0.1471  | 0.3529  |  0 hr 02 min \n",
      " 44   | 0.2508  | 0.1354  | 0.3377  |  0 hr 02 min \n",
      " 45   | 0.2709  | 0.1516  | 0.3895  |  0 hr 02 min \n",
      " 46   | 0.3219  | 0.1580  | 0.3587  |  0 hr 03 min \n",
      " 47   | 0.3012  | 0.1945  | 0.4700  |  0 hr 03 min \n",
      " 48   | 0.2363  | 0.1260  | 0.3396  |  0 hr 03 min \n",
      " 49   | 0.2827  | 0.1180  | 0.3203  |  0 hr 03 min \n",
      " 50   | 0.2640  | 0.1214  | 0.3438  |  0 hr 03 min \n",
      " 51   | 0.2257  | 0.1555  | 0.4172  |  0 hr 03 min \n",
      " 52   | 0.2416  | 0.1125  | 0.3176  |  0 hr 03 min \n",
      " 53   | 0.2752  | 0.1468  | 0.3745  |  0 hr 03 min \n",
      " 54   | 0.2060  | 0.1214  | 0.3443  |  0 hr 03 min \n",
      " 55   | 0.2441  | 0.1060  | 0.3397  |  0 hr 03 min \n",
      " 56   | 0.2322  | 0.1193  | 0.3597  |  0 hr 03 min \n",
      " 57   | 0.1931  | 0.1187  | 0.3223  |  0 hr 03 min \n",
      " 58   | 0.2619  | 0.1274  | 0.3905  |  0 hr 03 min \n",
      " 59   | 0.2204  | 0.1045  | 0.3350  |  0 hr 03 min \n",
      " 60   | 0.2381  | 0.1223  | 0.3785  |  0 hr 04 min \n",
      " 61   | 0.2229  | 0.1169  | 0.3267  |  0 hr 04 min \n",
      " 62   | 0.2130  | 0.1199  | 0.3880  |  0 hr 04 min \n",
      " 63   | 0.2031  | 0.1122  | 0.3928  |  0 hr 04 min \n",
      " 64   | 0.1668  | 0.0998  | 0.3534  |  0 hr 04 min \n",
      " 65   | 0.2059  | 0.0998  | 0.3739  |  0 hr 04 min \n",
      " 66   | 0.1849  | 0.1016  | 0.3858  |  0 hr 04 min \n",
      " 67   | 0.2642  | 0.1291  | 0.4114  |  0 hr 04 min \n",
      " 68   | 0.2573  | 0.1190  | 0.3649  |  0 hr 04 min \n",
      " 69   | 0.2506  | 0.1183  | 0.3762  |  0 hr 04 min \n",
      " 70   | 0.2162  | 0.1032  | 0.3663  |  0 hr 04 min \n",
      " 71   | 0.2425  | 0.1220  | 0.3813  |  0 hr 04 min \n",
      " 72   | 0.2272  | 0.1056  | 0.3600  |  0 hr 04 min \n",
      " 73   | 0.2486  | 0.1372  | 0.4048  |  0 hr 04 min \n",
      " 74   | 0.2370  | 0.1175  | 0.3734  |  0 hr 04 min \n",
      " 75   | 0.2296  | 0.0938  | 0.3467  |  0 hr 05 min \n",
      " 76   | 0.2234  | 0.0954  | 0.3592  |  0 hr 05 min \n",
      " 77   | 0.1937  | 0.1088  | 0.3482  |  0 hr 05 min \n",
      " 78   | 0.2555  | 0.1034  | 0.3832  |  0 hr 05 min \n",
      " 79   | 0.1939  | 0.1200  | 0.4292  |  0 hr 05 min \n",
      " 80   | 0.2086  | 0.0972  | 0.3534  |  0 hr 05 min \n",
      " 81   | 0.2117  | 0.0860  | 0.3637  |  0 hr 05 min \n",
      " 82   | 0.1729  | 0.1006  | 0.3688  |  0 hr 05 min \n",
      " 83   | 0.1794  | 0.0898  | 0.3889  |  0 hr 05 min \n",
      " 84   | 0.1657  | 0.0867  | 0.3578  |  0 hr 05 min \n",
      " 85   | 0.1861  | 0.0939  | 0.3690  |  0 hr 05 min \n",
      " 86   | 0.1813  | 0.0892  | 0.3613  |  0 hr 05 min \n",
      " 87   | 0.1839  | 0.0844  | 0.3165  |  0 hr 05 min \n",
      " 88   | 0.1916  | 0.0955  | 0.3616  |  0 hr 05 min \n",
      " 89   | 0.1825  | 0.0802  | 0.3614  |  0 hr 05 min \n",
      " 90   | 0.1895  | 0.0763  | 0.3604  |  0 hr 06 min \n",
      " 91   | 0.1485  | 0.0934  | 0.3603  |  0 hr 06 min \n",
      " 92   | 0.1745  | 0.0805  | 0.3634  |  0 hr 06 min \n",
      " 93   | 0.1769  | 0.0812  | 0.3348  |  0 hr 06 min \n",
      " 94   | 0.1858  | 0.0963  | 0.3667  |  0 hr 06 min \n",
      " 95   | 0.1830  | 0.1276  | 0.3965  |  0 hr 06 min \n",
      " 96   | 0.2063  | 0.1270  | 0.3839  |  0 hr 06 min \n",
      " 97   | 0.1803  | 0.0928  | 0.3494  |  0 hr 06 min \n",
      " 98   | 0.2067  | 0.0922  | 0.3619  |  0 hr 06 min \n",
      " 99   | 0.1690  | 0.0799  | 0.3395  |  0 hr 06 min \n",
      " 100  | 0.1831  | 0.1086  | 0.3988  |  0 hr 06 min \n",
      " 101  | 0.1574  | 0.0771  | 0.3133  |  0 hr 06 min \n",
      " 102  | 0.1743  | 0.0876  | 0.3618  |  0 hr 06 min \n",
      " 103  | 0.1766  | 0.0893  | 0.3672  |  0 hr 06 min \n",
      " 104  | 0.2179  | 0.0841  | 0.3167  |  0 hr 07 min \n",
      " 105  | 0.1750  | 0.0821  | 0.3434  |  0 hr 07 min \n",
      " 106  | 0.1725  | 0.0789  | 0.3097  |  0 hr 07 min \n",
      " 107  | 0.1849  | 0.0810  | 0.3467  |  0 hr 07 min \n",
      " 108  | 0.1799  | 0.0960  | 0.3791  |  0 hr 07 min \n",
      " 109  | 0.1989  | 0.1070  | 0.3543  |  0 hr 07 min \n",
      " 110  | 0.2079  | 0.0749  | 0.3794  |  0 hr 07 min \n",
      " 111  | 0.1553  | 0.1038  | 0.3896  |  0 hr 07 min \n",
      " 112  | 0.2825  | 0.0852  | 0.3583  |  0 hr 07 min \n",
      " 113  | 0.1564  | 0.0683  | 0.3275  |  0 hr 07 min \n",
      " 114  | 0.2247  | 0.0974  | 0.4040  |  0 hr 07 min \n",
      " 115  | 0.1923  | 0.0943  | 0.3057  |  0 hr 07 min \n",
      " 116  | 0.1487  | 0.0894  | 0.3742  |  0 hr 07 min \n",
      " 117  | 0.1689  | 0.0837  | 0.3259  |  0 hr 07 min \n",
      " 118  | 0.2269  | 0.1256  | 0.4332  |  0 hr 07 min \n",
      " 119  | 0.2309  | 0.0741  | 0.3202  |  0 hr 08 min \n",
      " 120  | 0.1450  | 0.0636  | 0.3327  |  0 hr 08 min \n",
      " 121  | 0.1521  | 0.0719  | 0.3531  |  0 hr 08 min \n",
      " 122  | 0.1870  | 0.0818  | 0.3450  |  0 hr 08 min \n",
      " 123  | 0.1746  | 0.0648  | 0.3479  |  0 hr 08 min \n",
      " 124  | 0.1418  | 0.0833  | 0.3456  |  0 hr 08 min \n",
      " 125  | 0.2123  | 0.0673  | 0.3290  |  0 hr 08 min \n",
      " 126  | 0.2024  | 0.0625  | 0.3215  |  0 hr 08 min \n",
      " 127  | 0.1492  | 0.0743  | 0.3341  |  0 hr 08 min \n",
      " 128  | 0.1416  | 0.0670  | 0.3288  |  0 hr 08 min \n",
      " 129  | 0.1764  | 0.0673  | 0.3147  |  0 hr 08 min \n",
      " 130  | 0.1325  | 0.0737  | 0.3488  |  0 hr 08 min \n",
      " 131  | 0.1520  | 0.0731  | 0.3375  |  0 hr 08 min \n",
      " 132  | 0.1342  | 0.0746  | 0.3537  |  0 hr 08 min \n",
      " 133  | 0.1520  | 0.0701  | 0.3604  |  0 hr 09 min \n",
      " 134  | 0.1459  | 0.0664  | 0.3368  |  0 hr 09 min \n",
      " 135  | 0.1722  | 0.0889  | 0.3916  |  0 hr 09 min \n",
      " 136  | 0.1532  | 0.0614  | 0.3355  |  0 hr 09 min \n",
      " 137  | 0.1651  | 0.0866  | 0.3213  |  0 hr 09 min \n",
      " 138  | 0.1984  | 0.0664  | 0.3359  |  0 hr 09 min \n",
      " 139  | 0.1520  | 0.0708  | 0.3091  |  0 hr 09 min \n",
      " 140  | 0.1197  | 0.0657  | 0.3313  |  0 hr 09 min \n",
      " 141  | 0.1401  | 0.0691  | 0.3305  |  0 hr 09 min \n",
      " 142  | 0.1440  | 0.0636  | 0.3125  |  0 hr 09 min \n",
      " 143  | 0.1644  | 0.0818  | 0.3275  |  0 hr 09 min \n",
      " 144  | 0.2082  | 0.0641  | 0.3300  |  0 hr 09 min \n",
      " 145  | 0.1744  | 0.0772  | 0.3363  |  0 hr 09 min \n",
      " 146  | 0.1491  | 0.0683  | 0.3266  |  0 hr 10 min \n",
      " 147  | 0.2069  | 0.0772  | 0.3136  |  0 hr 10 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  0   |  115  | 0.0614  | 0.3057  \n",
      "  0   | 10.6315 | 8.3364  | 7.7400  |  0 hr 10 min \n",
      "  1   | 4.8933  | 4.6592  | 3.9702  |  0 hr 10 min \n",
      "  2   | 2.3461  | 7.0547  | 6.6770  |  0 hr 10 min \n",
      "  3   | 1.3333  | 3.1469  | 2.9497  |  0 hr 10 min \n",
      "  4   | 1.0789  | 2.0587  | 1.8883  |  0 hr 10 min \n",
      "  5   | 0.9483  | 1.1625  | 1.1555  |  0 hr 10 min \n",
      "  6   | 0.8147  | 0.8319  | 0.8717  |  0 hr 10 min \n",
      "  7   | 0.6870  | 0.5100  | 0.5312  |  0 hr 10 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8   | 0.6950  | 0.4431  | 0.5101  |  0 hr 10 min \n",
      "  9   | 0.6304  | 0.4260  | 0.5098  |  0 hr 10 min \n",
      " 10   | 0.4975  | 0.5013  | 0.5990  |  0 hr 10 min \n",
      " 11   | 0.5166  | 0.3305  | 0.4061  |  0 hr 10 min \n",
      " 12   | 0.5006  | 0.3210  | 0.4050  |  0 hr 10 min \n",
      " 13   | 0.5054  | 0.2950  | 0.3897  |  0 hr 11 min \n",
      " 14   | 0.4592  | 0.5509  | 0.6564  |  0 hr 11 min \n",
      " 15   | 0.4742  | 0.2976  | 0.4191  |  0 hr 11 min \n",
      " 16   | 0.4111  | 0.2522  | 0.3609  |  0 hr 11 min \n",
      " 17   | 0.4034  | 0.2948  | 0.4202  |  0 hr 11 min \n",
      " 18   | 0.4066  | 0.2370  | 0.3608  |  0 hr 11 min \n",
      " 19   | 0.4141  | 0.2900  | 0.3932  |  0 hr 11 min \n",
      " 20   | 0.3723  | 0.2308  | 0.3526  |  0 hr 11 min \n",
      " 21   | 0.4072  | 0.2178  | 0.3717  |  0 hr 11 min \n",
      " 22   | 0.3810  | 0.2217  | 0.3986  |  0 hr 11 min \n",
      " 23   | 0.3783  | 0.2898  | 0.4681  |  0 hr 11 min \n",
      " 24   | 0.3932  | 0.2616  | 0.4172  |  0 hr 11 min \n",
      " 25   | 0.3577  | 0.2215  | 0.4189  |  0 hr 11 min \n",
      " 26   | 0.3613  | 0.2282  | 0.4048  |  0 hr 11 min \n",
      " 27   | 0.3177  | 0.2490  | 0.3877  |  0 hr 11 min \n",
      " 28   | 0.3312  | 0.2772  | 0.4665  |  0 hr 12 min \n",
      " 29   | 0.4295  | 0.2037  | 0.3607  |  0 hr 12 min \n",
      " 30   | 0.3596  | 0.2112  | 0.3835  |  0 hr 12 min \n",
      " 31   | 0.3000  | 0.1816  | 0.4067  |  0 hr 12 min \n",
      " 32   | 0.3160  | 0.1945  | 0.3967  |  0 hr 12 min \n",
      " 33   | 0.3265  | 0.1672  | 0.3447  |  0 hr 12 min \n",
      " 34   | 0.2852  | 0.1707  | 0.3790  |  0 hr 12 min \n",
      " 35   | 0.2783  | 0.1817  | 0.3934  |  0 hr 12 min \n",
      " 36   | 0.2784  | 0.1817  | 0.4060  |  0 hr 12 min \n",
      " 37   | 0.3206  | 0.1624  | 0.3803  |  0 hr 12 min \n",
      " 38   | 0.2849  | 0.1971  | 0.4036  |  0 hr 12 min \n",
      " 39   | 0.3157  | 0.1810  | 0.3453  |  0 hr 12 min \n",
      " 40   | 0.2512  | 0.1760  | 0.4065  |  0 hr 12 min \n",
      " 41   | 0.2952  | 0.1668  | 0.3783  |  0 hr 12 min \n",
      " 42   | 0.3220  | 0.1799  | 0.3801  |  0 hr 12 min \n",
      " 43   | 0.3136  | 0.1814  | 0.4370  |  0 hr 13 min \n",
      " 44   | 0.2805  | 0.1604  | 0.3946  |  0 hr 13 min \n",
      " 45   | 0.2845  | 0.1610  | 0.3622  |  0 hr 13 min \n",
      " 46   | 0.2408  | 0.1419  | 0.3945  |  0 hr 13 min \n",
      " 47   | 0.2562  | 0.1402  | 0.3828  |  0 hr 13 min \n",
      " 48   | 0.2384  | 0.1416  | 0.3841  |  0 hr 13 min \n",
      " 49   | 0.2512  | 0.1573  | 0.4396  |  0 hr 13 min \n",
      " 50   | 0.2848  | 0.1694  | 0.3971  |  0 hr 13 min \n",
      " 51   | 0.2836  | 0.1401  | 0.3954  |  0 hr 13 min \n",
      " 52   | 0.2400  | 0.1465  | 0.4160  |  0 hr 13 min \n",
      " 53   | 0.2872  | 0.1416  | 0.3841  |  0 hr 13 min \n",
      " 54   | 0.2213  | 0.1210  | 0.4045  |  0 hr 13 min \n",
      " 55   | 0.2467  | 0.1285  | 0.4321  |  0 hr 13 min \n",
      " 56   | 0.2478  | 0.1548  | 0.4056  |  0 hr 13 min \n",
      " 57   | 0.2561  | 0.1349  | 0.4281  |  0 hr 13 min \n",
      " 58   | 0.2316  | 0.1396  | 0.3957  |  0 hr 14 min \n",
      " 59   | 0.2181  | 0.1275  | 0.3971  |  0 hr 14 min \n",
      " 60   | 0.2661  | 0.1402  | 0.4323  |  0 hr 14 min \n",
      " 61   | 0.2612  | 0.1214  | 0.4600  |  0 hr 14 min \n",
      " 62   | 0.2435  | 0.1148  | 0.3967  |  0 hr 14 min \n",
      " 63   | 0.1987  | 0.1208  | 0.4302  |  0 hr 14 min \n",
      " 64   | 0.2235  | 0.1144  | 0.3829  |  0 hr 14 min \n",
      " 65   | 0.2350  | 0.1051  | 0.3748  |  0 hr 14 min \n",
      " 66   | 0.2165  | 0.1212  | 0.4233  |  0 hr 14 min \n",
      " 67   | 0.2332  | 0.1254  | 0.4296  |  0 hr 14 min \n",
      " 68   | 0.2276  | 0.0974  | 0.4096  |  0 hr 14 min \n",
      " 69   | 0.2274  | 0.1221  | 0.3957  |  0 hr 14 min \n",
      " 70   | 0.1977  | 0.1163  | 0.4232  |  0 hr 14 min \n",
      " 71   | 0.1883  | 0.0936  | 0.3972  |  0 hr 14 min \n",
      " 72   | 0.1893  | 0.0976  | 0.3995  |  0 hr 14 min \n",
      " 73   | 0.1949  | 0.1003  | 0.4183  |  0 hr 15 min \n",
      " 74   | 0.1981  | 0.0964  | 0.3914  |  0 hr 15 min \n",
      " 75   | 0.2050  | 0.1079  | 0.3876  |  0 hr 15 min \n",
      " 76   | 0.2085  | 0.0966  | 0.4017  |  0 hr 15 min \n",
      " 77   | 0.2299  | 0.1191  | 0.3922  |  0 hr 15 min \n",
      " 78   | 0.2371  | 0.1145  | 0.4055  |  0 hr 15 min \n",
      " 79   | 0.1901  | 0.1127  | 0.4097  |  0 hr 15 min \n",
      " 80   | 0.2176  | 0.1510  | 0.4591  |  0 hr 15 min \n",
      " 81   | 0.1871  | 0.1030  | 0.3980  |  0 hr 15 min \n",
      " 82   | 0.2173  | 0.0939  | 0.3840  |  0 hr 15 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  1   |  33   | 0.0936  | 0.3447  \n",
      "  0   | 8.8495  | 8.8624  | 9.1637  |  0 hr 15 min \n",
      "  1   | 4.1965  | 2.9737  | 3.2737  |  0 hr 15 min \n",
      "  2   | 2.0317  | 2.2362  | 2.6448  |  0 hr 15 min \n",
      "  3   | 1.2718  | 2.5696  | 3.0002  |  0 hr 15 min \n",
      "  4   | 1.0085  | 2.6702  | 3.0584  |  0 hr 15 min \n",
      "  5   | 0.8992  | 1.6750  | 2.0067  |  0 hr 15 min \n",
      "  6   | 0.8147  | 0.6149  | 0.8556  |  0 hr 16 min \n",
      "  7   | 0.7676  | 0.8485  | 1.0569  |  0 hr 16 min \n",
      "  8   | 0.6806  | 0.5956  | 0.8951  |  0 hr 16 min \n",
      "  9   | 0.5994  | 0.4311  | 0.6279  |  0 hr 16 min \n",
      " 10   | 0.5489  | 0.3489  | 0.5577  |  0 hr 16 min \n",
      " 11   | 0.4840  | 0.3257  | 0.5341  |  0 hr 16 min \n",
      " 12   | 0.5098  | 0.3637  | 0.5777  |  0 hr 16 min \n",
      " 13   | 0.4085  | 0.2850  | 0.4725  |  0 hr 16 min \n",
      " 14   | 0.4218  | 0.2851  | 0.4771  |  0 hr 16 min \n",
      " 15   | 0.4300  | 0.2760  | 0.4963  |  0 hr 16 min \n",
      " 16   | 0.4099  | 0.2858  | 0.4969  |  0 hr 16 min \n",
      " 17   | 0.4077  | 0.2582  | 0.5148  |  0 hr 16 min \n",
      " 18   | 0.3768  | 0.2536  | 0.4600  |  0 hr 16 min \n",
      " 19   | 0.3671  | 0.2453  | 0.4565  |  0 hr 16 min \n",
      " 20   | 0.4349  | 0.2576  | 0.4548  |  0 hr 16 min \n",
      " 21   | 0.4106  | 0.2407  | 0.4492  |  0 hr 16 min \n",
      " 22   | 0.4403  | 0.2806  | 0.5033  |  0 hr 17 min \n",
      " 23   | 0.3523  | 0.2256  | 0.4139  |  0 hr 17 min \n",
      " 24   | 0.3677  | 0.2439  | 0.5118  |  0 hr 17 min \n",
      " 25   | 0.3564  | 0.2029  | 0.4349  |  0 hr 17 min \n",
      " 26   | 0.3703  | 0.2109  | 0.4740  |  0 hr 17 min \n",
      " 27   | 0.3218  | 0.2083  | 0.4487  |  0 hr 17 min \n",
      " 28   | 0.3430  | 0.2107  | 0.4504  |  0 hr 17 min \n",
      " 29   | 0.3067  | 0.1917  | 0.4356  |  0 hr 17 min \n",
      " 30   | 0.2695  | 0.1926  | 0.3963  |  0 hr 17 min \n",
      " 31   | 0.3205  | 0.1857  | 0.4110  |  0 hr 17 min \n",
      " 32   | 0.2929  | 0.1633  | 0.4359  |  0 hr 17 min \n",
      " 33   | 0.2731  | 0.1651  | 0.4153  |  0 hr 17 min \n",
      " 34   | 0.2857  | 0.2025  | 0.4476  |  0 hr 17 min \n",
      " 35   | 0.2611  | 0.1575  | 0.3905  |  0 hr 17 min \n",
      " 36   | 0.2835  | 0.1775  | 0.4374  |  0 hr 17 min \n",
      " 37   | 0.2635  | 0.1784  | 0.4255  |  0 hr 17 min \n",
      " 38   | 0.2275  | 0.1468  | 0.3850  |  0 hr 18 min \n",
      " 39   | 0.2561  | 0.1416  | 0.4041  |  0 hr 18 min \n",
      " 40   | 0.3228  | 0.1921  | 0.4515  |  0 hr 18 min \n",
      " 41   | 0.3201  | 0.1365  | 0.4009  |  0 hr 18 min \n",
      " 42   | 0.3049  | 0.1841  | 0.5021  |  0 hr 18 min \n",
      " 43   | 0.2434  | 0.1716  | 0.5137  |  0 hr 18 min \n",
      " 44   | 0.2389  | 0.1400  | 0.4055  |  0 hr 18 min \n",
      " 45   | 0.2611  | 0.1374  | 0.4132  |  0 hr 18 min \n",
      " 46   | 0.2766  | 0.1470  | 0.4440  |  0 hr 18 min \n",
      " 47   | 0.3076  | 0.1561  | 0.4462  |  0 hr 18 min \n",
      " 48   | 0.2556  | 0.1278  | 0.4122  |  0 hr 18 min \n",
      " 49   | 0.2324  | 0.1305  | 0.4250  |  0 hr 18 min \n",
      " 50   | 0.2259  | 0.1209  | 0.4005  |  0 hr 18 min \n",
      " 51   | 0.2077  | 0.1182  | 0.4335  |  0 hr 18 min \n",
      " 52   | 0.2261  | 0.1356  | 0.4324  |  0 hr 18 min \n",
      " 53   | 0.2665  | 0.1408  | 0.4348  |  0 hr 18 min \n",
      " 54   | 0.2934  | 0.1139  | 0.4252  |  0 hr 18 min \n",
      " 55   | 0.1822  | 0.1138  | 0.4008  |  0 hr 19 min \n",
      " 56   | 0.2402  | 0.1146  | 0.4380  |  0 hr 19 min \n",
      " 57   | 0.3155  | 0.1142  | 0.4103  |  0 hr 19 min \n",
      " 58   | 0.2990  | 0.1223  | 0.4213  |  0 hr 19 min \n",
      " 59   | 0.2363  | 0.1046  | 0.3818  |  0 hr 19 min \n",
      " 60   | 0.2137  | 0.1341  | 0.4361  |  0 hr 19 min \n",
      " 61   | 0.2042  | 0.1359  | 0.4419  |  0 hr 19 min \n",
      " 62   | 0.1728  | 0.1291  | 0.4668  |  0 hr 19 min \n",
      " 63   | 0.2121  | 0.1052  | 0.4201  |  0 hr 19 min \n",
      " 64   | 0.2056  | 0.1104  | 0.4204  |  0 hr 19 min \n",
      " 65   | 0.2082  | 0.0995  | 0.3962  |  0 hr 19 min \n",
      " 66   | 0.2377  | 0.0965  | 0.4064  |  0 hr 19 min \n",
      " 67   | 0.2059  | 0.1091  | 0.4193  |  0 hr 19 min \n",
      " 68   | 0.2024  | 0.1108  | 0.4317  |  0 hr 19 min \n",
      " 69   | 0.2028  | 0.1187  | 0.4328  |  0 hr 19 min \n",
      " 70   | 0.2360  | 0.1104  | 0.4500  |  0 hr 19 min \n",
      " 71   | 0.2684  | 0.1060  | 0.4047  |  0 hr 19 min \n",
      " 72   | 0.1853  | 0.0978  | 0.4336  |  0 hr 19 min \n",
      " 73   | 0.2007  | 0.0883  | 0.4092  |  0 hr 19 min \n",
      " 74   | 0.2045  | 0.1192  | 0.4215  |  0 hr 19 min \n",
      " 75   | 0.2153  | 0.1056  | 0.4667  |  0 hr 19 min \n",
      " 76   | 0.2234  | 0.1281  | 0.4551  |  0 hr 20 min \n",
      " 77   | 0.2765  | 0.0984  | 0.4344  |  0 hr 20 min \n",
      " 78   | 0.2195  | 0.1022  | 0.4381  |  0 hr 20 min \n",
      " 79   | 0.1964  | 0.0980  | 0.4227  |  0 hr 20 min \n",
      " 80   | 0.2325  | 0.1161  | 0.4296  |  0 hr 20 min \n",
      " 81   | 0.2361  | 0.0875  | 0.4149  |  0 hr 20 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82   | 0.2021  | 0.0897  | 0.4526  |  0 hr 20 min \n",
      " 83   | 0.2150  | 0.0911  | 0.4123  |  0 hr 20 min \n",
      " 84   | 0.1851  | 0.0969  | 0.4672  |  0 hr 20 min \n",
      " 85   | 0.2301  | 0.1069  | 0.4492  |  0 hr 20 min \n",
      " 86   | 0.2307  | 0.1061  | 0.4238  |  0 hr 20 min \n",
      " 87   | 0.2531  | 0.0987  | 0.4528  |  0 hr 20 min \n",
      " 88   | 0.2255  | 0.1202  | 0.4572  |  0 hr 20 min \n",
      " 89   | 0.2655  | 0.1013  | 0.4324  |  0 hr 20 min \n",
      " 90   | 0.2704  | 0.0847  | 0.4338  |  0 hr 20 min \n",
      " 91   | 0.2366  | 0.1262  | 0.5118  |  0 hr 20 min \n",
      " 92   | 0.2544  | 0.1036  | 0.4373  |  0 hr 20 min \n",
      " 93   | 0.2027  | 0.1077  | 0.4699  |  0 hr 20 min \n",
      " 94   | 0.1801  | 0.0714  | 0.4103  |  0 hr 20 min \n",
      " 95   | 0.1663  | 0.0910  | 0.4542  |  0 hr 20 min \n",
      " 96   | 0.2115  | 0.0930  | 0.4310  |  0 hr 20 min \n",
      " 97   | 0.1792  | 0.0799  | 0.4333  |  0 hr 20 min \n",
      " 98   | 0.1437  | 0.0745  | 0.4460  |  0 hr 20 min \n",
      " 99   | 0.1592  | 0.0759  | 0.4311  |  0 hr 20 min \n",
      " 100  | 0.1774  | 0.0771  | 0.4418  |  0 hr 20 min \n",
      " 101  | 0.2251  | 0.0752  | 0.4246  |  0 hr 20 min \n",
      " 102  | 0.1866  | 0.0734  | 0.4267  |  0 hr 20 min \n",
      " 103  | 0.1879  | 0.0747  | 0.4392  |  0 hr 21 min \n",
      " 104  | 0.1726  | 0.0696  | 0.4049  |  0 hr 21 min \n",
      " 105  | 0.1956  | 0.0736  | 0.4410  |  0 hr 21 min \n",
      " 106  | 0.1851  | 0.0646  | 0.4064  |  0 hr 21 min \n",
      " 107  | 0.2036  | 0.0774  | 0.4414  |  0 hr 21 min \n",
      " 108  | 0.1801  | 0.0722  | 0.4037  |  0 hr 21 min \n",
      " 109  | 0.1977  | 0.0873  | 0.4234  |  0 hr 21 min \n",
      " 110  | 0.1570  | 0.0667  | 0.4266  |  0 hr 21 min \n",
      " 111  | 0.1481  | 0.0647  | 0.4134  |  0 hr 21 min \n",
      " 112  | 0.1552  | 0.0674  | 0.4217  |  0 hr 21 min \n",
      " 113  | 0.1556  | 0.0656  | 0.4311  |  0 hr 21 min \n",
      " 114  | 0.1741  | 0.0714  | 0.4394  |  0 hr 21 min \n",
      " 115  | 0.1413  | 0.0783  | 0.4164  |  0 hr 21 min \n",
      " 116  | 0.1551  | 0.0609  | 0.4250  |  0 hr 21 min \n",
      " 117  | 0.1534  | 0.0624  | 0.4053  |  0 hr 21 min \n",
      " 118  | 0.1665  | 0.0721  | 0.4369  |  0 hr 21 min \n",
      " 119  | 0.1329  | 0.0580  | 0.4101  |  0 hr 21 min \n",
      " 120  | 0.1508  | 0.0590  | 0.4252  |  0 hr 21 min \n",
      " 121  | 0.2317  | 0.0589  | 0.4265  |  0 hr 21 min \n",
      " 122  | 0.1619  | 0.0643  | 0.4344  |  0 hr 21 min \n",
      " 123  | 0.1641  | 0.0646  | 0.4581  |  0 hr 21 min \n",
      " 124  | 0.1794  | 0.0646  | 0.4283  |  0 hr 21 min \n",
      " 125  | 0.1762  | 0.0803  | 0.4545  |  0 hr 21 min \n",
      " 126  | 0.1360  | 0.0636  | 0.4300  |  0 hr 21 min \n",
      " 127  | 0.1924  | 0.0687  | 0.4389  |  0 hr 21 min \n",
      " 128  | 0.1882  | 0.0688  | 0.4404  |  0 hr 21 min \n",
      " 129  | 0.1549  | 0.0834  | 0.4539  |  0 hr 21 min \n",
      " 130  | 0.1440  | 0.0744  | 0.4377  |  0 hr 22 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  2   |  59   | 0.0580  | 0.3818  \n",
      "  0   | 9.9240  | 8.4696  | 6.4336  |  0 hr 22 min \n",
      "  1   | 4.5898  | 3.5173  | 3.1923  |  0 hr 22 min \n",
      "  2   | 2.0785  | 8.7442  | 7.8497  |  0 hr 22 min \n",
      "  3   | 1.2001  | 10.4155 | 9.2039  |  0 hr 22 min \n",
      "  4   | 1.0219  | 3.5897  | 3.3814  |  0 hr 22 min \n",
      "  5   | 0.8693  | 1.3740  | 1.4888  |  0 hr 22 min \n",
      "  6   | 0.6686  | 0.5702  | 0.5660  |  0 hr 22 min \n",
      "  7   | 0.6123  | 0.4641  | 0.5120  |  0 hr 22 min \n",
      "  8   | 0.5213  | 0.4347  | 0.5104  |  0 hr 22 min \n",
      "  9   | 0.4963  | 0.3441  | 0.4252  |  0 hr 22 min \n",
      " 10   | 0.4624  | 0.3199  | 0.4227  |  0 hr 22 min \n",
      " 11   | 0.5265  | 0.3178  | 0.3549  |  0 hr 22 min \n",
      " 12   | 0.4316  | 0.2763  | 0.3672  |  0 hr 22 min \n",
      " 13   | 0.4260  | 0.2649  | 0.3665  |  0 hr 22 min \n",
      " 14   | 0.4131  | 0.2723  | 0.3490  |  0 hr 22 min \n",
      " 15   | 0.4211  | 0.2916  | 0.3904  |  0 hr 22 min \n",
      " 16   | 0.3746  | 0.2417  | 0.3438  |  0 hr 22 min \n",
      " 17   | 0.3886  | 0.2950  | 0.3980  |  0 hr 22 min \n",
      " 18   | 0.4272  | 0.2417  | 0.3379  |  0 hr 22 min \n",
      " 19   | 0.3903  | 0.2220  | 0.3406  |  0 hr 22 min \n",
      " 20   | 0.3978  | 0.2161  | 0.3111  |  0 hr 22 min \n",
      " 21   | 0.3821  | 0.2801  | 0.3775  |  0 hr 22 min \n",
      " 22   | 0.3512  | 0.2083  | 0.3030  |  0 hr 22 min \n",
      " 23   | 0.3732  | 0.2262  | 0.3234  |  0 hr 22 min \n",
      " 24   | 0.3402  | 0.2120  | 0.3079  |  0 hr 22 min \n",
      " 25   | 0.3353  | 0.2033  | 0.2951  |  0 hr 22 min \n",
      " 26   | 0.3076  | 0.1921  | 0.2976  |  0 hr 23 min \n",
      " 27   | 0.4186  | 0.1852  | 0.2660  |  0 hr 23 min \n",
      " 28   | 0.3041  | 0.1955  | 0.2879  |  0 hr 23 min \n",
      " 29   | 0.3517  | 0.2452  | 0.3498  |  0 hr 23 min \n",
      " 30   | 0.3089  | 0.1802  | 0.3120  |  0 hr 23 min \n",
      " 31   | 0.3219  | 0.1693  | 0.2542  |  0 hr 23 min \n",
      " 32   | 0.2840  | 0.1856  | 0.3009  |  0 hr 23 min \n",
      " 33   | 0.2972  | 0.1763  | 0.2794  |  0 hr 23 min \n",
      " 34   | 0.2567  | 0.1564  | 0.2542  |  0 hr 23 min \n",
      " 35   | 0.2984  | 0.1515  | 0.2578  |  0 hr 23 min \n",
      " 36   | 0.2901  | 0.1533  | 0.2489  |  0 hr 23 min \n",
      " 37   | 0.3101  | 0.2191  | 0.3059  |  0 hr 23 min \n",
      " 38   | 0.2827  | 0.1552  | 0.2837  |  0 hr 23 min \n",
      " 39   | 0.2512  | 0.1573  | 0.2690  |  0 hr 23 min \n",
      " 40   | 0.2681  | 0.1594  | 0.2670  |  0 hr 23 min \n",
      " 41   | 0.2772  | 0.1448  | 0.2601  |  0 hr 23 min \n",
      " 42   | 0.2859  | 0.1524  | 0.2614  |  0 hr 23 min \n",
      " 43   | 0.2721  | 0.1718  | 0.2869  |  0 hr 23 min \n",
      " 44   | 0.2763  | 0.1332  | 0.2582  |  0 hr 23 min \n",
      " 45   | 0.2879  | 0.1674  | 0.2839  |  0 hr 23 min \n",
      " 46   | 0.2867  | 0.1458  | 0.2585  |  0 hr 23 min \n",
      " 47   | 0.2573  | 0.1625  | 0.2808  |  0 hr 23 min \n",
      " 48   | 0.2950  | 0.1336  | 0.2536  |  0 hr 23 min \n",
      " 49   | 0.2984  | 0.1273  | 0.2522  |  0 hr 23 min \n",
      " 50   | 0.2414  | 0.1484  | 0.2695  |  0 hr 23 min \n",
      " 51   | 0.2598  | 0.1306  | 0.2573  |  0 hr 23 min \n",
      " 52   | 0.2160  | 0.1377  | 0.2739  |  0 hr 24 min \n",
      " 53   | 0.2285  | 0.1305  | 0.2712  |  0 hr 24 min \n",
      " 54   | 0.2604  | 0.1437  | 0.2606  |  0 hr 24 min \n",
      " 55   | 0.2187  | 0.1359  | 0.2625  |  0 hr 24 min \n",
      " 56   | 0.2223  | 0.1532  | 0.2914  |  0 hr 24 min \n",
      " 57   | 0.3208  | 0.1543  | 0.2880  |  0 hr 24 min \n",
      " 58   | 0.2637  | 0.1364  | 0.2503  |  0 hr 24 min \n",
      " 59   | 0.2462  | 0.1238  | 0.2471  |  0 hr 24 min \n",
      " 60   | 0.2446  | 0.1175  | 0.2415  |  0 hr 24 min \n",
      " 61   | 0.2454  | 0.1429  | 0.2784  |  0 hr 24 min \n",
      " 62   | 0.1891  | 0.1183  | 0.2550  |  0 hr 24 min \n",
      " 63   | 0.1988  | 0.1211  | 0.2445  |  0 hr 24 min \n",
      " 64   | 0.2741  | 0.1136  | 0.2500  |  0 hr 24 min \n",
      " 65   | 0.2331  | 0.1397  | 0.2628  |  0 hr 24 min \n",
      " 66   | 0.2393  | 0.1242  | 0.2700  |  0 hr 24 min \n",
      " 67   | 0.2545  | 0.0973  | 0.2327  |  0 hr 24 min \n",
      " 68   | 0.2193  | 0.1291  | 0.2671  |  0 hr 24 min \n",
      " 69   | 0.2273  | 0.1261  | 0.2474  |  0 hr 24 min \n",
      " 70   | 0.2061  | 0.1005  | 0.2342  |  0 hr 24 min \n",
      " 71   | 0.1892  | 0.0958  | 0.2383  |  0 hr 24 min \n",
      " 72   | 0.2315  | 0.1187  | 0.2197  |  0 hr 24 min \n",
      " 73   | 0.2314  | 0.1541  | 0.2883  |  0 hr 24 min \n",
      " 74   | 0.2362  | 0.1174  | 0.2231  |  0 hr 24 min \n",
      " 75   | 0.2402  | 0.1130  | 0.2542  |  0 hr 24 min \n",
      " 76   | 0.2123  | 0.1257  | 0.2645  |  0 hr 24 min \n",
      " 77   | 0.2063  | 0.1440  | 0.2668  |  0 hr 24 min \n",
      " 78   | 0.2085  | 0.1887  | 0.3429  |  0 hr 24 min \n",
      " 79   | 0.2377  | 0.1028  | 0.2377  |  0 hr 25 min \n",
      " 80   | 0.1927  | 0.0983  | 0.2350  |  0 hr 25 min \n",
      " 81   | 0.2458  | 0.1087  | 0.2418  |  0 hr 25 min \n",
      " 82   | 0.1896  | 0.0929  | 0.2392  |  0 hr 25 min \n",
      " 83   | 0.2127  | 0.1153  | 0.2595  |  0 hr 25 min \n",
      " 84   | 0.1810  | 0.0886  | 0.2563  |  0 hr 25 min \n",
      " 85   | 0.2175  | 0.0919  | 0.2379  |  0 hr 25 min \n",
      " 86   | 0.1747  | 0.0997  | 0.2674  |  0 hr 25 min \n",
      " 87   | 0.2242  | 0.1004  | 0.2372  |  0 hr 25 min \n",
      " 88   | 0.1767  | 0.0903  | 0.2470  |  0 hr 25 min \n",
      " 89   | 0.1987  | 0.0933  | 0.2409  |  0 hr 25 min \n",
      " 90   | 0.2247  | 0.1055  | 0.2587  |  0 hr 25 min \n",
      " 91   | 0.1940  | 0.1234  | 0.2656  |  0 hr 25 min \n",
      " 92   | 0.2007  | 0.0933  | 0.2470  |  0 hr 25 min \n",
      " 93   | 0.1974  | 0.0974  | 0.2389  |  0 hr 25 min \n",
      " 94   | 0.1848  | 0.0978  | 0.2504  |  0 hr 25 min \n",
      " 95   | 0.2075  | 0.0810  | 0.2367  |  0 hr 25 min \n",
      " 96   | 0.2039  | 0.0830  | 0.2470  |  0 hr 25 min \n",
      " 97   | 0.1926  | 0.0920  | 0.2400  |  0 hr 25 min \n",
      " 98   | 0.1936  | 0.0825  | 0.2438  |  0 hr 25 min \n",
      " 99   | 0.1833  | 0.0848  | 0.2298  |  0 hr 25 min \n",
      " 100  | 0.1827  | 0.0907  | 0.2466  |  0 hr 25 min \n",
      " 101  | 0.1917  | 0.0841  | 0.2281  |  0 hr 25 min \n",
      " 102  | 0.2001  | 0.0977  | 0.2772  |  0 hr 25 min \n",
      " 103  | 0.1851  | 0.0816  | 0.2255  |  0 hr 25 min \n",
      " 104  | 0.1839  | 0.0904  | 0.2475  |  0 hr 25 min \n",
      " 105  | 0.1546  | 0.0826  | 0.2176  |  0 hr 25 min \n",
      " 106  | 0.1522  | 0.0731  | 0.2346  |  0 hr 25 min \n",
      " 107  | 0.1741  | 0.0822  | 0.2376  |  0 hr 25 min \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 108  | 0.1671  | 0.0767  | 0.2310  |  0 hr 26 min \n",
      " 109  | 0.1363  | 0.0681  | 0.2375  |  0 hr 26 min \n",
      " 110  | 0.1561  | 0.0972  | 0.2729  |  0 hr 26 min \n",
      " 111  | 0.1690  | 0.0737  | 0.2419  |  0 hr 26 min \n",
      " 112  | 0.2103  | 0.0802  | 0.2413  |  0 hr 26 min \n",
      " 113  | 0.2142  | 0.0954  | 0.2570  |  0 hr 26 min \n",
      " 114  | 0.1550  | 0.0964  | 0.2436  |  0 hr 26 min \n",
      " 115  | 0.1903  | 0.0986  | 0.2792  |  0 hr 26 min \n",
      " 116  | 0.1466  | 0.0885  | 0.2599  |  0 hr 26 min \n",
      " 117  | 0.2068  | 0.0797  | 0.2605  |  0 hr 26 min \n",
      " 118  | 0.1642  | 0.0747  | 0.2320  |  0 hr 26 min \n",
      " 119  | 0.2333  | 0.0844  | 0.2438  |  0 hr 26 min \n",
      " 120  | 0.1508  | 0.0827  | 0.2395  |  0 hr 26 min \n",
      " 121  | 0.2812  | 0.1153  | 0.2885  |  0 hr 26 min \n",
      " 122  | 0.1814  | 0.0846  | 0.2608  |  0 hr 26 min \n",
      " 123  | 0.1755  | 0.0827  | 0.2181  |  0 hr 26 min \n",
      " 124  | 0.1728  | 0.1001  | 0.2607  |  0 hr 26 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  3   |  105  | 0.0681  | 0.2176  \n",
      "  0   | 9.3385  | 9.2826  | 11.8820 |  0 hr 26 min \n",
      "  1   | 3.9357  | 4.1614  | 5.0546  |  0 hr 26 min \n",
      "  2   | 1.8682  | 2.1156  | 1.9618  |  0 hr 26 min \n",
      "  3   | 0.9441  | 2.1780  | 2.0716  |  0 hr 26 min \n",
      "  4   | 0.8335  | 0.8923  | 0.9421  |  0 hr 26 min \n",
      "  5   | 0.6287  | 0.6156  | 0.6192  |  0 hr 26 min \n",
      "  6   | 0.5628  | 0.4078  | 0.5937  |  0 hr 26 min \n",
      "  7   | 0.4995  | 0.5228  | 0.6823  |  0 hr 26 min \n",
      "  8   | 0.4625  | 0.3769  | 0.5104  |  0 hr 26 min \n",
      "  9   | 0.4723  | 0.4170  | 0.5118  |  0 hr 26 min \n",
      " 10   | 0.4333  | 0.2917  | 0.5016  |  0 hr 26 min \n",
      " 11   | 0.3991  | 0.3152  | 0.4758  |  0 hr 26 min \n",
      " 12   | 0.4293  | 0.2861  | 0.4381  |  0 hr 27 min \n",
      " 13   | 0.4112  | 0.3002  | 0.5208  |  0 hr 27 min \n",
      " 14   | 0.4020  | 0.2474  | 0.4058  |  0 hr 27 min \n",
      " 15   | 0.3731  | 0.2455  | 0.4439  |  0 hr 27 min \n",
      " 16   | 0.4347  | 0.2821  | 0.4875  |  0 hr 27 min \n",
      " 17   | 0.4117  | 0.2419  | 0.4007  |  0 hr 27 min \n",
      " 18   | 0.3408  | 0.2568  | 0.4237  |  0 hr 27 min \n",
      " 19   | 0.3890  | 0.2413  | 0.4681  |  0 hr 27 min \n",
      " 20   | 0.3704  | 0.2118  | 0.3954  |  0 hr 27 min \n",
      " 21   | 0.3656  | 0.2048  | 0.3969  |  0 hr 27 min \n",
      " 22   | 0.3142  | 0.1930  | 0.3999  |  0 hr 27 min \n",
      " 23   | 0.3460  | 0.2475  | 0.4751  |  0 hr 27 min \n",
      " 24   | 0.3068  | 0.1913  | 0.3914  |  0 hr 27 min \n",
      " 25   | 0.3181  | 0.1822  | 0.3892  |  0 hr 27 min \n",
      " 26   | 0.3598  | 0.2421  | 0.4024  |  0 hr 27 min \n",
      " 27   | 0.3218  | 0.2254  | 0.4892  |  0 hr 27 min \n",
      " 28   | 0.2895  | 0.2066  | 0.3858  |  0 hr 27 min \n",
      " 29   | 0.2970  | 0.1810  | 0.4140  |  0 hr 27 min \n",
      " 30   | 0.2831  | 0.1943  | 0.4154  |  0 hr 27 min \n",
      " 31   | 0.2979  | 0.1665  | 0.3662  |  0 hr 27 min \n",
      " 32   | 0.2422  | 0.1831  | 0.4112  |  0 hr 27 min \n",
      " 33   | 0.2802  | 0.1515  | 0.3839  |  0 hr 27 min \n",
      " 34   | 0.2401  | 0.1546  | 0.3805  |  0 hr 27 min \n",
      " 35   | 0.2485  | 0.1576  | 0.3936  |  0 hr 27 min \n",
      " 36   | 0.2790  | 0.1546  | 0.3497  |  0 hr 27 min \n",
      " 37   | 0.2838  | 0.1683  | 0.4349  |  0 hr 27 min \n",
      " 38   | 0.2679  | 0.1610  | 0.3535  |  0 hr 27 min \n",
      " 39   | 0.2728  | 0.1646  | 0.3856  |  0 hr 27 min \n",
      " 40   | 0.2739  | 0.1647  | 0.4560  |  0 hr 28 min \n",
      " 41   | 0.2556  | 0.1658  | 0.3603  |  0 hr 28 min \n",
      " 42   | 0.2992  | 0.1496  | 0.3745  |  0 hr 28 min \n",
      " 43   | 0.2512  | 0.1363  | 0.3918  |  0 hr 28 min \n",
      " 44   | 0.2635  | 0.1215  | 0.3551  |  0 hr 28 min \n",
      " 45   | 0.2504  | 0.1758  | 0.3796  |  0 hr 28 min \n",
      " 46   | 0.2683  | 0.1365  | 0.4125  |  0 hr 28 min \n",
      " 47   | 0.2330  | 0.1390  | 0.4077  |  0 hr 28 min \n",
      " 48   | 0.2313  | 0.1385  | 0.3547  |  0 hr 28 min \n",
      " 49   | 0.2395  | 0.1299  | 0.3887  |  0 hr 28 min \n",
      " 50   | 0.2257  | 0.1145  | 0.3629  |  0 hr 28 min \n",
      " 51   | 0.2119  | 0.1285  | 0.3709  |  0 hr 28 min \n",
      " 52   | 0.2424  | 0.1379  | 0.3842  |  0 hr 28 min \n",
      " 53   | 0.2389  | 0.1328  | 0.4000  |  0 hr 28 min \n",
      " 54   | 0.2113  | 0.1354  | 0.3733  |  0 hr 28 min \n",
      " 55   | 0.1894  | 0.1027  | 0.3444  |  0 hr 28 min \n",
      " 56   | 0.1977  | 0.1090  | 0.3688  |  0 hr 28 min \n",
      " 57   | 0.2142  | 0.1035  | 0.3685  |  0 hr 28 min \n",
      " 58   | 0.2413  | 0.1233  | 0.3905  |  0 hr 28 min \n",
      " 59   | 0.2439  | 0.1082  | 0.3763  |  0 hr 28 min \n",
      " 60   | 0.1989  | 0.1134  | 0.3749  |  0 hr 28 min \n",
      " 61   | 0.2200  | 0.1133  | 0.3920  |  0 hr 28 min \n",
      " 62   | 0.1756  | 0.1100  | 0.3625  |  0 hr 28 min \n",
      " 63   | 0.1993  | 0.0932  | 0.3506  |  0 hr 28 min \n",
      " 64   | 0.1771  | 0.0974  | 0.3617  |  0 hr 28 min \n",
      " 65   | 0.1856  | 0.1008  | 0.3701  |  0 hr 28 min \n",
      " 66   | 0.2144  | 0.1162  | 0.3575  |  0 hr 28 min \n",
      " 67   | 0.2116  | 0.1335  | 0.4362  |  0 hr 28 min \n",
      " 68   | 0.3023  | 0.1092  | 0.3725  |  0 hr 29 min \n",
      " 69   | 0.2277  | 0.0937  | 0.3750  |  0 hr 29 min \n",
      " 70   | 0.2184  | 0.0923  | 0.4251  |  0 hr 29 min \n",
      " 71   | 0.2174  | 0.1217  | 0.3976  |  0 hr 29 min \n",
      " 72   | 0.1703  | 0.0839  | 0.3956  |  0 hr 29 min \n",
      " 73   | 0.2309  | 0.0998  | 0.4474  |  0 hr 29 min \n",
      " 74   | 0.1960  | 0.1086  | 0.4220  |  0 hr 29 min \n",
      " 75   | 0.1983  | 0.1201  | 0.4849  |  0 hr 29 min \n",
      " 76   | 0.1718  | 0.0937  | 0.4214  |  0 hr 29 min \n",
      " 77   | 0.1755  | 0.1069  | 0.4264  |  0 hr 29 min \n",
      " 78   | 0.1710  | 0.0895  | 0.4048  |  0 hr 29 min \n",
      " 79   | 0.1900  | 0.1168  | 0.4267  |  0 hr 29 min \n",
      " 80   | 0.2014  | 0.0898  | 0.3701  |  0 hr 29 min \n",
      " 81   | 0.2012  | 0.1118  | 0.4696  |  0 hr 29 min \n",
      " 82   | 0.1887  | 0.0972  | 0.3656  |  0 hr 29 min \n",
      " 83   | 0.1658  | 0.0769  | 0.3829  |  0 hr 29 min \n",
      " 84   | 0.1875  | 0.0773  | 0.3882  |  0 hr 29 min \n",
      " 85   | 0.2080  | 0.0976  | 0.4184  |  0 hr 29 min \n",
      " 86   | 0.1798  | 0.0821  | 0.3870  |  0 hr 29 min \n",
      " 87   | 0.2001  | 0.0954  | 0.3974  |  0 hr 29 min \n",
      " 88   | 0.1504  | 0.0777  | 0.4103  |  0 hr 29 min \n",
      " 89   | 0.1803  | 0.0784  | 0.3627  |  0 hr 30 min \n",
      " 90   | 0.1649  | 0.0686  | 0.3968  |  0 hr 30 min \n",
      " 91   | 0.1501  | 0.0724  | 0.4040  |  0 hr 30 min \n",
      " 92   | 0.2400  | 0.0816  | 0.3732  |  0 hr 30 min \n",
      " 93   | 0.1773  | 0.1032  | 0.4530  |  0 hr 30 min \n",
      " 94   | 0.2060  | 0.0714  | 0.4343  |  0 hr 30 min \n",
      " 95   | 0.1896  | 0.0909  | 0.4370  |  0 hr 30 min \n",
      " 96   | 0.2238  | 0.0860  | 0.4026  |  0 hr 30 min \n",
      " 97   | 0.1965  | 0.0782  | 0.4319  |  0 hr 30 min \n",
      " 98   | 0.1567  | 0.0673  | 0.3954  |  0 hr 30 min \n",
      " 99   | 0.1697  | 0.0712  | 0.4238  |  0 hr 30 min \n",
      " 100  | 0.1788  | 0.0661  | 0.3920  |  0 hr 30 min \n",
      " 101  | 0.1653  | 0.0747  | 0.4264  |  0 hr 30 min \n",
      " 102  | 0.1764  | 0.0763  | 0.3763  |  0 hr 30 min \n",
      " 103  | 0.2089  | 0.0872  | 0.4517  |  0 hr 30 min \n",
      " 104  | 0.1771  | 0.0816  | 0.3987  |  0 hr 30 min \n",
      " 105  | 0.1727  | 0.0901  | 0.4134  |  0 hr 30 min \n",
      " 106  | 0.2055  | 0.0857  | 0.4331  |  0 hr 30 min \n",
      " 107  | 0.1970  | 0.0772  | 0.4230  |  0 hr 31 min \n",
      " 108  | 0.1709  | 0.0841  | 0.4143  |  0 hr 31 min \n",
      " 109  | 0.1772  | 0.0862  | 0.4539  |  0 hr 31 min \n",
      " 110  | 0.1547  | 0.0642  | 0.3953  |  0 hr 31 min \n",
      " 111  | 0.1992  | 0.0634  | 0.3938  |  0 hr 31 min \n",
      " 112  | 0.1740  | 0.0598  | 0.4256  |  0 hr 31 min \n",
      " 113  | 0.1576  | 0.0619  | 0.4378  |  0 hr 31 min \n",
      " 114  | 0.1525  | 0.0590  | 0.4125  |  0 hr 31 min \n",
      " 115  | 0.1236  | 0.0667  | 0.4313  |  0 hr 31 min \n",
      " 116  | 0.1299  | 0.0639  | 0.3838  |  0 hr 31 min \n",
      " 117  | 0.1244  | 0.0548  | 0.3909  |  0 hr 31 min \n",
      " 118  | 0.1580  | 0.0630  | 0.4050  |  0 hr 31 min \n",
      " 119  | 0.1539  | 0.0567  | 0.4105  |  0 hr 31 min \n",
      " 120  | 0.1587  | 0.0689  | 0.4306  |  0 hr 31 min \n",
      " 121  | 0.1939  | 0.0570  | 0.3989  |  0 hr 31 min \n",
      " 122  | 0.1624  | 0.0619  | 0.4235  |  0 hr 31 min \n",
      " 123  | 0.2313  | 0.0681  | 0.3997  |  0 hr 31 min \n",
      " 124  | 0.1676  | 0.0605  | 0.4020  |  0 hr 31 min \n",
      " 125  | 0.1841  | 0.0570  | 0.3989  |  0 hr 32 min \n",
      " 126  | 0.1514  | 0.0671  | 0.3888  |  0 hr 32 min \n",
      " 127  | 0.1451  | 0.0757  | 0.4374  |  0 hr 32 min \n",
      " 128  | 0.1315  | 0.0694  | 0.3815  |  0 hr 32 min \n",
      "fold | epoch | train_MSE | valid MSE \n",
      "  4   |  55   | 0.0548  | 0.3444  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "log = Logger()\n",
    "log.open(f'log/{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch | loss | train MSE |  valid MSE |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "log2 = Logger()\n",
    "log2.open(f'{prefix_filename}_best_{start_time}.txt')\n",
    "f2 = '{:^5} | {:^5} | {:^7.4f} | {:^7.4f} \\n'\n",
    "\n",
    "for fold_index in range(5):\n",
    "    \n",
    "    model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "    \n",
    "    best_param ={}\n",
    "    best_param[\"train_epoch\"] = 0\n",
    "    best_param[\"valid_epoch\"] = 0\n",
    "    best_param[\"train_MSE\"] = 800\n",
    "    best_param[\"valid_MSE\"] = 800\n",
    "    for epoch in range(800):\n",
    "        losses = train(smiles_list[train_fold[fold_index]])\n",
    "        traine_MAE, train_MSE = eval(smiles_list[train_fold[fold_index]])\n",
    "        valid_MAE, valid_MSE = eval(smiles_list[valid_fold[fold_index]])\n",
    "        \n",
    "        timing = time_to_str((timer() - start), 'min')  \n",
    "        log.write(f.format(epoch, losses, train_MSE, valid_MSE, timing))\n",
    "        \n",
    "        if train_MSE < best_param[\"train_MSE\"]:\n",
    "            best_param[\"train_epoch\"] = epoch\n",
    "            best_param[\"train_MSE\"] = train_MSE\n",
    "        if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "            best_param[\"valid_epoch\"] = epoch\n",
    "            best_param[\"valid_MSE\"] = valid_MSE\n",
    "#             if valid_MSE < 0.35:\n",
    "#                  torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "        if (epoch - best_param[\"train_epoch\"] >10) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "            break\n",
    "\n",
    "    log2.write('fold | epoch | train_MSE | valid MSE \\n')\n",
    "    log2.write(f2.format(fold_index, best_param[\"valid_epoch\"],best_param[\"train_MSE\"],best_param[\"valid_MSE\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model\n",
    "# best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "# test_MAE, test_MSE = eval(model, test_df)\n",
    "# print(\"best epoch:\",best_param[\"test_epoch\"],\"\\n\",\"test MSE:\",test_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(20):\n",
    "#     losses = train(smiles_list[valid_fold[fold_index]])\n",
    "#     print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
