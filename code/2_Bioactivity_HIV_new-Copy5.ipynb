{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "import random\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#then import my own modules\n",
    "# from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n",
    "from timeit import default_timer as timer\n",
    "from AttentiveFP.featurizing import graph_dict\n",
    "from AttentiveFP.AttentiveLayers_new import Fingerprint, graph_dataset, null_collate, Graph, Logger, time_to_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_aviable = torch.cuda.is_available()\n",
    "device = torch.device(0)\n",
    "\n",
    "SEED = 8\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  41127\n",
      "number of successfully processed smiles:  41127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'HIV'\n",
    "tasks = ['HIV_active']\n",
    "raw_filename = \"../data/HIV.csv\"\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        remained_smiles.append(smiles)\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 200\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "K = 3\n",
    "T = 2\n",
    "per_task_output_units_num = 2 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph dicts loaded from ../data/HIV.pkl\n"
     ]
    }
   ],
   "source": [
    "smiles_list = smiles_tasks_df['smiles'].values\n",
    "label_list = smiles_tasks_df[tasks[0]].values\n",
    "graph_dict = graph_dict(smiles_list, label_list, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "class ScaffoldGenerator(object):\n",
    "    \"\"\"\n",
    "    Generate molecular scaffolds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    include_chirality : : bool, optional (default False)\n",
    "      Include chirality in scaffolds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, include_chirality=False):\n",
    "        self.include_chirality = include_chirality\n",
    "\n",
    "    def get_scaffold(self, mol):\n",
    "        \"\"\"\n",
    "        Get Murcko scaffolds for molecules.\n",
    "\n",
    "        Murcko scaffolds are described in DOI: 10.1021/jm9602928. They are\n",
    "        essentially that part of the molecule consisting of rings and the\n",
    "        linker atoms between them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mols : array_like\n",
    "            Molecules.\n",
    "        \"\"\"\n",
    "        return MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=self.include_chirality)\n",
    "\n",
    "\n",
    "def generate_scaffold(smiles, include_chirality=False):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    engine = ScaffoldGenerator(include_chirality=include_chirality)\n",
    "    scaffold = engine.get_scaffold(mol)\n",
    "    return scaffold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f880510dd3e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_tasks_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscaffold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_scaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mscaffold_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscaffold\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_scaffolds_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e13b1fa56015>\u001b[0m in \u001b[0;36mgenerate_scaffold\u001b[0;34m(smiles, include_chirality)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_scaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_chirality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScaffoldGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_chirality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_chirality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mscaffold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = smiles_tasks_df[smiles_tasks_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = smiles_tasks_df[smiles_tasks_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "scaffold_list = []\n",
    "all_scaffolds_dict = {}\n",
    "\n",
    "for index, smiles in enumerate(smiles_tasks_df['smiles']):\n",
    "    scaffold = generate_scaffold(smiles)\n",
    "    scaffold_list.append(scaffold)\n",
    "    if scaffold not in all_scaffolds_dict:\n",
    "        all_scaffolds_dict[scaffold] = [index]\n",
    "    else:\n",
    "        all_scaffolds_dict[scaffold].append(index)\n",
    "smiles_tasks_df['scaffold'] = scaffold_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tasks_df.groupby(['scaffold'])['scaffold'].count() \\\n",
    "                     .reset_index(name='count') \\\n",
    "                     .sort_values(['count'], ascending=False) \\\n",
    "                     .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaffold_randomized_spliting(scaffolds_dict, sample_size, random_seed = 0): \n",
    "    count = 0\n",
    "    minor_count = 0\n",
    "    minor_class = np.argmax(weights[0]) # weights are inverse of the ratio\n",
    "    minor_ratio= 1/weights[0][minor_class]\n",
    "    optimal_count = 0.1*len(smiles_tasks_df)\n",
    "    while (count < optimal_count*0.9 or  count > optimal_count*1.1) \\\n",
    "        or (minor_count < minor_ratio*optimal_count*0.9 \\\n",
    "            or  minor_count > minor_ratio*optimal_count*1.1):\n",
    "        random_seed +=1\n",
    "        random.seed(random_seed)\n",
    "        scaffold = random.sample(list(scaffolds_dict.keys()), sample_size)\n",
    "        count = sum([len(scaffolds_dict[scaffold]) for scaffold in scaffold])\n",
    "        index = [index for scaffold in scaffold for index in scaffolds_dict[scaffold]]\n",
    "        minor_count = len(smiles_tasks_df.iloc[index, :][smiles_tasks_df[tasks[0]] == minor_class])\n",
    "#     print(random)\n",
    "    print(random_seed, count, minor_count, index)\n",
    "    return scaffold, index\n",
    "\n",
    "samples_size = int(len(all_scaffolds_dict.keys())*0.1)\n",
    "print(samples_size)\n",
    "test_scaffold, test_index = scaffold_randomized_spliting(all_scaffolds_dict, samples_size, random_seed=8)\n",
    "training_scaffolds_dict = {x: all_scaffolds_dict[x] for x in all_scaffolds_dict.keys() if x not in test_scaffold}\n",
    "valid_scaffold, valid_index = scaffold_randomized_spliting(training_scaffolds_dict, samples_size, random_seed=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = smiles_tasks_df.iloc[test_index,:] # test set\n",
    "valid_df = smiles_tasks_df.iloc[valid_index,:] # valid set\n",
    "train_df = smiles_tasks_df.drop(test_df.index).drop(valid_df.index) # train set\n",
    "test_smiles = test_df.smiles.values\n",
    "valid_smiles = valid_df.smiles.values\n",
    "train_smiles = train_df.smiles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "\n",
    "model = Fingerprint(output_units_num, fingerprint_dim, K=K, T=T, p_dropout=p_dropout)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in  model.parameters()])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, smiles_list):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=True, worker_init_fn=np.random.seed(SEED),drop_last=True)\n",
    "    losses = []\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in tqdm(enumerate(train_loader)):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        \n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            \n",
    "            validInds = np.where((label==0) | (label==1))[0]\n",
    "#             validInds = np.where(label != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            label_adjust = np.array([label[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(label_adjust))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "        \n",
    "def eval(model, smiles_list):\n",
    "    model.eval()\n",
    "    label_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    eval_loader = DataLoader(graph_dataset(smiles_list, graph_dict), batch_size, collate_fn=null_collate, \\\n",
    "                              num_workers=8, pin_memory=True, shuffle=False, worker_init_fn=np.random.seed(SEED))\n",
    "    for b, (smiles, atom, bond, bond_index, mol_index, label) in tqdm(enumerate(eval_loader)):\n",
    "        atom = atom.to(device)\n",
    "        bond = bond.to(device)\n",
    "        bond_index = bond_index.to(device)\n",
    "        mol_index = mol_index.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "        mol_prediction = model(atom, bond, bond_index, mol_index)\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "\n",
    "            validInds = np.where((label==0) | (label==1))[0]\n",
    "#             validInds = np.where((label=='0') | (label=='1'))[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            label_adjust = np.array([label[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(label_adjust))\n",
    "            \n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                label_list[i].extend(label_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                label_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                label_list[i].extend(label_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                \n",
    "    eval_loss = np.array(losses_list).mean()\n",
    "    eval_roc = [roc_auc_score(label_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "#     eval_prc = [auc(precision_recall_curve(label_list[i], y_pred_list[i])[1],precision_recall_curve(label_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     eval_precision = [precision_score(label_list[i],\n",
    "#                                      (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "#     eval_recall = [recall_score(label_list[i],\n",
    "#                                (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    \n",
    "    return eval_roc, eval_loss #, eval_prc, eval_precision, eval_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Logger()\n",
    "log.open(f'{prefix_filename}_{start_time}.txt')\n",
    "\n",
    "f = '{:^5} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7.4f} | {:^7} \\n'\n",
    "log.write('epoch |  losses  | train loss |  valid loss | train roc |  valid roc |  time \\n')\n",
    "start = timer()\n",
    "\n",
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    losses = train(model, train_smiles)\n",
    "    train_roc, train_loss = eval(model, train_smiles)\n",
    "    valid_roc, valid_loss = eval(model, valid_smiles)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "    timing = time_to_str((timer() - start), 'min')  \n",
    "    log.write(f.format(epoch, losses, train_loss, valid_loss, train_roc_mean, valid_roc_mean, timing))\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.80:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    if (epoch - best_param[\"roc_epoch\"] >8) and (epoch - best_param[\"loss_epoch\"] >18):        \n",
    "        break\n",
    "        \n",
    "print(best_param[\"roc_epoch\"],best_param[\"loss_epoch\"],best_param[\"valid_roc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "# best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_33.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_losses = eval(best_model, test_smiles)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
